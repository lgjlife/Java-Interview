
<span id="menu" >

<!-- TOC -->

- [1. 计算机&网络&操作系统](#1-计算机网络操作系统)
    - [1.1. 计算机基础](#11-计算机基础)
        - [1.1.1. 数据类型](#111-数据类型)
            - [1.1.1.1. ASCII](#1111-ascii)
    - [1.2. 操作系统](#12-操作系统)
        - [1.2.1. 操作系统基本概念](#121-操作系统基本概念)
            - [1.2.1.1. 操作系统的功能](#1211-操作系统的功能)
            - [1.2.1.2. 操作系统发展过程](#1212-操作系统发展过程)
            - [1.2.1.3. 操作系统的特性](#1213-操作系统的特性)
            - [1.2.1.4. 操作系统的体系结构](#1214-操作系统的体系结构)
                - [1.2.1.4.1. 层次结构](#12141-层次结构)
                - [1.2.1.4.2. 微内核结构](#12142-微内核结构)
                - [1.2.1.4.3. 基本特性](#12143-基本特性)
        - [1.2.2. Linux进程和线程的区别](#122-linux进程和线程的区别)
        - [1.2.3. Linux各目录及每个目录的详细介绍](#123-linux各目录及每个目录的详细介绍)
    - [1.3. 网络TCP](#13-网络tcp)
        - [1.3.1. OSI网路分层](#131-osi网路分层)
        - [1.3.2. IP(Internet Protocol,网际协议)](#132-ipinternet-protocol网际协议)
            - [1.3.2.1. 基本概念](#1321-基本概念)
            - [1.3.2.2. IP地址定义](#1322-ip地址定义)
            - [1.3.2.3. IP协议相关技术](#1323-ip协议相关技术)
                - [1.3.2.3.1. DNS](#13231-dns)
                - [1.3.2.3.2. ARP](#13232-arp)
        - [1.3.3. 传输层](#133-传输层)
            - [1.3.3.1. 基本概念](#1331-基本概念)
                - [1.3.3.1.1. TCP和UDP差别](#13311-tcp和udp差别)
                - [1.3.3.1.2. 端口](#13312-端口)
            - [1.3.3.2. UDP](#1332-udp)
            - [1.3.3.3. TCP](#1333-tcp)
                - [1.3.3.3.1. 连接管理](#13331-连接管理)
                - [1.3.3.3.2. 超时重传机制](#13332-超时重传机制)
                - [1.3.3.3.3. 数据流和窗口机制](#13333-数据流和窗口机制)
                - [1.3.3.3.4. 阻塞控制](#13334-阻塞控制)
    - [1.4. 网络HTTP](#14-网络http)
        - [1.4.1. 基本概念](#141-基本概念)
            - [1.4.1.1. 访问一个网站的流程](#1411-访问一个网站的流程)
            - [1.4.1.2. 资源](#1412-资源)
                - [1.4.1.2.1. 媒体类型(MIME)](#14121-媒体类型mime)
                - [1.4.1.2.2. URL和资源](#14122-url和资源)
            - [1.4.1.3. HTTP报文](#1413-http报文)
                - [1.4.1.3.1. 请求报文和响应报文](#14131-请求报文和响应报文)
                - [1.4.1.3.2. 首部](#14132-首部)
                - [1.4.1.3.3. 方法](#14133-方法)
                - [1.4.1.3.4. 状态码](#14134-状态码)
            - [1.4.1.4. 连接管理](#1414-连接管理)
                - [1.4.1.4.1. 对TCP性能的考虑](#14141-对tcp性能的考虑)
                - [1.4.1.4.2. 持久连接](#14142-持久连接)
                    - [1.4.1.4.2.1. TCP连接](#141421-tcp连接)
            - [1.4.1.5. 版本变化](#1415-版本变化)
        - [1.4.2. HTTPS](#142-https)
            - [1.4.2.1. HTTP协议的缺点以及改进目标](#1421-http协议的缺点以及改进目标)
            - [1.4.2.2. 密码基础](#1422-密码基础)
            - [1.4.2.3. HTTPS协议的改进](#1423-https协议的改进)
            - [1.4.2.4. HTTPS实现原理](#1424-https实现原理)
            - [1.4.2.5. 与HTTP原理区别](#1425-与http原理区别)
            - [1.4.2.6. 优缺点](#1426-优缺点)
        - [1.4.3. HTTP结构](#143-http结构)
            - [1.4.3.1. WEB服务器](#1431-web服务器)
            - [1.4.3.2. 代理](#1432-代理)
            - [1.4.3.3. 缓存](#1433-缓存)
            - [1.4.3.4. 网关](#1434-网关)
        - [1.4.4. 识别,认证与安全](#144-识别认证与安全)
            - [1.4.4.1. 客户端识别与Cookie机制](#1441-客户端识别与cookie机制)
                - [1.4.4.1.1. Cookie](#14411-cookie)
            - [1.4.4.2. 基本认证机制](#1442-基本认证机制)
            - [1.4.4.3. 摘要认证](#1443-摘要认证)
        - [1.4.5. 实体和编码](#145-实体和编码)
            - [1.4.5.1. 实体首部](#1451-实体首部)
            - [1.4.5.2. HTTP的媒体类型](#1452-http的媒体类型)
        - [1.4.6. 国际化](#146-国际化)
        - [1.4.7. WEB主机托管](#147-web主机托管)
        - [1.4.8. 重定向和负载均衡](#148-重定向和负载均衡)
    - [1.5. WEB Socket](#15-web-socket)
        - [1.5.1. websocket与http](#151-websocket与http)
        - [1.5.2. 数据帧格式](#152-数据帧格式)
        - [1.5.3. 数据传递](#153-数据传递)
        - [1.5.4. 连接保持+心跳](#154-连接保持心跳)
        - [1.5.5. Sec-WebSocket-Key/Accept的作用](#155-sec-websocket-keyaccept的作用)
        - [1.5.6. 数据掩码的作用](#156-数据掩码的作用)
        - [1.5.7. WebSocket运行流程](#157-websocket运行流程)
        - [1.5.8. SpringBoot + WebSocket实现案例](#158-springboot--websocket实现案例)
            - [1.5.8.1. 第一种实现方法](#1581-第一种实现方法)
            - [1.5.8.2. 第二种实现方法](#1582-第二种实现方法)
            - [1.5.8.3. 补充说明](#1583-补充说明)
            - [1.5.8.4. 客户端的实现，js方式和java WebSocketClient两种方式](#1584-客户端的实现js方式和java-websocketclient两种方式)
    - [1.6. Unix环境编程](#16-unix环境编程)
        - [1.6.1. 基本概念](#161-基本概念)
        - [1.6.2. IO模型](#162-io模型)
        - [1.6.3. select&poll&epoll比较](#163-selectpollepoll比较)
            - [1.6.3.1. 整体概览](#1631-整体概览)
            - [1.6.3.2. 对比总结](#1632-对比总结)
    - [1.7. Shell](#17-shell)
        - [1.7.1. 文件安装](#171-文件安装)
            - [1.7.1.1. deb文件操作](#1711-deb文件操作)
        - [1.7.2. 常用命令](#172-常用命令)
            - [1.7.2.1. 系统信息](#1721-系统信息)
            - [1.7.2.2. SSH](#1722-ssh)
            - [1.7.2.3. 网络](#1723-网络)
            - [1.7.2.4. 进程管理](#1724-进程管理)
            - [1.7.2.5. 快捷键](#1725-快捷键)
            - [查看端口占用](#查看端口占用)
            - [1.7.2.6. 文件相关](#1726-文件相关)
            - [1.7.2.7. 监测程序](#1727-监测程序)
                - [1.7.2.7.1. 探查进程](#17271-探查进程)
                - [1.7.2.7.2. 实时监测进程](#17272-实时监测进程)
                - [1.7.2.7.3. 结束进程](#17273-结束进程)
            - [1.7.2.8. 监测磁盘空间](#1728-监测磁盘空间)
                - [1.7.2.8.1. df 命令](#17281-df-命令)
                - [1.7.2.8.2. du 命令](#17282-du-命令)
            - [1.7.2.9. 处理数据文件](#1729-处理数据文件)
                - [1.7.2.9.1. 排序数据](#17291-排序数据)
                - [1.7.2.9.2. 搜索数据](#17292-搜索数据)
                - [1.7.2.9.3. 归档数据](#17293-归档数据)
        - [1.7.3. 环境变量](#173-环境变量)
            - [1.7.3.1. 什么是环境变量](#1731-什么是环境变量)
                - [1.7.3.1.1. 全局环境变量](#17311-全局环境变量)
                - [1.7.3.1.2. 局部环境变量](#17312-局部环境变量)
            - [1.7.3.2. 设置用户定义变量](#1732-设置用户定义变量)
                - [1.7.3.2.1. 设置局部用户变量](#17321-设置局部用户变量)
                - [1.7.3.2.2. 设置全局变量](#17322-设置全局变量)
            - [1.7.3.3. 删除环境变量](#1733-删除环境变量)
            - [1.7.3.4. 默认的shell环境变量](#1734-默认的shell环境变量)
            - [1.7.3.5. 设置PATH环境变量](#1735-设置path环境变量)
            - [1.7.3.6. 定位系统环境变量](#1736-定位系统环境变量)
                - [1.7.3.6.1. 环境变量持久化](#17361-环境变量持久化)
            - [1.7.3.7. 数组变量](#1737-数组变量)
        - [1.7.4. 理解Linux文件权限](#174-理解linux文件权限)
            - [1.7.4.1. Linux 安全性](#1741-linux-安全性)
                - [1.7.4.1.1. /etc/passwd 文件](#17411-etcpasswd-文件)
                - [1.7.4.1.2. /etc/shadow 文件](#17412-etcshadow-文件)
                - [1.7.4.1.3. 添加新用户](#17413-添加新用户)
                - [1.7.4.1.4. 删除用户](#17414-删除用户)
                - [1.7.4.1.5. 修改用户](#17415-修改用户)
            - [1.7.4.2. 使用Linux组](#1742-使用linux组)
                - [1.7.4.2.1. /etc/group 文件](#17421-etcgroup-文件)
                - [1.7.4.2.2. 创建新组](#17422-创建新组)
                - [1.7.4.2.3. 修改组](#17423-修改组)
            - [1.7.4.3. 理解文件权限](#1743-理解文件权限)
                - [1.7.4.3.1. 使用文件权限符](#17431-使用文件权限符)
            - [1.7.4.4. 改变安全性设置](#1744-改变安全性设置)
            - [1.7.4.5. 共享文件](#1745-共享文件)
        - [1.7.5. 管理文件系统](#175-管理文件系统)
            - [1.7.5.1. Linux 文件系统](#1751-linux-文件系统)
            - [1.7.5.2. 操作文件系统](#1752-操作文件系统)
            - [1.7.5.3. 逻辑文件系统](#1753-逻辑文件系统)
        - [1.7.6. Shell脚本编程](#176-shell脚本编程)
            - [1.7.6.1. 基本脚本命令](#1761-基本脚本命令)
                - [1.7.6.1.1. 创建 shell 脚本文件](#17611-创建-shell-脚本文件)
                - [1.7.6.1.2. 脚本中打印](#17612-脚本中打印)
                - [1.7.6.1.3. 使用变量](#17613-使用变量)
                - [1.7.6.1.4. 命令替换](#17614-命令替换)
                - [1.7.6.1.5. 重定向输入和输出](#17615-重定向输入和输出)
                - [1.7.6.1.6. 管道](#17616-管道)
                - [1.7.6.1.7. 执行数学运算](#17617-执行数学运算)
                - [1.7.6.1.8. 退出脚本](#17618-退出脚本)
            - [1.7.6.2. 结构化命令](#1762-结构化命令)
                - [1.7.6.2.1. 使用 if-then 语句](#17621-使用-if-then-语句)
                - [1.7.6.2.2. if-then-else 语句](#17622-if-then-else-语句)
                - [1.7.6.2.3. 嵌套 if](#17623-嵌套-if)
                - [1.7.6.2.4. test 命令](#17624-test-命令)
                - [1.7.6.2.5. 复合条件测试](#17625-复合条件测试)
                - [1.7.6.2.6. if-then 的高级特性](#17626-if-then-的高级特性)
                - [1.7.6.2.7. case 命令](#17627-case-命令)
            - [1.7.6.3. 更多结构化命令](#1763-更多结构化命令)
                - [1.7.6.3.1. for命令](#17631-for命令)
                - [1.7.6.3.2. C 语言的 for 命令](#17632-c-语言的-for-命令)
                - [1.7.6.3.3. while 命令](#17633-while-命令)
                - [1.7.6.3.4. until 命令](#17634-until-命令)
                - [1.7.6.3.5. 控制循环](#17635-控制循环)
                - [1.7.6.3.6. 处理循环的输出](#17636-处理循环的输出)
            - [1.7.6.4. 处理用户输入](#1764-处理用户输入)
                - [1.7.6.4.1. 命令行参数](#17641-命令行参数)
                - [1.7.6.4.2. 特殊参数变量](#17642-特殊参数变量)
                - [1.7.6.4.3. 移动变量](#17643-移动变量)
                - [1.7.6.4.4. 处理选项](#17644-处理选项)
                - [1.7.6.4.5. 获得用户输入](#17645-获得用户输入)
            - [1.7.6.5. 呈现数据](#1765-呈现数据)
                - [1.7.6.5.1. 理解输入和输出](#17651-理解输入和输出)
                - [1.7.6.5.2. 脚本中重定向输出](#17652-脚本中重定向输出)
                - [1.7.6.5.3. 脚本中重定向输入](#17653-脚本中重定向输入)
                - [1.7.6.5.4. 创建自己的重定向](#17654-创建自己的重定向)
                - [1.7.6.5.5. 列出打开的文件描述符](#17655-列出打开的文件描述符)
                - [1.7.6.5.6. 阻止命令输出](#17656-阻止命令输出)
                - [1.7.6.5.7. 创建临时文件](#17657-创建临时文件)
                - [1.7.6.5.8. 记录消息](#17658-记录消息)
            - [1.7.6.6. 控制脚本](#1766-控制脚本)
                - [1.7.6.6.1. 处理信号](#17661-处理信号)
                - [1.7.6.6.2. 以后台模式运行脚本](#17662-以后台模式运行脚本)
                - [1.7.6.6.3. 在非控制台下运行脚本](#17663-在非控制台下运行脚本)
                - [1.7.6.6.4. 作业控制](#17664-作业控制)
                - [1.7.6.6.5. 调整谦让度](#17665-调整谦让度)
                - [1.7.6.6.6. 定时运行作业](#17666-定时运行作业)
        - [1.7.7. 高级 shell 脚本编程](#177-高级-shell-脚本编程)
            - [1.7.7.1. 创建函数](#1771-创建函数)
                - [1.7.7.1.1. 基本的脚本函数](#17711-基本的脚本函数)
                - [1.7.7.1.2. 返回值](#17712-返回值)
                - [1.7.7.1.3. 在函数中使用变量](#17713-在函数中使用变量)
                - [1.7.7.1.4. 数组变量和函数](#17714-数组变量和函数)
                - [1.7.7.1.5. 函数递归](#17715-函数递归)
                - [1.7.7.1.6. 创建库](#17716-创建库)
                - [1.7.7.1.7. 在命令行上使用函数](#17717-在命令行上使用函数)
            - [1.7.7.2. 图形化桌面环境中的脚本编程](#1772-图形化桌面环境中的脚本编程)
            - [1.7.7.3. 初识 sed 和 gawk](#1773-初识-sed-和-gawk)
                - [1.7.7.3.1. 文本处理](#17731-文本处理)
                - [1.7.7.3.2. sed编辑器基础](#17732-sed编辑器基础)
            - [1.7.7.4. 正则表达式](#1774-正则表达式)
                - [1.7.7.4.1. 什么是正则表达式](#17741-什么是正则表达式)
                - [1.7.7.4.2. 定义BRE模式](#17742-定义bre模式)
                - [1.7.7.4.3. 扩展正则表达式](#17743-扩展正则表达式)
                - [1.7.7.4.4. 正则表达式实战](#17744-正则表达式实战)
            - [1.7.7.5. sed 进阶](#1775-sed-进阶)
                - [1.7.7.5.1. 多行命令](#17751-多行命令)
                - [1.7.7.5.2. 保持空间](#17752-保持空间)
                - [1.7.7.5.3. 排除命令](#17753-排除命令)
                - [1.7.7.5.4. 改变流](#17754-改变流)
                - [1.7.7.5.5. 模式替代](#17755-模式替代)
                - [1.7.7.5.6. 在脚本中使用sed](#17756-在脚本中使用sed)
                - [1.7.7.5.7. 创建sed实用工具](#17757-创建sed实用工具)
            - [1.7.7.6. gawk 进阶](#1776-gawk-进阶)
                - [1.7.7.6.1. 使用变量](#17761-使用变量)
                - [1.7.7.6.2. 处理数组](#17762-处理数组)
                - [1.7.7.6.3. 使用模式](#17763-使用模式)
                - [1.7.7.6.4. 结构化命令](#17764-结构化命令)
                - [1.7.7.6.5. 格式化打印](#17765-格式化打印)
                - [1.7.7.6.6. 内建函数](#17766-内建函数)
                - [1.7.7.6.7. 自定义函数](#17767-自定义函数)

<!-- /TOC -->


# 1. 计算机&网络&操作系统
<a href="#menu" style="float:right">目录</a>

## 1.1. 计算机基础

<a href="#menu" style="float:right">目录</a>

### 1.1.1. 数据类型

#### 1.1.1.1. ASCII
* ASCII控制字符

|二进制|	十进制|	十六进制	|缩写	|名称/意义|
|---|---|---|---|---|
|0000 0000	|0	|00	|NUL	|空字符（Null）
|0000 0001	|1	|01	|SOH		|标题开始
|0000 0010	|2	|02	|STX	  |本文开始
|0000 0011	|3	|03	|ETX		|本文结束
|0000 0100	|4	|04	|EOT		|传输结束
|0000 0101	|5	|05	|ENQ		|请求
|0000 0110	|6	|06	|ACK		|确认回应
|0000 0111	|7	|07	|BEL		|响铃
|0000 1000	|8	|08	|BS	|退格
|0000 1001	|9	|09	|HT		|水平定位符号
|0000 1010	|10	|0A	|LF		|换行键
|0000 1011	|11	||0B	|VT	|垂直定位符号
|0000 1100	|12	|0C	|FF		|换页键
|0000 1101	|13	|0D	|CR		|归位键
|0000 1110	|14	|0E	|SO		|取消变换（Shift out）
|0000 1111	|15	|0F	|SI		|启用变换（Shift in）
|0001 0000	|16	|10	|DLE		|跳出数据通讯
|0001 0001	|17	|11	|DC1		|设备控制一（XON 启用软件速度控制）
|0001 0010	|18	|12	|DC2		|设备控制二
|0001 0011	|19	|13	|DC3		|设备控制三（XOFF 停用软件速度控制）
|0001 0100	|20	|14	|DC4		|设备控制四
|0001 0101	|21	|15	|NAK		|确认失败回应
|0001 0110	|22	|16	|SYN		|同步用暂停
|0001 0111	|23	|17	|ETB		|区块传输结束
|0001 1000	|24	|18	|CAN		|取消
|0001 1001	|25	|19	|EM		|连接介质中断
|0001 1010	|26	|1A	|SUB		|替换
|0001 1011	|27	|1B	|ESC		|跳出
|0001 1100	|28	|1C	|FS		|文件分割符
|0001 1101	|29	|1D	|GS	|组群分隔符
|0001 1110	|30	|1E	|RS		|记录分隔符
|0001 1111	|31	|1F	|US		|单元分隔符
|0111 1111	|127	|7F	|DEL	|删除

* ASCII可显示字符

|二进制	|十进制	|十六进制	|图形|
|---|---|---|---|
|0010 0000|	32|	20|	（空格）(␠)
|0010 0001|	33|	21	|!
|0010 0010|	34|	22	|"
|0010 0011|	35|	23	|#
|0010 0100|	36|	24|	$
|0010 0101|	37|	25|	 %
|0010 0110|	38|	26|	&
|0010 0111|	39|	27|	'
|0010 1000|	40|	28|	(
|0010 1001|	41|	29|	)
|0010 1010|	42|	2A|	*
|0010 1011|	43|	2B|	+
|0010 1100|	44|	2C|	,
|0010 1101|	45|	2D|	-
|0010 1110|	46|	2E|	.
|0010 1111|	47|	2F|	/
|0011 0000|	48|	30|	0
|0011 0001|	49|	31|	1
|0011 0010|	50|	32|	2
|0011 0011|	51|	33|	3
|0011 0100|	52|	34|	4
|0011 0101|	53|	35|	5
|0011 0110|	54|	36|	6
|0011 0111|	55|	37|	7
|0011 1000|	56|	38|	8
|0011 1001|	57|	39|	9
|0011 1010|	58|	3A|	:
|0011 1011|	59|	3B|	;
|0011 1100|	60|	3C|	<
|0011 1101|	61|	3D|	=
|0011 1110|	62|	3E|	>
|0011 1111|	63|	3F|	?
|0100 0000|	64|	40	|@
|0100 0001|	65|	41	|A
|0100 0010|	66|	42	|B
|0100 0011|	67|	43	|C
|0100 0100|	68|	44	|D
|0100 0101|	69|	45	|E
|0100 0110|	70|	46	|F
|0100 0111|	71|	47	|G
|0100 1000|	72|	48	|H
|0100 1001|	73|	49	|I
|0100 1010|	74|	4A	|J
|0100 1011|	75|	4B	|K
|0100 1100|	76|	4C	|L
|0100 1101|	77|	4D	|M
|0100 1110|	78|   4E	|N
|0100 1111|	79|	4F|	O
|0101 0000|	80|	50	|P
|0101 0001|	81|	51	|Q
|0101 0010|	82|	52	|R
|0101 0011|	83|	53	|S
|0101 0100|	84|	54	|T
|0101 0101|	85|	55	|U
|0101 0110|	86|	56	|V
|0101 0111|	87|	57	|W
|0101 1000|	88|	58	|X
|0101 1001|	89|	59	|Y
|0101 1010|	90|	5A	|Z
|0101 1011|	91|	5B	|[
|0101 1100|	92|	5C	|\
|0101 1101|	93|	5D	|]
|0101 1110|	94|	5E	|^
|0101 1111|	95|	5F	|_
|0110 0000|	96|	60	|`
|0110 0001|	97|	61	|a
|0110 0010|	98|	62	|b
|0110 0011|	99|	63	|c
|0110 0100|	100|	64	|d
|0110 0101|	101| 65	|e
|0110 0110|	102|	66	|f
|0110 0111|	103|	67	|g
|0110 1000|	104|	68	|h
|0110 1001|	105|	69	|i
|0110 1010|	106|	6A	|j
|0110 1011|	107|	6B	|k
|0110 1100|	108|	6C	|l
|0110 1101|	109|	6D	|m
|0110 1110|	110|	6E	|n
|0110 1111|	111|	6F	|o
|0111 0000|	112|	70	|p
|0111 0001|	113|	71	|q
|0111 0010|	114|	72	|r
|0111 0011|	115|	73	|s
|0111 0100|	116|	74	|t
|0111 0101|	117|	75	|u
|0111 0110|	118|	76	|v
|0111 0111|	119|	77	|w
|0111 1000|	120|	78	|x
|0111 1001|	121|	79	|y
|0111 1010|	122|	7A	|z
|0111 1011|	123|	7B	|{
|0111 1100|	124|	7C	|\|
|0111 1101|	125|	7D	|}
|0111 1110|	126|	7E	|~

## 1.2. 操作系统

计算机系统由软件和硬件组成,硬件是计算机系统的基础,操作系统是位于硬件上的第一层软件,用于控制管理各种硬件资源.为其他软件和用户提供了工作环境.操作系统为人们有效的使用计算机提供了用户接口.操作系统还要对系统资源进行统一管理,使各并发进程能改按照一定的原则合理共享计算机资源,并在保证各个并发进程顺利运行的基础上提高资源的利用率,操作系统是整个计算机的控制管理中心.

### 1.2.1. 操作系统基本概念

#### 1.2.1.1. 操作系统的功能

**1.提供人机接口**
* 作业控制级接口
* 程序级接口

**管理计算机资源**
* 进程管理
    * 进程调度
    * 进程通信
    * 进程控制
    * 进程同步
* 存储管理
    * 内存分配
    * 地址转换
    * 内存保护
    * 内存扩充
* 设备管理
    * 设备分配
    * 缓冲管理
    * 设备驱动
    * 设备独立性
* 文件管理
    * 文件存储空间的管理
    * 目录管理
    * 文件操作
    * 文件的存取和权限管理
    

#### 1.2.1.2. 操作系统发展过程

* 无操作系统的计算机
* 单道批处理系统
* 分时系统
* 实时系统

#### 1.2.1.3. 操作系统的特性

* 程序并发运行
    * 宏观上多道程序同时运行,微观上交替运行,如果有多个CPU,可以实现并行
    * 提高资源利用率和系统吞吐量
    * 由操作系统实现并发的管理
* 资源共享
    * 共享的理由
        * 各用户或任务独占系统资源将导致资源浪费
        * 多个任务共享一个程序的同一个副本
* 异步
* 虚拟
    * 虚拟指的是通过某种技术把一个物理实体映射为多个逻辑实体,用户程序使用的是逻辑实体
    * 比如虚拟内存,docker的应用

#### 1.2.1.4. 操作系统的体系结构

##### 1.2.1.4.1. 层次结构

##### 1.2.1.4.2. 微内核结构



##### 1.2.1.4.3. 基本特性

### 1.2.2. Linux进程和线程的区别
进程与线程的区别，早已经成为了经典问题。自线程概念诞生起，关于这个问题的讨论就没有停止过。无论是初级程序员，还是资深专家，都应该考虑过这个问题，只是层次角度不同罢了。一般程序员而言，搞清楚二者的概念，在工作实际中去运用成为了焦点。而资深工程师则在考虑系统层面如何实现两种技术及其各自的性能和实现代价。以至于到今天，Linux内核还在持续更新完善(关于进程和线程的实现模块也是内核完善的任务之一)。

本文将以一个从事Linux平台系统开发的程序员角度描述这个经典问题。本文素材全部来源于工作实践经验与知识规整，若有疏漏或不正之处，敬请读者慷慨指出。



0.首先，简要了解一下进程和线程。对于操作系统而言，进程是核心之核心，整个现代操作系统的根本，就是以进程为单位在执行任务。系统的管理架构也是基于进程层面的。在按下电源键之后，计算机就开始了复杂的启动过程，此处有一个经典问题：当按下电源键之后，计算机如何把自己由静止启动起来的？本文不讨论系统启动过程，请读者自行科普。操作系统启动的过程简直可以描述为上帝创造万物的过程，期初没有世界，但是有上帝，是上帝创造了世界，之后创造了万物，然后再创造了人，然后塑造了人的七情六欲，再然后人类社会开始遵循自然规律繁衍生息。。。操作系统启动进程的阶段就相当于上帝造人的阶段。本文讨论的全部内容都是“上帝造人”之后的事情。第一个被创造出来的进程是0号进程，这个进程在操作系统层面是不可见的，但它存在着。0号进程完成了操作系统的功能加载与初期设定，然后它创造了1号进程(init)，这个1号进程就是操作系统的“耶稣”。1号进程是上帝派来管理整个操作系统的，所以在用pstree查看进程树可知，1号进程位于树根。再之后，系统的很多管理程序都以进程身份被1号进程创造出来，还创造了与人类沟通的桥梁——shell。从那之后，人类可以跟操作系统进行交流，可以编写程序，可以执行任务。。。

而这一切，都是基于进程的。每一个任务(进程)被创建时，系统会为他分配存储空间等必要资源，然后在内核管理区为该进程创建管理节点，以便后来控制和调度该任务的执行。

进程真正进入执行阶段，还需要获得CPU的使用权，这一切都是操作系统掌管着，也就是所谓的调度，在各种条件满足(资源与CPU使用权均获得)的情况下，启动进程的执行过程。

除CPU而外，一个很重要的资源就是存储器了，系统会为每个进程分配独有的存储空间，当然包括它特别需要的别的资源，比如写入时外部设备是可使用状态等等。有了上面的引入，我们可以对进程做一个简要的总结：

进程，是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。它的执行需要系统分配资源创建实体之后，才能进行。

随着技术发展，在执行一些细小任务时，本身无需分配单独资源时(多个任务共享同一组资源即可，比如所有子进程共享父进程的资源)，进程的实现机制依然会繁琐的将资源分割，这样造成浪费，而且还消耗时间。后来就有了专门的多任务技术被创造出来——线程。

线程的特点就是在不需要独立资源的情况下就可以运行。如此一来会极大节省资源开销，以及处理时间。

 

1.好了，前面的一段文字是简要引入两个名词，即进程和线程。本文讨论目标是解释清楚进程和线程的区别，关于二者的技术实现，请读者查阅相关资料。

下面我们开始重点讨论本文核心了。从下面几个方面阐述进程和线程的区别。

1).二者的相同点

2).实现方式的差异

3).多任务程序设计模式的区别

4).实体间(进程间，线程间，进线程间)通信方式的不同

5).控制方式的异同

6).资源管理方式的异同

7).个体间辈分关系的迥异

8).进程池与线程池的技术实现差别

 

接下来我们就逐个进行解释。

1).二者的相同点

无论是进程还是线程，对于程序员而言，都是用来实现多任务并发的技术手段。二者都可以独立调度，因此在多任务环境下，功能上并无差异。并且二者都具有各自的实体，是系统独立管理的对象个体。所以在系统层面，都可以通过技术手段实现二者的控制。而且二者所具有的状态都非常相似。而且，在多任务程序中，子进程(子线程)的调度一般与父进程(父线程)平等竞争。

其实在Linux内核2.4版以前，线程的实现和管理方式就是完全按照进程方式实现的。在2.6版内核以后才有了单独的线程实现。

 

 

2).实现方式的差异

进程是资源分配的基本单位，线程是调度的基本单位。

这句经典名言已流传数十年，各种操作系统教材都可见此描述。确实如此，这就是二者的显著区别。读者请注意“基本”二字。相信有读者看到前半句的时候就在心里思考，“进程岂不是不能调度？”，非也！进程和线程都可以被调度，否则多进程程序该如何运行呢！

只是，线程是更小的可以调度的单位，也就是说，只要达到线程的水平就可以被调度了，进程自然可以被调度。它强调的是分配资源时的对象必须是进程，不会给一个线程单独分配系统管理的资源。若要运行一个任务，想要获得资源，最起码得有进程，其他子任务可以以线程身份运行，资源共享就行了。

    简而言之，进程的个体间是完全独立的，而线程间是彼此依存的。多进程环境中，任何一个进程的终止，不会影响到其他进程。而多线程环境中，父线程终止，全部子线程被迫终止(没有了资源)。而任何一个子线程终止一般不会影响其他线程，除非子线程执行了exit()系统调用。任何一个子线程执行exit()，全部线程同时灭亡。

其实，也没有人写出只有线程而没有进程的程序。多线程程序中至少有一个主线程，而这个主线程其实就是有main函数的进程。它是整个程序的进程，所有线程都是它的子线程。我们通常把具有多线程的主进程称之为主线程。

从系统实现角度讲，进程的实现是调用fork系统调用：

pid_t fork(void);

线程的实现是调用clone系统调用：

int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...

/* pid_t *ptid, struct user_desc *tls, pid_t *ctid */

);

其中，fork()是将父进程的全部资源复制给了子进程。而线程的clone只是复制了一小部分必要的资源。在调用clone时可以通过参数控制要复制的对象。可以说，fork实现的是clone的加强完整版。当然，后来操作系统还进一步优化fork实现——写时复制技术。在子进程需要复制资源(比如子进程执行写入动作更改父进程内存空间)时才复制，否则创建子进程时先不复制。

实际中，编写多进程程序时采用fork创建子进程实体。而创建线程时并不采用clone系统调用，而是采用线程库函数。常用线程库有Linux-Native线程库和POSIX线程库。其中应用最为广泛的是POSIX线程库。因此读者在多线程程序中看到的是pthread_create而非clone。

我们知道，库是建立在操作系统层面上的功能集合，因而它的功能都是操作系统提供的。由此可知，线程库的内部很可能实现了clone的调用。不管是进程还是线程的实体，都是操作系统上运行的实体。

    最后，我们说一下vfork() 。这也是一个系统调用，用来创建一个新的进程。它创建的进程并不复制父进程的资源空间，而是共享，也就说实际上vfork实现的是一个接近线程的实体，只是以进程方式来管理它。并且，vfork()的子进程与父进程的运行时间是确定的：子进程“结束”后父进程才运行。请读者注意“结束”二字。并非子进程完成退出之意，而是子进程返回时。一般采用vfork()的子进程，都会紧接着执行execv启动一个全新的进程，该进程的进程空间与父进程完全独立不相干，所以不需要复制父进程资源空间。此时，execv返回时父进程就认为子进程“结束”了，自己开始运行。实际上子进程继续在一个完全独立的空间运行着。举个例子，比如在一个聊天程序中，弹出了一个视频播放器。你说视频播放器要继承你的聊天程序的进程空间的资源干嘛？莫非视频播放器想要窥探你的聊天隐私不成？懂了吧！

 

3).多任务程序设计模式的区别

由于进程间是独立的，所以在设计多进程程序时，需要做到资源独立管理时就有了天然优势，而线程就显得麻烦多了。比如多任务的TCP程序的服务端，父进程执行accept()一个客户端连接请求之后会返回一个新建立的连接的描述符DES，此时如果fork()一个子进程，将DES带入到子进程空间去处理该连接的请求，父进程继续accept等待别的客户端连接请求，这样设计非常简练，而且父进程可以用同一变量(val)保存accept()的返回值，因为子进程会复制val到自己空间，父进程再覆盖此前的值不影响子进程工作。但是如果换成多线程，父线程就不能复用一个变量val多次执行accept()了。因为子线程没有复制val的存储空间，而是使用父线程的，如果子线程在读取val时父线程接受了另一个客户端请求覆盖了该值，则子线程无法继续处理上一次的连接任务了。改进的办法是子线程立马复制val的值在自己的栈区，但父线程必须保证子线程复制动作完成之后再执行新的accept()。但这执行起来并不简单，因为子线程与父线程的调度是独立的，父线程无法知道子线程何时复制完毕。这又得发生线程间通信，子线程复制完成后主动通知父线程。这样一来父线程的处理动作必然不能连贯，比起多进程环境，父线程显得效率有所下降。

PS：这里引述一个知名的面试问题：多进程的TCP服务端，能否互换fork()与accept()的位置？请读者自行思考。

关于资源不独立，看似是个缺点，但在有的情况下就成了优点。多进程环境间完全独立，要实现通信的话就得采用进程间的通信方式，它们通常都是耗时间的。而线程则不用任何手段数据就是共享的。当然多个子线程在同时执行写入操作时需要实现互斥，否则数据就写“脏”了。

 

4).实体间(进程间，线程间，进线程间)通信方式的不同

进程间的通信方式有这样几种：

A.共享内存    B.消息队列    C.信号量    D.有名管道    E.无名管道    F.信号

G.文件        H.socket

线程间的通信方式上述进程间的方式都可沿用，且还有自己独特的几种：

A.互斥量      B.自旋锁      C.条件变量  D.读写锁      E.线程信号

G.全局变量

值得注意的是，线程间通信用的信号不能采用进程间的信号，因为信号是基于进程为单位的，而线程是共属于同一进程空间的。故而要采用线程信号。

综上，进程间通信手段有8种。线程间通信手段有13种。

而且，进程间采用的通信方式要么需要切换内核上下文，要么要与外设访问(有名管道，文件)。所以速度会比较慢。而线程采用自己特有的通信方式的话，基本都在自己的进程空间内完成，不存在切换，所以通信速度会较快。也就是说，进程间与线程间分别采用的通信方式，除了种类的区别外，还有速度上的区别。

另外，进程与线程之间穿插通信的方式，除信号以外其他进程间通信方式都可采用。
    线程有内核态线程与用户级线程，相关知识请参看我的另一篇博文《Linux线程的实质》。

 

5).控制方式的异同

进程与线程的身份标示ID管理方式不一样，进程的ID为pid_t类型，实际为一个int型的变量(也就是说是有限的)：

/usr/include/unistd.h:260:typedef __pid_t   pid_t;

/usr/include/bits/types.h:126:# define __STD_TYPE    typedef

/usr/include/bits/types.h:142:__STD_TYPE  __PID_T_TYPE   __pid_t;

/usr/include/bits/typesizes.h:53:#define __PID_T_TYPE   __S32_TYPE

/usr/include/bits/types.h:100:#define   __S32_TYPE      int

在全系统中，进程ID是唯一标识，对于进程的管理都是通过PID来实现的。每创建一个进程，内核去中就会创建一个结构体来存储该进程的全部信息：

注：下述代码来自 Linux内核3.18.1

 

include/linux/sched.h:1235:struct task_struct {

        volatile long state;    /* -1 unrunnable, 0 runnable, >0 stopped */

        void *stack;

...

        pid_t pid;

        pid_t tgid;

...

};

每一个存储进程信息的节点也都保存着自己的PID。需要管理该进程时就通过这个ID来实现(比如发送信号)。当子进程结束要回收时(子进程调用exit()退出或代码执行完)，需要通过wait()系统调用来进行，未回收的消亡进程会成为僵尸进程，其进程实体已经不复存在，但会虚占PID资源，因此回收是有必要的。

线程的ID是一个long型变量：

/usr/include/bits/pthreadtypes.h:60:typedef unsigned long int pthread_t;

它的范围大得多，管理方式也不一样。线程ID一般在本进程空间内作用就可以了，当然系统在管理线程时也需要记录其信息。其方式是，在内核创建一个内核态线程与之对应，也就是说每一个用户创建的线程都有一个内核态线程对应。但这种对应关系不是一对一，而是多对一的关系，也就是一个内核态线程可以对应着多个用户级线程。还是请读者参看《Linux线程的实质》普及相关概念。此处贴出blog地址：

http://my.oschina.net/cnyinlinux/blog/367910

对于线程而言，若要主动终止需要调用pthread_exit() ，主线程需要调用pthread_join()来回收(前提是该线程没有被detached，相关概念请查阅线程的“分离属性”)。像线发送线程信号也是通过线程ID实现的。

 

6).资源管理方式的异同

进程本身是资源分配的基本单位，因而它的资源都是独立的，如果有多进程间的共享资源，就要用到进程间的通信方式了，比如共享内存。共享数据就放在共享内存去，大家都可以访问，为保证数据写入的安全，加上信号量一同使用。一般而言，共享内存都是和信号量一起使用。消息队列则不同，由于消息的收发是原子操作，因而自动实现了互斥，单独使用就是安全的。

线程间要使用共享资源不需要用共享内存，直接使用全局变量即可，或者malloc()动态申请内存。显得方便直接。而且互斥使用的是同一进程空间内的互斥量，所以效率上也有优势。

实际中，为了使程序内资源充分规整，也都采用共享内存来存储核心数据。不管进程还是线程，都采用这种方式。原因之一就是，共享内存是脱离进程的资源，如果进程发生意外终止的话，共享内存可以独立存在不会被回收(是否回收由用户编程实现)。进程的空间在进程崩溃的那一刻也被系统回收了。虽然有coredump机制，但也只能是有限的弥补。共享内存在进程down之后还完整保存，这样可以拿来分析程序的故障原因。同时，运行的宝贵数据没有丢失，程序重启之后还能继续处理之前未完成的任务，这也是采用共享内存的又一大好处。

总结之，进程间的通信方式都是脱离于进程本身存在的，是全系统都可见的。这样一来，进程的单点故障并不会损毁数据，当然这不一定全是优点。比如，进程崩溃前对信号量加锁，崩溃后重启，然后再次进入运行状态，此时直接进行加锁，可能造成死锁，程序再也无法继续运转。再比如，共享内存是全系统可见的，如果你的进程资源被他人误读误写，后果肯定也是你不想要的。所以，各有利弊，关键在于程序设计时如何考量，技术上如何规避。这说起来又是编程技巧和经验的事情了。

 

7).个体间辈分关系的迥异

进程的备份关系森严，在父进程没有结束前，所有的子进程都尊从父子关系，也就是说A创建了B，则A与B是父子关系，B又创建了C，则B与C也是父子关系，A与C构成爷孙关系，也就是说C是A的孙子进程。在系统上使用pstree命令打印进程树，可以清晰看到备份关系。

多线程间的关系没有那么严格，不管是父线程还是子线程创建了新的线程，都是共享父线程的资源，所以，都可以说是父线程的子线程，也就是只存在一个父线程，其余线程都是父线程的子线程。

 

8).进程池与线程池的技术实现差别

我们都知道，进程和线程的创建时需要时间的，并且系统所能承受的进程和线程数也是有上限的，这样一来，如果业务在运行中需要动态创建子进程或线程时，系统无法承受不能立即创建的话，必然影响业务。综上，聪明的程序员发明了一种新方法——池。

在程序启动时，就预先创建一些子进程或线程，这样在需要用时直接使唤。这就是老人口中的“多生孩子多种树”。程序才开始运行，没有那么多的服务请求，必然大量的进程或线程空闲，这时候一般让他们“冬眠”，这样不耗资源，要不然一大堆孩子的口食也是个负担啊。对于进程和线程而言，方式是不一样的。另外，当你有了任务，要分配给那些孩子的时候，手段也不一样。下面就分别来解说。
**进程池**
首先创建了一批进程，就得管理，也就是你得分开保存进程ID，可以用数组，也可用链表。建议用数组，这样可以实现常数内找到某个线程，而且既然做了进程池，就预先估计好了生产多少进程合适，一般也不会再动态延展。就算要动态延展，也能预估范围，提前做一个足够大的数组。不为别的，就是为了快速响应。本来错进程池的目的也是为了效率。

接下来就要让闲置进程冬眠了，可以让他们pause()挂起，也可用信号量挂起，还可以用IPC阻塞，方法很多，分析各自优缺点根据实际情况采用就是了。

然后是分配任务了，当你有任务的时候就要让他干活了。唤醒了进程，让它从哪儿开始干呢？肯定得用到进程间通信了，比如信号唤醒它，然后让它在预先指定的地方去读取任务，可以用函数指针来实现，要让它干什么，就在约定的地方设置代码段指针。这也只是告诉了它怎么干，还没说干什么(数据条件)，再通过共享内存把要处理的数据设置好，这也子进程就知道怎么做了。干完之后再来一次进程间通信然后自己继续冬眠，父进程就知道孩子干完了，收割成果。

最后结束时回收子进程，向各进程发送信号唤醒，改变激活状态让其主动结束，然后逐个wait()就可以了。

**线程池**
线程池的思想与上述类似，只是它更为轻量级，所以调度起来不用等待额外的资源。
要让线程阻塞，用条件变量就是了，需要干活的时候父线程改变条件，子线程就被激活。
线程间通信方式就不用赘述了，不用繁琐的通信就能达成，比起进程间效率要高一些。
线程干完之后自己再改变条件，这样父线程也就知道该收割成果了。
整个程序结束时，逐个改变条件并改变激活状态让子线程结束，最后逐个回收即可。

### 1.2.3. Linux各目录及每个目录的详细介绍

/bin 二进制可执行命令

/dev 设备特殊文件
/etc 系统管理和配置文件
/etc/rc.d 启动的配置文件和脚本
/home 用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示
/lib 标准程序设计库，又叫动态链接共享库，作用类似windows里的.dll文件
/sbin 超级管理命令，这里存放的是系统管理员使用的管理程序
/tmp 公共的临时文件存储点
/root 系统管理员的主目录
/mnt 系统提供这个目录是让用户临时挂载其他的文件系统
/lost+found这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里
/proc 虚拟的目录，是系统内存的映射。可直接访问这个目录来获取系统信息。
/var 某些大文件的溢出区，比方说各种服务的日志文件
/usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录，其中包含：

/usr/x11R6 存放x window的目录
/usr/bin 众多的应用程序
/usr/sbin 超级用户的一些管理程序
/usr/doc linux文档
/usr/include linux下开发和编译应用程序所需要的头文件
/usr/lib 常用的动态链接库和软件包的配置文件
/usr/man 帮助文档
/usr/src 源代码，linux内核的源代码就放在/usr/src/linux里
/usr/local/bin 本地增加的命令
/usr/local/lib 本地增加的库根文件系统



## 1.3. 网络TCP
<a href="#menu" style="float:right">目录</a>

### 1.3.1. OSI网路分层



![](https://github.com/lgjlife/Java-Study/pic/tcp/osi.png)

||层|说明||
|---|---|---|---|
|7|应用层|针对特定应用的协议|电子邮件，远程登录，文件传输等。HTTP，DNS，DHCP，SSH，FTP|
|6|表示层|设备固有数据格式和网络标准数据格式的转换|接收不同表现形式的信息，比如文字，图片，声音等|
|5|会话层|通信管理，负责建立连接和断开通信连接，管理传输层以下的分层|何时建立连接，何时断开连接，保持多久的连接|
|4|传输层|管理两个节点之间的可靠传输|TCP，UDP，SCYP，DCCP|
|3|网络层|地址管理和路由选择|如何通过IP地址寻找目标主机，IPV4,IPV6,ARP地址解析协议|
|2|数据链路层|互联设备之间传送和识别数据帧|数据帧和比特位之间的转换|
|1|物理层|数据比特流在实际物理设备上的传输，比如光纤。负责比特流和物理电压之间的转换||
![](https://github.com/lgjlife/Java-Study/blob/master/pic/tcp/send.png?raw=true)
在数据发送时，下层不会改变上层的PDU（消息），只会在上层上添加头部或者尾部信息。
* 分层优点
    * 解耦，每层内部协议改变，不影响其他层。
    * 开发方便，每层负责自己的协议即可。
* 传输方式分类
    * 有连接型
        * 发送数据前，两个通信端必须建立连接的通信链路(TCP)
    * 无连接型
        * 不要求建立和断开连接，发送端任何时候都可以发送数据(UDP)
    * 根据接收端数据分类
        * 单播：一对一通信
        * 多播:一对多通信，组播通信
        * 任播:特定的多台主机中选出一台进行通信
### 1.3.2. IP(Internet Protocol,网际协议)
#### 1.3.2.1. 基本概念
IP协议负责将数据包发送给最终的目标主机。
通信链路层是负责两个直连两个设备之间的通信，而IP是负责两个没有直连设备之间的通信。每个计算机都有自己的IP地址，发送端在发送数据之前要先确定接收者是属于哪台计算机。也就是ARP地址解析协议，通过广播发送请求，有回应的是便是目标主机，然后获取目标主机的网卡地址，缓在发送端，下次发送的时候，就可以从缓存中获取到目标主机的网卡地址。

* IP协议是面向无连接的，通信可靠性由上层解决
    * 一是为了简化
    * 二是为了快速
#### 1.3.2.2. IP地址定义

* IPV4
    * 使用32位来表示，每8位一组，中间使用"."分隔
    * 最大值2的32次方，也就是42.94亿，无法满足全球用户
    * 组成
        * 由网络标识(网络地址)和主机标识(主机地址)组成
        * 192.168.1.10/24
        * "/24"表示从第一位到24位是网络标识，后面的为主机标识
        * 路由器通过比较网络标识决定如何转发
        * 同一个网络标识作为一个网段
    * IPV4地址的分类
        * A类
            * 0开头的地址
            * 第一位到第八都是它的网络标识：0.0.0.0～127.0.0.0
            * A类地址后24位为主机标识，也就是A类网段可以容纳16777214个主机
        * B类
            * "10"开头的地址
            * 1～16位是它的网络标识，128.0.0.1～191.255.0.0是B类的网络地址
            * 后16位是主机标识，所以B类一个网段可以容纳的主机最大为65534
        * C类
            * "110"开头的地址
            * 1~24位是网络标识，192.168.0.0～239.255.255.0
            * 主机标识为后8位，一个网段最大主机数为254个
        * D类
            * "1110"开头的地址
            * 1~32位是它的网络标识，224.0.0.0～239.255.255.255
            * 没有主机标识，常被用于多播
        * IP主机地址不能全部为0或者全闭为1
            * 全部为0表示IP地址或者网络地址不可获知的情况下才使用，因此上面每个都少了两个IP地址。
            * 全部为1通常用作广播地址
    * 广播
        * 广播主机地址全部设置为1
        * 本地广播:本网络内的广播
        * 直接广播:不同网络之间的广播
    * IP多播
        * 广播是将数据发送给网络上的所有计算机，由于不是目标的主机也会收到消息，因此造成通讯效率差。
        * 多播是放送给特定组的主机
        * 应用场景:电视会议中的1对多
        * 多播采用D类地址   

* IPV4首部

||长度(bit)|
|---|---|
|版本 Version|4|
|首部长度 IHL|4|
|区分服务 Type of Service|8|
|总长度 Total Length|32|
|标识 Identification|16|
|标志 Flags|3|
|片偏移 Fragment Offset|29|
|生存时间 Time To Live |8|
|协议 Protocal|8|
|首部校验和 Header CheckSum|32|
|源地址 Source Address |32|
|目标地址 Destination Adress|32|
|可选字段 Options|24|
|填充 Padding|8|
|实际的数据部分Data|~|



* IPV6
    * IPV6地址
        * 长度为128位，16位为1组，中间使用::分隔
        * 二进制表示
            * 10101010:10101010:10101010:10101010:10101010:10101010:10101010:10101010
        * 16进制表示
            * AABB:AABB:AABB:AABB:AABB:AABB:AABB:AABB
        * 省略表示，中间连续多个0的,使用::替换
            * AABB:0:0:0:0:0:0:AABB
            * AABB::AABB
            
||||
|---|---|---|
|未定义|0000...0000（128比特位）|::/128|
|环回地址|0000...0001|::1/128|
|唯一本地地址|1111 110|FC00::/7|
|链路本地单播地址|1111 1110 10|FE8O::/10|
|多播地址|11111111|FF00::/8|
|全局单播地址|其他||

#### 1.3.2.3. IP协议相关技术
##### 1.3.2.3.1. DNS
TCP/IP网络中，每一个互联的设备都有其唯一的IP地址，都可以通过IP地址访问到对方。但是IP地址不便于记忆，因此产生了一种方式，就是给每台计算机赋予唯一的主机名，可以通过主机名访问该主机名对应的IP地址的计算机。在这个背景下，便产生了一个可以有效管理主机名和IP地址之间对应关系的系统，那就是DNS系统。

**域名**:域名是为了识别主机名称和组织机构名称的一种具有分层的名称。比如:www.baidu.com
![](https://github.com/lgjlife/Java-Study/blob/master/pic/tcp/yuming.png?raw=true)
**域名服务器**:域名服务器是指管理域名的主机和相应的软件，它可以管理所在分层的域的相关信息。根部所设置的DNS叫做根域名服务器。他对DNS的检索起着至关重要的作用。根域名服务器注册着根以下第一层域名服务器的IP地址。也就是说上一层注册着下一层的域名服务器的IP地址。根据每个域名服务器所管理的域名，如果下面再没有其他分层，就可以自由的指定主机名称或者子网名称。如果想修改分层的域名名称或者想重新修改域名服务器的IP地址，还必须向其上层的域名服务器进行追加或修改。
由于是分层设计，如果某一台域名服务器宕机，那么针对该域名的查询将会失效，一般设置两台以上域名服务器，以提高容灾能力，第一个查询失败，则转到另一个。

**域名查询**
* 进行DNS查询的主机和软件叫做DNS解析器
* 查询过程

![](https://github.com/lgjlife/Java-Study/blob/master/pic/tcp/dns-search.png?raw=true)
解析器为了查询IP地址，向域名服务器查询，接收这个请求的域名服务器先在自己的数据库中查找，没有查找到则向上一级查找，直至遍历完查找到，查找到则将数据缓存起来，下次使用可以从缓存里面获取。

##### 1.3.2.3.2. ARP
DNS是通过访问名称获取到IP地址，但是有进行访问还需要获取到这个IP地址对应的MAC地址。

* 查找流程:
    * 主机A访问主机B
    * 主机A广播发送一个ARP请求包，这个包包括主机B的IP地址
    * 这个广播包将会被链路上所有的计算机接收并解析
    * 如果请求包中的IP地址和自己的IP地址一致，那么这个节点将会把自己的MAC地址塞入ARP响应包并返回给主机A
    * 主机A获取到主机B的MAC地址，就可以和主机B进行通信了。
    * 主机A会将主机B的MAC地址进行缓存到本地，以供下次使用
    * 这个缓存会按照一定机制被清除，也就是有过期时间。同时若请求失败，也会重新发起获取MAC地址请求。

### 1.3.3. 传输层
<a href="#menu" style="float:right">目录</a>

#### 1.3.3.1. 基本概念

##### 1.3.3.1.1. TCP和UDP差别

 TCP和UDP是传输层的两个具有代表性的传输层协议。TCP提供可靠的通信传输。UDP常被用于广播和细节控制交给应用的通信传输，比如可靠性保证，失败重传等策略由应用实现。
 IP首部字段有一个字段标明传输层使用的是UDP还是TCP或者其他协议。

* TCP
    * 面向连接的，可靠的流协议。流指不间断的数据结构。
    * 在发送数据之前，必须建立连接
    * 提供复杂的功能，比如顺序控制，重发机制，流量控制
    * 应用场景是需要可靠性传输的场景
* UDP
    * 不具有可靠性的数据报协议
    * 不需要建立连接就能发送数据
    * 没有TCP复杂的辅助功能，需要应用自己实现
    * 应用场景是告诉传输和实行性有较高要求的场景，比如广播，IP电话等

* 套接字(Socket)
    * 操作系统提供的网络编程接口

* HTTP或者TCP中常出现的长连接，都是基于TCP来实现，也就是创建TCP连接以后不关闭，一直保持连接状态，下次发送数据的时候就可以不用重新建立连接，毕竟建立TCP连接是很费时的事情，不再通信时再关闭连接。

##### 1.3.3.1.2. 端口
数据链路中的MAC地址: 识别同一链路中的不同计算机
IP中的IP地址:识别TCP/IP网络中互联的主机和路由器
端口号:用于识别同一台计算机中不同的应用程序


端口号的范围万为0-65535之间
（1）公认端口（WellKnownPorts）：从0到1023，它们紧密绑定（binding）于一些服务。通常这些端口的通讯明确表明了某种服务的协议。例如：80端口实际上总是HTTP通讯。
（2）注册端口（RegisteredPorts）：从1024到49151。它们松散地绑定于一些服务。也就是说有许多服务绑定于这些端口，这些端口同样用于许多其它目的。例如：许多系统处理动态端口从1024左右开始。
（3）动态和/或私有端口（Dynamicand/orPrivatePorts）：从49152到65535。理论上，不应为服务分配这些端口。实际上，机器通常从1024起分配动态端口。但也有例外：SUN的RPC端口从32768开始

#### 1.3.3.2. UDP
#### 1.3.3.3. TCP
TCP通信中的四元组:源IP，源端口，目标IP，目标端口

##### 1.3.3.3.1. 连接管理
![](https://github.com/lgjlife/Java-Study/blob/master/pic/tcp/tcp-connect.png?raw=true)
* 三次连接
    * 客户端发送一个SYN报文，并指明自己想要连接的端口号和它的客户端初始序列号(ISN(C))
    * 服务端返回响应报文，并带上它的初始序列号(SYN(S)),ACK为客户端的序列号+1
    * 确认服务器的响应报文，回复Seq和ACK如图

* 四次断开
    * 客户端发送给FIN报文请求关闭 
    * 服务端响应客户端关闭请求
    * 服务端发送FIN报文请求关闭
    * 客户端响应服务端关闭请求

* SYN攻击
在三次握手过程中，服务器发送SYN-ACK之后，收到客户端的ACK之前的TCP连接称为半连接(half-open connect).此时服务器处于Syn_RECV状态.当收到ACK后，服务器转入ESTABLISHED状态.Syn攻击就是 攻击客户端 在短时间内伪造大量不存在的IP地址，向服务器不断地发送syn包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直 至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。Syn攻击是一个典型的DDOS攻击。检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击.在Linux下可以如下命令检测是否被Syn攻击netstat -n -p TCP | grep SYN_RECV一般较新的TCP/IP协议栈都对这一过程进行修正来防范Syn攻击，修改tcp协议实现。主要方法有SynAttackProtect保护机制、SYN cookies技术、增加最大半连接和缩短超时时间等.
但是不能完全防范syn攻击

* 为什么要进行三次握手
    * 假如连接时没有第三次ACK回复。当客户端第一次SYN请求时，由于网络拥堵，客户端检测超时重新发送SYN请求，第二次服务端收到并回复ACK，此时连接建立。后来又收到客户端的第一次请求，服务端以为是新的请求，返回ACK，但是客户端并没有发新的连接请求，所以会忽略服务端的ACK，但是服务端认为这个连接是存在的，其实是一个无效连接，因此会占用服务端的连接资源。
    假如有三次握手，服务端收到客户端的第一次请求并返回ACK之后，即使客户端忽略了该ACK响应，但是服务端超时未收到客户端的ACK将会断开本次连接。

* 为什么需要四次挥手
    * 这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送.

**连接时的11种状态**

|状态|说明|
|---|---|
|CLOSED|初始状态，表示TCP连接是“关闭着的”或“未打开的”。
|LISTEN|表示服务器端的某个SOCKET处于监听状态，可以接受客户端的连接。
|SYN_RCVD |表示服务器接收到了来自客户端请求连接的SYN报文。在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat很难看到这种状态，除非故意写一个监测程序，将三次TCP握手过程中最后一个ACK报文不予发送。当TCP连接处于此状态时，再收到客户端的ACK报文，它就会进入到ESTABLISHED 状态。
|SYN_SENT|这个状态与SYN_RCVD 状态相呼应，当客户端SOCKET执行connect()进行连接时，它首先发送SYN报文，然后随即进入到SYN_SENT 状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT 状态表示客户端已发送SYN报文。
|ESTABLISHED |表示TCP连接已经成功建立。
|FIN_WAIT_1 |这个状态得好好解释一下，其实FIN_WAIT_1 和FIN_WAIT_2 两种状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET进入到FIN_WAIT_1 状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2 状态。当然在实际的正常情况下，无论对方处于任何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1 状态一般是比较难见到的，而FIN_WAIT_2 状态有时仍可以用netstat看到。
|FIN_WAIT_2 |上面已经解释了这种状态的由来，实际上FIN_WAIT_2状态下的SOCKET表示半连接，即有一方调用close()主动要求关闭连接。注意：FIN_WAIT_2 是没有超时的（不像TIME_WAIT 状态），这种状态下如果对方不关闭（不配合完成4次挥手过程），那这个 FIN_WAIT_2 状态将一直保持到系统重启，越来越多的FIN_WAIT_2 状态会导致内核crash。
|TIME_WAIT |表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（这种情况应该就是四次挥手变成三次挥手的那种情况）
|CLOSING |这种状态在实际情况中应该很少见，属于一种比较罕见的例外状态。正常情况下，当一方发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING 状态表示一方发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？那就是当双方几乎在同时close()一个SOCKET的话，就出现了双方同时发送FIN报文的情况，这是就会出现CLOSING 状态，表示双方都正在关闭SOCKET连接。
|CLOSE_WAIT|表示正在等待关闭。怎么理解呢？当对方close()一个SOCKET后发送FIN报文给自己，你的系统毫无疑问地将会回应一个ACK报文给对方，此时TCP连接则进入到CLOSE_WAIT状态。接下来呢，你需要检查自己是否还有数据要发送给对方，如果没有的话，那你也就可以close()这个SOCKET并发送FIN报文给对方，即关闭自己到对方这个方向的连接。有数据的话则看程序的策略，继续发送或丢弃。简单地说，当你处于CLOSE_WAIT 状态下，需要完成的事情是等待你去关闭连接。
|LAST_ACK|当被动关闭的一方在发送FIN报文后，等待对方的ACK报文的时候，就处于LAST_ACK 状态。当收到对方的ACK报文后，也就可以进入到CLOSED 可用状态了。


##### 1.3.3.3.2. 超时重传机制
##### 1.3.3.3.3. 数据流和窗口机制
##### 1.3.3.3.4. 阻塞控制 


## 1.4. 网络HTTP
<a href="#menu" style="float:right">目录</a>


HTTP是应用层协议,无需操心网络通信的具体细节,把联网的细节都交给了通用,可靠的因特网传输协议TCP/IP.

### 1.4.1. 基本概念

#### 1.4.1.1. 访问一个网站的流程
* 输入网址
* DNS域名解析服务解析域名，获取域名对应的服务器IP地址
* 浏览器将端口号(如果有的话)从URL中解析出来
* ARP地址解析协议根据IP查找服务端的MAC地址
* TCP 3次连接流程，客户端和服务端建立连接
* 连接建立之后，客户端发送请求
* 服务端收到请求之后，进行业务处理，根据请求返回客户端的数据。
* 客户端收到服务端响应，渲染页面
* 如果是短连接，客户端将发送关闭连接请求。也就是四次挥手。


#### 1.4.1.2. 资源
<a href="#menu" style="float:right">目录</a>

* 静态资源
    * 文本
    * HTML文件
    * 图片
    * 音频等
* 动态资源
    * 根据请求动态生成的资源
    
##### 1.4.1.2.1. 媒体类型(MIME)

* 因特网上有数千种不同的数据类型，http会给每种要通过web传输的对象都打上一个名为MIME类型（MIME type）的数据格式标签
* web服务器会为所有http对象数据附加一个MIME类型。
* 当web浏览器从服务器中取回一个对象时，会去查看相关的MIME类型，看看他们是否知道如何处理这个对象。
* 大多数浏览器都可以处理数百种常见的对象类型：显示图片文件、解析并格式化html文件等等。
* MIME类型是一种文本标记，表示一种主要的对象类型和一个特定的子类型，中间由一个斜杠来分割。

* 常用的媒体类型(数百个)
    * HTML文档 text/html
    * ASCII文本文档 text/plain
    * JPEG图片 image/jpeg
    * GIF动态图片 image/gif

##### 1.4.1.2.2. URL和资源
<a href="#menu" style="float:right">目录</a>

URI是一类更通用的资源标识符，URL是它的一个子集。URI由两个子集URL和URN构成。URL通过描述资源的位置类标识资源。URN则通过名字来识别。

URI = Universal Resource Identifier 统一资源标志符
URL = Universal Resource Locator 统一资源定位符
URN = Universal Resource Name 统一资源名称

* URL
    * 第一部分就是访问资源所用的协议，比如Http,ftp
    * 第二部分就是资源所在的服务器网站，比如www.baidu.com
    * 第三部分，资源在服务器中的位置，比如 /xxx/xx.pic

目前，基本所有的URI都为URL，URN还在实验阶段。

URL通用格式：
```
<scheme>://<user>:<password>@<host>:port/path;<param>?<query>#<frag>
```
|组件|描述|默认值|
|---|---|---|
|方案|访问资源时的协议|无|
|用户|用户名|匿名|
|密码|访问密码||
|主机|访问资源所在的宿主主机的IP地址|无|
|端口|资源所在应用的端口|无|
|路径|资源在服务器上的访问路径|无|
|参数|参数之间使用(;)分隔||
|查询|查询字符串？a=1234;b=234||
|片段|一小片或者一部分资源的名字，不会将其发送给服务器，仅在客户端内部使用||


#### 1.4.1.3. HTTP报文
<a href="#menu" style="float:right">目录</a>

##### 1.4.1.3.1. 请求报文和响应报文

* 起始行
    * 报文的第一行
    * 在请求报文中说明要做什么
    * 在响应报文中说明出现了什么情况
* 首部字段
    * 起始行后零个或者多个的首部字段
    * 字段包括一个名字和值,中间使用":"隔开,Content-type: text/html
    * 首部以空行作为结尾    
* 主体
    * 实际传输的数据,任意的二进制数据(图片,音频等)或者文本等信息
    
**请求报文格式**
```
<method> <request-url> <version>
<headers>

<entity-body>
```
**响应报文格式**
```
<version> <status> <reason-phrase>
<headers>

<entity-body>
```

**例子**
```
HTTP/2.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry

[page content]

```
* method: 请求方法，GET，POST等
* request-url: 请求资源在服务器内的URL
* version: HTTP版本 ， 格式： http/1.1
* headers：请求头和响应头,格式： Connection: close
* status: 状态码，401/404
* reason-phrase: 原因短语,状态码的简要说明
* body: 实际数据部分，可以承载很多类型的数据，比如图片，音频，视频等

##### 1.4.1.3.2. 首部
HTTP 首部字段根据实际用途被分为以下 4 种类型：
* 通用首部字段（General Header Fields）
  请求报文和响应报文两方都会使用的首部。
* 请求首部字段（Request Header Fields）
从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。
* 响应首部字段（Response Header Fields）
从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。
* 实体首部字段（Entity Header Fields）
针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。

如果首部内容过长，可以分行写，但是前面必须有空格或者制表符。

[首部官方说明：https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html](https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html)
* 通用首部
    * Date：报文创建时间
    * Connection：客户端和服务器连接的有关选项
    * Via：报文经过的中间节点（代理、网关）
    * Cache-control：缓存

* 请求首部
    * From：客户端用户的E-mail地址
    * Host：接受请求的服务器的主机名和端口
    * Referer：当前请求的URL
    * UA-Color：客户端显示器颜色信息
    * UA-OS：客户端操作系统及版本
    * Accept：告诉服务器能够发送的媒体类型
    * Accept-Charset：告诉服务器能够发送的字符集
    * Accept-Encoding：告诉服务器能够发送的编码方式
    * Accept-Language：告诉服务器能够发送的语言
    * Expect：要求服务器的行为
    * If-Match：实体标记与文档当前的标记相匹配，则获取该文档
    * If-Modified-Since：除非在某个指定日期后资源被修改过，否则限制该请求
    * If-None-Match：实体标记与文档当前的标记不匹配，则获取该文档
    * If-Unmodified-Since：除非在某个指定日期后资源没有被修改过，否则限制该请求
    * Authorization：包含客户端提供给服务端，以便进行安全认证的数据
    * Cookie：客户端需要发送的cookie
    * Cookie2：客户端支持的cookie版本

* 响应首部
    * Server：服务器应用软件名称及版本
    * Accept-Range：服务器可以接受的范围类型
    * Set-Cookie：设置cookie

* 实体首部
    * Allow：对该实体可执行的请求方法
    * Location：资源的新地址，重定向中常用到
    * Content-Language：理解主体应该使用的语言
    * Content-Length：主体的长度
    * Content-Encoding：对主体实行的编码方式
    * Content-Range：在整个资源中实体表示的字节范围
    * Content-Type：主体的类型
    * ETag：与实体相关的实体标记
    * Expires：实体不再有效，需要再次获取该实体的时间
    * Last-Modified：实体最后一次被修改的时间
##### 1.4.1.3.3. 方法

* GET
    * 通常用于向服务器请求资源
    * GET请求的参数将会拼接在URL后面，因此如果是密码等参数，会存在安全性问题
    * GET请求的URL有长度限制问题，不是协议本身限制，是浏览器限制，每个浏览器都不同
    * GET 请求可被缓存
    * GET 请求保留在浏览器历史记录中
    * GET 请求可被收藏为书签
    * GET 请求不应在处理敏感数据时使用
    * GET 请求只应当用于取回数据
* POST
    * 向服务器写入数据请求。
    * POST 请求不会被缓存
    * POST 请求不会保留在浏览器历史记录中
    * POST 不能被收藏为书签
    * POST 请求对数据长度没有要求,一般也是web服务器的限制
* HEAD
    * 服务器响应只返回首部，不返回body数据
    * 在不获取资源的情况下了解资源的类型
    * 通过查看状态码，查看资源是否存在
    * 查看首部，测试资源是否被修改

* PUT
    * 向服务器写入数据请求。
* TRACE
    * 用于回环测试
    * 每个请求可能经过网关，代理，防火墙等，测试经过这些之后报文发生了啥变化
    * 最后接收到的服务器将会返回TRACE响应，响应主体为原始请求报文
* OPTIONS
    * 查看资源支持的方法，通过响应头中的Allow: GET,POST
* DELETE
    * 请求删除资源

##### 1.4.1.3.4. 状态码

* 1xx 信息性状态码
    * 100/Continue: 说明收到了请求的初始部分，请客户端继续
    * 101 Switching Protocols ：说明服务器正在根据客户端的指定，将协议切换成Udate首部所列的协议

* 2xx 正常
    * 200 OK,请求正常
    * 201 Created	已创建
    * 202 Accepted	接受
    * 203 Non-Authoritative information	非权威信息
    * 204 NO Content,请求处理成功，但是返回的请求主体中没有内容。
    * 205 Reset Content	重置内容
    * 206 Partial Content	部分内容
* 3xx 重定向
    * 301 Moved Permanenty ,永久重定向，该状态标识请求的资源已经分配新的URL，以后使用新的URI进行访问。Location返回新的URI
    * 302 Found,临时性重定向,该状态标识请求的资源已经分配新的URL，希望用户本次使用新的URI进行访问。
    * 303 See Other,URI已经更新，应使用GET方法使用新的uri获取资源。
    * 304 Not Modified,客户端发送附带条件的请求时(首部：If-match,If-Modified-Sinch,If-None-Match,If-Range,If-Unmodified-Since),服务端允许请求访问资源，但未满足条件的情况，此时响应不包含任何主体。
    * 305 Use Proxy	使用代理
    * 307 Temporary Redirect	临时重发
* 4xx 客户端错误
    * 400 Bad Request,错误的请求，请求报文存在语法错误。
    * 401 Unauthorzied,用户认证失败
    * 402 Payment Required	必需的支付
    * 403 Forbidden,被拒绝访问
    * 404 Not Found ,无法找到资源，可能路径\方法\请求参数有问题
    * 405 Method Not Allowed	方法不被允许
    * 406 Not Acceptable	不可接受的
    * 407 Proxy Authentication Required	需要代理验证 
    * 408 Request Timeout	请求超时
    * 409 Confilict	冲突
    * 410 Gone	不存在
    * 411 Length Required	长度必需
    * 412 Precondition Failed	先决条件失败
    * 413 Request Entity Too Large	请求实体太大
    * 414 Request-URI Too Long	请求URI太长
    * 415 Unsupported Media Type	不支持的媒体类型
    * 416 Requested Range Not Satisfiable	请求范围不被满足
    * 417 Expectation Failed	期望失败
* 5xx 服务器错误
    * 500 Internal Server Error,服务器内部错误，比如抛出异常。
    * 501 Not Implemented	服务端没有实现
    * 502 bad gateway,网关错误
    * 503 Service Unavailable,服务不可用，常见场景是网关正常，但是底下的服务不正常。
    * 504 Gateway Timeout	网关超时
    * 505 HTTP Version Not Supported	HTTP协议版本不支持

#### 1.4.1.4. 连接管理
<a href="#menu" style="float:right">目录</a>

HTTP要传送一条报文时，会以流的形式将报文数据的内容通过一条打开的TCP连接按序传输，TCP收到数据流之后，会将数据流砍成被称作段的小数据块。并将段封装在IP分组中，通过因特网进行传输。

1. HTTP协议与TCP/IP协议的关系

HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。TCP有可靠，面向连接的特点。

2. 如何理解HTTP协议是无状态的

HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。


##### 1.4.1.4.1. 对TCP性能的考虑
HTTP是TCP的上层，主要通信实现由TCP/IP层实现，因此影响性能的主要也是这两层。
影响性能主要以下几点
* 首次访问时的DNS域名解析，可能花费数十秒，后续访问会进行缓存。
* TCP连接建立过程

##### 1.4.1.4.2. 持久连接

在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。

但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：Connection:keep-alive

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

* HTTP1.0方式
    * keep-alive实现 ,keep-Alive 也是首部字段,由服务器响应决定
        * keep-Alive： max=5,timeout=120 
        * max:服务器能接受的最大长连接数
        * timeout: 服务器希望连接在活跃状态的时间
    * 客户端请求时包含头部: Connection: keep-Alive.请求将一条连接保持在打开状态
    * 服务端响应若返回头部: Connection: keep-Alive，则说明支持持久连接，否则将关闭本次连接。
* HTTP1.1方式
    * 默认情况下激活，也就是默认情况下保持长连接
    * 客户端若收到的响应中包含首部信息: Connection: close，将会关闭连接。
    * 客户端和服务端可以随时关闭连接
    * 客户端发送一个请求首部  Connection: close之后将不能在该连接上发送信息。
    * HTTP1.1的代理必须能够分别管理客户端和服务端的持久连接。

###### 1.4.1.4.2.1. TCP连接

当网络通信时采用TCP协议时，在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接 时它们可以释放这个连接，连接的建立是需要三次握手的，而释放则需要4次握手，所以说每个连接的建立都是需要资源消耗和时间消耗的

![经典的三次握手示意图](http://static.codeceo.com/images/2015/08/a25fb124b65178c39c04e428d1913a15.png)

![经典的四次握手关闭图](http://static.codeceo.com/images/2015/08/f05cb2b32b06337cbd4abe7567dcbbcd.png)


**TCP短连接**

我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server 发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起 close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在 client/server间传递一次读写操作

短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段

**TCP长连接**

接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务 器端检测到这种半开放的连接。

如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：
* 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
* 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。
* 客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
* 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。


**长连接短连接操作过程**
* 短连接的操作步骤是：建立连接——数据传输——关闭连接...建立连接——数据传输——关闭连接
* 长连接的操作步骤是：建立连接——数据传输...（保持连接）...数据传输——关闭连接

**长连接和短连接的优点和缺点**

由上可以看出，长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。在长连接的应用场景下，client端一般不会主动关闭它们之间的连接，Client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可 以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。

短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在TCP的建立和关闭操作上浪费时间和带宽。

长连接和短连接的产生在于client和server采取的关闭策略，具体的应用场景采用具体的策略，没有十全十美的选择，只有合适的选择。

**什么时候用长连接，短连接？**

长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好。



#### 1.4.1.5. 版本变化
<a href="#menu" style="float:right">目录</a>


**HTTP 0.9**
 

HTTP 0.9是第一个版本的HTTP协议，已过时。它的组成极其简单，只允许客户端发送GET这一种请求，且不支持请求头。由于没有协议头，造成了HTTP 0.9协议只支持一种内容，即纯文本。不过网页仍然支持用HTML语言格式化，同时无法插入图片。

HTTP 0.9具有典型的无状态性，每个事务独立进行处理，事务结束时就释放这个连接。由此可见，HTTP协议的无状态特点在其第一个版本0.9中已经成型。一次HTTP 0.9的传输首先要建立一个由客户端到Web服务器的TCP连接，由客户端发起一个请求，然后由Web服务器返回页面内容，然后连接会关闭。如果请求的页面不存在，也不会返回任何错误码。

HTTP 0.9协议文档：
http://www.w3.org/Protocols/HTTP/AsImplemented.html

 

**HTTP 1.0**
 

HTTP协议的第二个版本，第一个在通讯中指定版本号的HTTP协议版本，至今仍被广泛采用。相对于HTTP 0.9 增加了如下主要特性：

请求与响应支持头域
响应对象以一个响应状态行开始
响应对象不只限于超文本
开始支持客户端通过POST方法向Web服务器提交数据，支持GET、HEAD、POST方法
支持长连接（但默认还是使用短连接），缓存机制，以及身份认证 

**HTTP 1.1**
 

HTTP协议的第三个版本是HTTP 1.1，是目前使用最广泛的协议版本 。HTTP 1.1是目前主流的HTTP协议版本，因此这里就多花一些笔墨介绍一下HTTP 1.1的特性。

HTTP 1.1引入了许多关键性能优化：keepalive连接，chunked编码传输，字节范围请求，请求流水线等

* Persistent Connection（keepalive连接）
允许HTTP设备在事务处理结束之后将TCP连接保持在打开的状态，一遍未来的HTTP请求重用现在的连接，直到客户端或服务器端决定将其关闭为止。
在HTTP1.0中使用长连接需要添加请求头 Connection: Keep-Alive，而在HTTP 1.1 所有的连接默认都是长连接，除非特殊声明不支持（ HTTP请求报文首部加上Connection: close ）
            

* chunked编码传输
该编码将实体分块传送并逐块标明长度,直到长度为0块表示传输结束, 这在实体长度未知时特别有用(比如由数据库动态产生的数据)

* 字节范围请求
HTTP1.1支持传送内容的一部分。比方说，当客户端已经有内容的一部分，为了节省带宽，可以只向服务器请求一部分。该功能通过在请求消息中引入了range头域来实现，它允许只请求资源的某个部分。在响应消息中Content-Range头域声明了返回的这部分对象的偏移值和长度。如果服务器相应地返回了对象所请求范围的内容，则响应码206（Partial Content）

* Pipelining（请求流水线）
A client that supports persistent connections MAY "pipeline" its requests (i.e., send multiple requests without waiting for each response). A server MUST send its responses to those requests in the same order that the requests were received.（摘自http://www.ietf.org/rfc/rfc2616.txt）

另外，HTTP 1.1还新增了如下特性：
* 请求消息和响应消息都应支持Host头域
* 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。因此，Host头的引入就很有必要了。
* 新增了一批Request method ,HTTP1.1增加了OPTIONS,PUT, DELETE, TRACE, CONNECT方法
* 缓存处理,HTTP/1.1在1.0的基础上加入了一些cache的新特性，引入了实体标签，一般被称为e-tags，新增更为强大的Cache-Control头。 


**HTTP 2.0**

HTTP 2.0是下一代HTTP协议，目前应用还非常少。主要特点有：

* 多路复用（二进制分帧）
HTTP 2.0最大的特点: 不会改动HTTP 的语义，HTTP 方法、状态码、URI 及首部字段，等等这些核心概念上一如往常，却能致力于突破上一代标准的性能限制，改进传输性能，实现低延迟和高吞吐量。而之所以叫2.0，是在于新增的二进制分帧层。在二进制分帧层上， HTTP 2.0 会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。

HTTP 2.0 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据流以消息的形式发送，而消息由一或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。

* 头部压缩
当一个客户端向相同服务器请求许多资源时，像来自同一个网页的图像，将会有大量的请求看上去几乎同样的，这就需要压缩技术对付这种几乎相同的信息。

* 随时复位
HTTP1.1一个缺点是当HTTP信息有一定长度大小数据传输时，你不能方便地随时停止它，中断TCP连接的代价是昂贵的。使用HTTP2的RST_STREAM将能方便停止一个信息传输，启动新的信息，在不中断连接的情况下提高带宽利用效率。
* 服务器端推流: Server Push
客户端请求一个资源X，服务器端判断也许客户端还需要资源Z，在无需事先询问客户端情况下将资源Z推送到客户端，客户端接受到后，可以缓存起来以备后用。
* 优先权和依赖
每个流都有自己的优先级别，会表明哪个流是最重要的，客户端会指定哪个流是最重要的，有一些依赖参数，这样一个流可以依赖另外一个流。优先级别可以在运行时动态改变，当用户滚动页面时，可以告诉浏览器哪个图像是最重要的，你也可以在一组流中进行优先筛选，能够突然抓住重点流。 



### 1.4.2. HTTPS
<a href="#menu" style="float:right">目录</a>


HTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性  。HTTPS 在HTTP 的基础下加入SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。 HTTPS 存在不同于 HTTP 的默认端口及一个加密/身份验证层（在 HTTP与 TCP 之间）。这个系统提供了身份验证与加密通讯方法。现在它被广泛用于万维网上安全敏感的通讯，例如交易支付等方面

![https网络层](https://github.com/lgjlife/Java-Study/blob/master/pic/computer-base/http/https-layer.png?raw=true)
TLS为传输层安全,和SSL非常类似.

简单的讲HTTPS是在HTTP协议的基础上，增加了保密措施的一种协议。所以其主要作用是保证通信的安全，其主要解决了如下几个问题：
* 防止第三方冒充服务器。
* 防止第三方拦截通信报文，窃取通信中请求报文、响应报文的内容。
* 防止第三方拦截通信报文，篡改报文内容。

**三个思考**
* 为什么用了 HTTPS 就是安全的？
* HTTPS 的底层原理如何实现？
* 用了 HTTPS 就一定安全吗？

**目标**
* 服务器认证 (客户端知道它们是在与真正的而不是伪造的服务器通话)；
* 客户端认证 (服务器知道它们是在与真正的而不是伪造的客户端通话)；
* 完整性 (客户端和服务器的数据不会被修改)；
* 加密 (客户端和服务器的对话是私密的，无需担心被窃听)；
* 效率 (一个运行的足够快的算法，以便低端的客户端和服务器使用)；
* 普适性 (基本上所有的客户端和服务器都支持这些协议)；
* 管理的可扩展性 (在任何地方的任何人都可以立即进行安全通信)；
* 适应性 (能够支持当前最知名的安全方法)；
* 在社会上的可行性 (满足社会的政治文化需要)；



#### 1.4.2.1. HTTP协议的缺点以及改进目标
<a href="#menu" style="float:right">目录</a>

HTTP 协议虽然使用极为广泛, 但是却存在不小的安全缺陷, 主要是其数据的明文传送和消息完整性检测的缺乏, 而这两点恰好是网络支付, 网络交易等新兴应用中安全方面最需要关注的 。
关于 HTTP协议的明文数据传输, 攻击者最常用的攻击手法就是网络嗅探, 试图从传输过程当中分析出敏感的数据, 例如管理员对 Web 程序后台的登录过程等等, 从而获取网站管理权限, 进而渗透到整个服务器的权限。即使无法获取到后台登录信息, 攻击者也可以从网络中获取普通用户的隐秘信息, 包括手机号码, 身份证号码, 信用卡号等重要资料, 导致严重的安全事故。进行网络嗅探攻击非常简单, 对攻击者的要求很低。使用网络发布的任意一款抓包工具, 一个新手就有可能获取到大型网站的用户信息  。
另外,HTTP协议在传输客户端请求和服务端响应时, 唯一的数据完整性检验就是在报文头部包含了本次传输数据的长度, 而对内容是否被篡改不作确认。 因此攻击者可以轻易的发动中间人攻击, 修改客户端和服务端传输的数据, 甚至在传输数据中插入恶意代码, 导致客户端被引导至恶意网站被植入木马  。

* 不安全访问的问题
    * 客户端向服务端发起请求 
        * 此时请求报文有可能被截获，泄漏请求信息
        * 请求有可能被截获，并冒充服务器，给其响应
    * 服务端向客户端发起响应 
        * 此时请求报文有可能被截获，泄漏响应信息

**改进目标**
HTTPS 协议是由 HTTP 加上 TLS/SSL 协议构建的可进行加密传输、身份认证的网络协议，主要通过数字证书、加密算法、非对称密钥等技术完成互联网数据传输加密，实现互联网传输安全保护。设计目标主要有三个。
* 数据保密性
    * 保证数据内容在传输的过程中不会被第三方查看。就像快递员传递包裹一样，都进行了封装，别人无法获知里面装了什么   。
* 数据完整性
    * 及时发现被第三方篡改的传输内容。就像快递员虽然不知道包裹里装了什么东西，但他有可能中途掉包，数据完整性就是指如果被掉包，我们能轻松发现并拒收  。
* 身份校验安全性
    * 保证数据到达用户期望的目的地。就像我们邮寄包裹时，虽然是一个封装好的未掉包的包裹，但必须确定这个包裹不会送错地方，通过身份校验来确保送对了地方   。

#### 1.4.2.2. 密码基础
<a href="#menu" style="float:right">目录</a>

* 密码
    * 对文本进行编码的算法
* 密钥
    * 改变密码行为的数字化参数
* 对称密钥加密
    * 编解码都是使用同一个密钥
* 非对称加密
    * 编解码使用不同的密钥
* 数字签名
    * 对报文进行签名,以说明是谁编写的报文,同时证明报文未被篡改过
    * 是附加在报文上的特苏加密校验码
    * 用来验证报文未被伪造或者篡改的校验和
* 数字证书
    * 由一个可信的组织验证和签发的识别信息
    * 证书的只要内容
        * 对象的名称(人,服务器,组织等)
        * 证书发布者(由谁为证书担保)
        * 来自证书发布者的数字签名
        * 有效期
        * 公开密钥
        * 所用签名算法的描述性信息
        * 其他扩展信息
    * 大部分信息都遵循标准格式X509 v3
        * 字段
            * 版本号（integer）
            * 序列号（integer）
            * 签名算法（object）
            * 颁布者（set）
            * 有效期（utc_time）
            * 主体（set）
            * 主体公钥（bit_string）
            * 主体公钥算法（object）
            * 签名值（bit_string）
        * 基于X509 v3证书的签名
            * web服务器证书
            * 客户端电子邮件证书
            * 软件代码签名证书
            * 证书颁发机构证书
* 明文经过编码器编码(加密)之后变成密文,再经过解码器解码(解密)之后恢复成明文.

**用证书对服务器进行认证**
通过HTTPS建立了一个安全Web事务之后，现代的浏览器都会自动获取所连接服务器的数字证书。如果服务器没有证书，安全连接就会失败。服务器证书中包含很多字段，其中包括：Web站点的名称和主机名；Web站点的公开密钥；签名颁发机构的名称；来自签名颁发机构的签名

浏览器收到证书时会对签名颁发机构进行检査。如果这个机构是个很有权威的公共签名机构，浏览器可能已经知道其公开密钥了， 因为浏览器会预先安装很多签名颁发机构的证书。下图中说明了如何通过其数字签名来验证证书的完整性


![浏览器验证证书过程](https://github.com/lgjlife/Java-Study/blob/master/pic/computer-base/http/sign-process.png?raw=true)



如果对签名颁发机构一无所知，浏览器就无法确定是否应该信任这个签名颁发机构，它通常会向用户显示一个对话框，看看他是否相信这个签名发布者。签名发布者可能是本地的IT部门或软件厂商


#### 1.4.2.3. HTTPS协议的改进
<a href="#menu" style="float:right">目录</a>

**双向的身份认证**
* 客户端和服务端在传输数据之前,会通过基于X.509证书对双方进行身份认证 。具体过程如下  :
    * 客户端发起 SSL 握手消息给服务端要求连接。
    * 服务端将证书发送给客户端。
    * 客户端检查服务端证书，确认是否由自己信任的证书签发机构签发。 如果不是，将是否继续通讯的决定权交给用户选择 ( 注意，这里将是一个安全缺陷 )。如果检查无误或者用户选择继续，则客户端认可服务端的身份。
    * 服务端要求客户端发送证书，并检查是否通过验证。失败则关闭连接，认证成功则��客户端证书中获得客户端的公钥，一般为1024位或者 2048位。到此，服务器客户端双方的身份认证结束，双方确保身份都是真实可靠的。

**数据传输的机密性**
客户端和服务端在开始传输数据之前，会协商传输过程需要使用的加密算法。 客户端发送协商请求给服务端, 其中包含自己支持的非对成加密的密钥交换算法 ( 一般是RSA), 数据签名摘要算法 ( 一般是SHA或者MD5) , 加密传输数据的对称加密算法 ( 一般是DES),以及加密密钥的长度。 服务端接收到消息之后，选中安全性最高的算法，并将选中的算法发送给客户端，完成协商。客户端生成随机的字符串，通过协商好的非对称加密算法，使用服务端的公钥对该字符串进行加密，发送给服务端。 服务端接收到之后，使用自己的私钥解密得到该字符串。在随后的数据传输当中，使用这个字符串作为密钥进行对称加密   。

**防止重放攻击**
SSL使用序列号来保护通讯方免受报文重放攻击。这个序列号被加密后作为数据包的负载。在整个SSL握手中,都有一个唯一的随机数来标记SSL握手。 这样防止了攻击者嗅探整个登录过程，获取到加密的登录数据之后，不对数据进行解密, 而直接重传登录数据包的攻击手法。
可以看到，鉴于电子商务等安全上的需求，HTTPS对比HTTP 协议，在安全方面已经取得了极大的增强。总结来说，HTTPS的改进点在于创造性的使用了非对称加密算法，在不安全的网路上，安全的传输了用来进行非对称加密的密钥，综合利用了非对称加密的安全性和对称加密的快速性   。


#### 1.4.2.4. HTTPS实现原理


　HTTPS就是在安全的传输层上发送的HTTP。HTTPS没有将未加密的HTTP报文发送给TCP，并通过世界范围内的因特网进行传输，而是在将HTTP报文发送给TCP之前，先将其发送给了一个安全层，对其进行加密


HTTP安全层是通过SSL及其现代替代协议TLS来实现的。我们遵循常见的用法，用术语SSL来表示SSL或者TLS

　　安全HTTP是可选的。因此，对Web服务器发起请求时，我们需要有一种方式来告知Web服务器去执行HTTP的安全协议版本，这是在URL的方案中实现的。
通常情况下，非安全HTTP的URL方案前缀为http，如下所示：http://, 在安全HTTPS协议中，URL的方案前缀为https，如下所示：https://
　　请求一个客户端(比如Web浏览器)对某Web资源执行某事务时，它会去检査 URL的方案：如果URL的方案为http，客户端就会打开一条到服务器端口80(默认情况下)的连接，并向其发送老的HTTP命令；如果URL的方案为https，客户端就会打开一条到服务器端口443(默认情况下)的连接，然后与服务器“握手”，以二进制格式与服务器交换一些SSL安全参数，附上加密的HTTP命令

SSL是个二进制协议，与HTTP完全不同，其流量是承载在另一个端口上的(SSL通常是由端口443承载的)。如果SSL和HTTP流量都从端口80到达，大部分Web服务器会将二进制SSL流量理解为错误的HTTP并关闭连接。将安全服务进一步整合到HTTP层中去就无需使用多个目的端口了，在实际中这样不会引发严重的问题

　在未加密HTTP中，客户端会打开一条到Web服务器端口80的TCP连接，发送一条请求报文，接收一条响应报文，关闭连接

　　由于SSL安全层的存在，HTTPS中这个过程会略微复杂一些。在HTTPS中，客户端首先打开一条到Web服务器端口443(安全HTTP的默认端口)的连接。一且建立了TCP连接，客户端和服务器就会初始化SSL层，对加密参数进行沟通，并交换密钥。握手完成之后，SSL初始化就完成了，客户端就可以将请求报文发送给安全层了。在将这些报文发送给TCP之前，要先对其进行加密


HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了非对称加密实现。但其实，HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段

* 证书验证阶段
    * 浏览器发起 HTTPS 请求
    * 服务端返回 HTTPS 证书
    * 客户端验证证书是否合法，如果不合法则提示告警
* 数据传输阶段
    * 当证书验证合法后，在本地生成随机数
    * 通过公钥加密随机数，并把加密后的随机数传输到服务端
    * 服务端通过私钥对随机数进行解密
    * 服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输



**HTTPS双向认证过程：**
* 浏览器发送一个连接请求给安全服务器。
* 服务器将自己的证书，以及同证书相关的信息发送给客户浏览器。
* 客户浏览器检查服务器送过来的证书是否是由自己信赖的 CA 中心所签发的。如果是，就继续执行协议；如果不是，客户浏览器就给客户一个警告消息：警告客户这个证书不是可以信赖的，询问客户是否需要继续。
* 接着客户浏览器比较证书里的消息，例如域名和公钥，与服务器刚刚发送的相关消息是否一致，如果是一致的，客户浏览器认可这个服务器的合法身份。
* 服务器要求客户发送客户自己的证书。收到后，服务器验证客户的证书，如果没有通过验证，拒绝连接；如果通过验证，服务器获得用户的公钥。
* 客户浏览器告诉服务器自己所能够支持的通讯对称密码方案。
* 服务器从客户发送过来的密码方案中，选择一种加密程度最高的密码方案，用客户的公钥加过密后通知浏览器。
* 浏览器针对这个密码方案，选择一个通话密钥，接着用服务器的公钥加过密后发送给服务器。
* 服务器接收到浏览器送过来的消息，用自己的私钥解密，获得通话密钥。
* 服务器、浏览器接下来的通讯都是用对称密码方案，对称密钥是加过密的。

**HTTPS单向认证过程：**
* 客户端的浏览器向服务器传送客户端SSL协议的版本号，加密算法的种类，产生的随机数，以及其他服务器和客户端之间通讯所需要的各种信息。
* 服务器向客户端传送SSL协议的版本号，加密算法的种类，随机数以及其他相关信息，同时服务器还将向客户端传送自己的证书。
* 客户利用服务器传过来的信息验证服务器的合法性，服务器的合法性包括：证书是否过期，发行服务器证书的CA是否可靠，发行者证书的公钥能否正确解开服务器证书的"发行者的数字签名"，服务器证书上的域名是否和服务器的实际域名相匹配。如果合法性验证没有通过，通讯将断开;如果合法性验证通过，将继续进行第四步。
* 用户端随机产生一个用于后面通讯的"对称密码"，然后用服务器的公钥(服务器的公钥从步骤②中的服务器的证书中获得)对其加密，然后将加密后的"预主密码"传给服务器。
* 如果服务器要求客户的身份认证(在握手过程中为可选)，用户可以建立一个随机数然后对其进行数据签名，将这个含有签名的随机数和客户自己的证书以及加密过的"预主密码"一起传给服务器。
* 如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性，具体的合法性验证过程包括：客户的证书使用日期是否有效，为客户提供证书的CA是否可靠，发行CA 的公钥能否正确解开客户证书的发行CA的数字签名，检查客户的证书是否在证书废止列表(CRL)中。检验如果没有通过，通讯立刻中断;如果验证通过，服务器将用自己的私钥解开加密的"预主密码 "，然后执行一系列步骤来产生主通讯密码(客户端也将通过同样的方法产生相同的主通讯密码)。
* 服务器和客户端用相同的主密码即"通话密码"，一个对称密钥用于SSL协议的安全数据通讯的加解密通讯。同时在SSL通讯过程中还要完成数据通讯的完整性，防止数据通讯中的任何变化。
* 客户端向服务器端发出信息，指明后面的数据通讯将使用的步骤⑦中的主密码为对称密钥，同时通知服务器客户端的握手过程结束。
* 服务器向客户端发出信息，指明后面的数据通讯将使用的步骤⑦中的主密码为对称密钥，同时通知客户端服务器端的握手过程结束。
* SSL的握手部分结束，SSL安全通道的数据通讯开始，客户和服务器开始使用相同的对称密钥进行数据通讯，同时进行通讯完整性的检验。


**双向认证：**
* 浏览器发送请求给服务器，服务器首先返回证书；
* 浏览器比对服务器返回证书是否由信赖的CA中心签发，以及证书里的消息如：域名和公钥，通过后证明此服务器是安全的目标服务器，此时浏览器得到服务器的公钥；
* 浏览器发送客户端证书给服务器进行验证，通过后建立连接，此时服务器获得客户端的公钥；
* 客户端用各自的公钥、私钥发送对称秘钥，之后的通信就用对称秘钥进行加解密。（公钥和私钥为不对称秘钥，性能开销大于对称秘钥）

**单向认证：**
* 浏览器发送请求给服务器，服务器首先返回证书；
* 浏览器比对服务器返回证书是否由信赖的CA中心签发，以及证书里的消息如：域名和公钥，通过后证明此服务器是安全的目标服务器，此时浏览器得到服务器的公钥；
* 客户端用服务端公钥传送对称秘钥， 后续就用对称秘钥进行加解密再传送数据。

**单向认证和双向认证的区别：**
双向认证则是需要服务端与客户端提供身份认证，只能是服务端允许的客户能去访问，安全性相对于要高一些；
SSL单向认证只要求站点部署了ssl证书就行，任何用户都可以去访问(IP被限制除外等)，只是服务端提供了身份认证；


**加密方式**

为了达到以上的目的，最容易想到的就是加密了。而加密的方式一般情况下可以分为3中形式。
* 对称加密算法：加密、解密用同一个密钥，速度快。
* 非对称加密算法：加密、解密用不同的密钥。公、私钥对。私钥加密的，所有公钥都可以解密，公钥加密的，只有私钥可以解密。
* Hash算法：一种单向加密，理论上不可解密。
那么在HTTPS认证过程中都用到那种加密方式了呢？ 
答案是以上3种均都利用上了。


**通信内容加密**

既然HTTP通信过程中，请求报文、响应报文均可能被窃取，这里只要把request、response加密就可以了。

这个加密用哪种方式呢？
* 对称算法：需要客户端、服务端拿到相同的密钥用来加密、解密，要达到同步必然需要通信。如果说事先在客户端和服务端预安装好这个密钥，则服务端需要管理海量的密钥，显然是不现实的。
* 非对称算法：加密请求报文时，看上去并没有问题，但是在响应时，由于加密是服务器利用私钥加密的，所以所有拥有其公钥的客户端都可以解密，这样就有可能被其他有其公钥客户端窃取报文并进行解密窥探响应信息。并且由于是非对称算法，速度比较慢。
* Hash算法：这个算法不可解密，传过去也没有什么用。
由于非对称算法，所有有公钥的客户端都可以解密响应报文，其不能够被选择，Hash算法更是没有用武之地，所以只剩下对称算法可以考虑，那么怎么解决密钥的同步问题呢？

既然同步密钥也需要通信，那么还是加密呗，但是如果还用对称加密，则变成鸡生蛋、蛋生鸡的问题了。

**给对称算法的密钥加密**

HTTPS是将这个密钥用非对称的算法进行加密（实际上，只是加密了生成这个密钥的一部分原料）。

在服务端保存这个一个密钥。
在所有的客户端保存着服务器的密钥对应的公钥。
这个密钥由客户端生成，用公钥加密，传给服务端，这样只有服务端有密钥可以解密，即使报文被拦截，也无法解密。
这样看上去就没有什么问题了，但是实际情况中，客户端不可能知道所有服务的公钥，只要访问某个https网站的时候，才需要知道这个公钥。所以这个公钥在客户端访问服务端的时候，由服务端发给客户端就可以了。

这时，有人问了，这个公钥不需要加密了么？当然没有必要了，其他客户端只需访问这个网站就会得这些信息，不用拦截其他人这么麻烦，其公钥是颁发给大家的，不需要保密。

最后一个问题，怎么防止第三方冒充目标服务器呢？黑客给你发一个他的公钥，之后的加密全都变得没有意义。

**证书**

服务端为了向客户端证明自己，会给客户端发一个凭证，这里的这个凭证就是证书。其证书不仅用证明服务其身份的作用，其本身还必须带有防伪造的能力。

这里一般是服务器向第三方颁发证书的机构申请一个证明自己的证书，利用这个证书证明自己的身份，并且客户端会根据这个颁证的机构的算法去进行防伪验证，看看证书是否伪造，如果不是伪造的，则没有问题。

这个防伪的验证算法是什么呢？

* 颁发证书时，会根据申请方的信息用hash类的加密算法生成摘要信息，客户端也会用这个算法生成摘要，与其进行对比。
* 并对这个摘要进行非对称加密，防止对其篡改
* 将加密后的摘要信息、生成摘要的加密算法、和证书的基本信息放在一起，作为证书颁发给申请方，
* 客户端利用颁证机构的公钥，对其加密后的摘要进行解密。
这里的客户端的公钥是怎么来的呢，由于颁证机构并不多，操作系统里对一些信用良好的机构进行了信任处理，将其公钥事先安装好了。

**认证流程**

* 服务提供者向办证机构申请证书。
* 将证书发布到web服务中
* 客户端向服务端发起申请，并发起一个随机数a。
* 服务端将证书返回客户端证明自己，并发会一个随机数b。
* 客户端根据证书的颁发机构，拿到预装的公钥，对其摘要进行解密
* 客户端根据证书中的摘要算法，进行客户端的摘要计算，并将计算结果和解密后的摘要进行比较
* 如果不一致，说明证书是伪造或被篡改过，立即停止通信
* 如果一致，则生成第三个随机数c，并用a、b、c生成对称加密算法的密钥，并用证书中的公钥（对应服务其的密钥）对c进行加密，然后将c发给服务端
* 服务端用密钥将c解密，并用a、b、c生成对称加密算法的密钥。
* 之后的通信将报文进行签名，并与报文一起进行对称加密（防止他人恶意篡改信息，以试错方式进行密钥的破解，以增加破解难度）



**为什么数据传输是用对称加密？**

* 首先，非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的；
* 另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。

**为什么需要 CA 认证机构颁发证书？**

HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。

首先我们假设不存在认证机构，任何人都可以制作证书，这带来的安全风险便是经典的“中间人攻击”问题。

“中间人攻击”的具体过程如下：
[中间人攻击](https://static.blog.leapmie.com/2019/11/2410496311.png)

* 过程原理：
    * 本地请求被劫持（如DNS劫持等），所有请求均发送到中间人的服务器
    * 中间人服务器返回中间人自己的证书
    * 客户端创建随机数，通过中间人证书的公钥对随机数加密后传送给中间人，然后凭随机数构造对称加密对传输内容进行加密传输
    * 中间人因为拥有客户端的随机数，可以通过对称加密算法进行内容解密
    * 中间人以客户端的请求内容再向正规网站发起请求  
    * 因为中间人与服务器的通信过程是合法的，正规网站通过建立的安全通道返回加密后的数据
    * 中间人凭借与正规网站建立的对称加密算法对内容进行解密
    * 中间人通过与客户端建立的对称加密算法对正规内容返回的数据进行加密传输
    * 客户端通过与中间人建立的对称加密算法对返回结果数据进行解密
    * 由于缺少对证书的验证，所以客户端虽然发起的是 HTTPS 请求，但客户端完全不知道自己的网络已被拦截，传输内容被中间人全部窃取。

**浏览器是如何确保 CA 证书的合法性？**

* 证书包含什么信息？
    * 颁发机构信息
    * 公钥
    * 公司信息
    * 域名
    * 有效期
    * 指纹
* 证书的合法性依据是什么？
    * 首先，权威机构是要有认证的，不是随便一个机构都有资格颁发证书，不然也不叫做权威机构。另外，证书的可信性基于信任制，权威机构需要对其颁发的证书进行信用背书，只要是权威机构生成的证书，我们就认为是合法的。所以权威机构会对申请者的信息进行审核，不同等级的权威机构对审核的要求也不一样，于是证书也分为免费的、便宜的和贵的。
* 浏览器如何验证证书的合法性？
    * 浏览器发起 HTTPS 请求时，服务器会返回网站的 SSL 证书，浏览器需要对证书做以下验证：
        * 验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；
        * 判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；
        * 判断证书是否被篡改。需要与 CA 服务器进行校验；
        * 判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率
    * 以上任意一步都满足的情况下浏览器才认为证书是合法的。

既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？
其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。

**只有认证机构可以生成证书吗？**

如果需要浏览器不提示安全风险，那只能使用认证机构签发的证书。但浏览器通常只是提示安全风险，并不限制网站不能访问，所以从技术上谁都可以生成证书，只要有证书就可以完成网站的 HTTPS 传输。例如早期的 12306 采用的便是手动安装私有证书的形式实现 HTTPS 访问

**本地随机数被窃取怎么办？**

证书验证是采用非对称加密实现，但是传输过程是采用对称加密，而其中对称加密算法中重要的随机数是由本地生成并且存储于本地的，HTTPS 如何保证随机数不会被窃取？

其实 HTTPS 并不包含对随机数的安全保证，HTTPS 保证的只是传输过程安全，而随机数存储于本地，本地的安全属于另一安全范畴，应对的措施有安装杀毒软件、反木马、浏览器升级修复漏洞等。

**用了 HTTPS 会被抓包吗？**

HTTPS 的数据是加密的，常规下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。

但是，正如前文所说，浏览器只会提示安全风险，如果用户授权仍然可以继续访问网站，完成请求。因此，只要客户端是我们自己的终端，我们授权的情况下，便可以组建中间人网络，而抓包工具便是作为中间人的代理。通常 HTTPS 抓包工具的使用方法是会生成一个证书，用户需要手动把证书安装到客户端中，然后终端发起的所有请求通过该证书完成与抓包工具的交互，然后抓包工具再转发请求到服务器，最后把服务器返回的结果在控制台输出后再返回给终端，从而完成整个请求的闭环。

**既然 HTTPS 不能防抓包，那 HTTPS 有什么意义？**

HTTPS 可以防止用户在不知情的情况下通信链路被监听，对于主动授信的抓包操作是不提供防护的，因为这个场景用户是已经对风险知情。要防止被抓包，需要采用应用级的安全防护，例如采用私有的对称加密，同时做好移动端的防反编译加固，防止本地算法被破解。

**总结**

以下用简短的Q&A形式进行全文总结：
Q: HTTPS 为什么安全？
A: 因为 HTTPS 保证了传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。

Q: HTTPS 的传输过程是怎样的？
A: 客户端发起 HTTPS 请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。

Q: 为什么需要证书？
A: 防止”中间人“攻击，同时可以为网站提供身份证明。

Q: 使用 HTTPS 会被抓包吗？
A: 会被抓包，HTTPS 只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。


#### 1.4.2.5. 与HTTP原理区别
<a href="#menu" style="float:right">目录</a>

HTTPS 主要由两部分组成：HTTP + SSL / TLS，也就是在 HTTP 上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过 TLS 进行加密，所以传输的数据都是加密后的数据。

**HTTP 原理**
* 客户端的浏览器首先要通过网络与服务器建立连接，该连接是通过TCP 来完成的，一般 TCP 连接的端口号是80。 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是 MIME 信息包括请求修饰符、客户机信息和许可内容   。
* 服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是 MIME 信息包括服务器信息、实体信息和可能的内容  。
HTTPS 原理
* 客户端将它所支持的算法列表和一个用作产生密钥的随机数发送给服务器   ；
* 服务器从算法列表中选择一种加密算法，并将它和一份包含服务器公用密钥的证书发送给客户端；该证书还包含了用于认证目的的服务器标识，服务器同时还提供了一个用作产生密钥的随机数   ；
* 客户端对服务器的证书进行验证（有关验证证书，可以参考数字签名），并抽取服务器的公用密钥；然后，再产生一个称作 pre_master_secret 的随机密码串，并使用服务器的公用密钥对其进行加密（参考非对称加 / 解密），并将加密后的信息发送给服务器   ；
* 客户端与服务器端根据 pre_master_secret 以及客户端与服务器的随机数值独立计算出加密和 MAC密钥（参考 DH密钥交换算法）   ；
* 客户端将所有握手消息的 MAC 值发送给服务器  ；
* 服务器将所有握手消息的 MAC 值发送给客户端  。

#### 1.4.2.6. 优缺点
<a href="#menu" style="float:right">目录</a>

* 优点
    * 使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器   ；
    * HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性   。
    * HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本   。
* 缺点
    * 相同网络环境下，HTTPS 协议会使页面的加载时间延长近 50%，增加 10%到 20%的耗电。此外，HTTPS 协议还会影响缓存，增加数据开销和功耗  。
    * HTTPS 协议的安全是有范围的，在黑客攻击、拒绝服务攻击和服务器劫持等方面几乎起不到什么作用   。
    * 最关键的是，SSL 证书的信用链体系并不安全。特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行  。
    * 成本增加。部署 HTTPS 后，因为 HTTPS 协议的工作要增加额外的计算资源消耗，例如 SSL 协议加密算法和 SSL 交互次数将占用一定的计算资源和服务器成本。在大规模用户访问应用的场景下，服务器需要频繁地做加密和解密操作，几乎每一个字节都需要做加解密，这就产生了服务器成本。随着云计算技术的发展，数据中心部署的服务器使用成本在规模增加后逐步下降，相对于用户访问的安全提升，其投入成本已经下降到可接受程度。

### 1.4.3. HTTP结构

#### 1.4.3.1. WEB服务器
<a href="#menu" style="float:right">目录</a>

#### 1.4.3.2. 代理
<a href="#menu" style="float:right">目录</a>

#### 1.4.3.3. 缓存
<a href="#menu" style="float:right">目录</a>

#### 1.4.3.4. 网关 
<a href="#menu" style="float:right">目录</a>

### 1.4.4. 识别,认证与安全

#### 1.4.4.1. 客户端识别与Cookie机制
<a href="#menu" style="float:right">目录</a>

HTTP是无状态的协议,也就是说WEB服务器不能判定当前发出请求的是哪个客户端发出的.

**可以使用的用户识别机制**

* 承载用户身份信息的HTTP首部
    * From : 用户的email地址
    * User-Agent: 用户的浏览器软件
    * Referer: 用户是从这个页面上的链接跳转
    * Authorization: 用户名和密码
    * Client-IP: 客户端的IP地址
    * X-Forward-For: 客户端的IP地址
    * Cookie: 服务器产生的ID标签
* 客户端IP地址
    * 问题
        * 客户端IP地址描述的是机器的IP.如果同一个用户不同的机器就无法区分
        * 有些IP地址是动态分配的
        * 防火墙转换IP
        * 通过代理访问,IP发生改变,服务端看到的是代理的IP地址
* 用户登录,用认证的方式来识别用户
* 胖URL,一种在url中嵌入识别信息的技术

##### 1.4.4.1.1. Cookie


* Cokie类型
    * 会话Cookie
        * 存储在内存中,关闭浏览器会消失
    * 持久Cookie
        * 存储在硬盘中,重启时数据仍然存在

* Cookie是由服务器生成,添加到请求的响应中.响应头部的首部字段Set-Cookie或者Set-Cookie(扩展).

请求中添加两个cookie
```java
@RequestMapping("/main")
public String main(){

    response.setStatus(401);
    response.setHeader("WWW-Authentication","");

    Cookie cookie = new Cookie("my-key","my-value");
    cookie.setMaxAge(100);
    cookie.setComment("test");
    cookie.setDomain("domain");
    cookie.setHttpOnly(true);
    cookie.setPath("/aa");
    cookie.setSecure(true);
    cookie.setVersion(1);
    
    Cookie cookie1 = new Cookie("my-key1","my-value1");
    cookie1.setMaxAge(100);
    cookie1.setComment("test");

    
    response.addCookie(cookie);
    response.addCookie(cookie1);
    return "main";
}
```
响应头部

```yml
HTTP/1.1 401 
WWW-Authentication: 
Set-Cookie: my-key=my-value; Max-Age=100; Expires=Mon, 02-Dec-2019 18:52:57 GMT; Domain=domain; Path=/aa; Secure; HttpOnly
Set-Cookie: my-key1=my-value1; Max-Age=100; Expires=Mon, 02-Dec-2019 19:21:44 GMT

Content-Type: text/html;charset=UTF-8
Content-Language: en-US
Content-Length: 135
Date: Mon, 02 Dec 2019 18:51:17 GMT

```
浏览器会记住从服务器返回的Set-Cookie或Set-Cookie2首部中的cookie内容,当再次访问该站点(主域名)时,将会携带该cookie信息返回给服务器.

这里的cookie是不可跨域的,因此一个域名的cookie不会传到其他域名的服务器.

**cookie属性**
* name　　
    * 为一个cookie的名称。
* value　　
    * 为一个cookie的值。
* expires属性
    * 指定了cookie的生存期，默认情况下cookie是暂时存在的，他们存储的值只在浏览器会话期间存在，当用户退出浏览器后这些值也会丢失，如果想让cookie存在一段时间，就要为expires属性设置为未来的一个用毫秒数表示的过期日期或时间点，expires默认为设置的expires的当前时间。现在已经被max-age属性所取代，max-age用秒来设置cookie的生存期。
    * 如果max-age属性为正数，则表示该cookie会在max-age秒之后自动失效。浏览器会将max-age为正数的cookie持久化，即写到对应的cookie文件中。无论客户关闭了浏览器还是电脑，只要还在max-age秒之前，登录网站时该cookie仍然有效。
    * 如果max-age为负数，则表示该cookie仅在本浏览器窗口以及本窗口打开的子窗口内有效，关闭窗口后该cookie即失效。max-age为负数的Cookie，为临时性cookie，不会被持久化，不会被写到cookie文件中。cookie信息保存在浏览器内存中，因此关闭浏览器该cookie就消失了。cookie默认的max-age值为-1。
    * ‍如果max-age为0，则表示删除该cookie。cookie机制没有提供删除cookie的方法，因此通过设置该cookie即时失效实现删除cookie的效果。失效的Cookie会被浏览器从cookie文件或者内存中删除。
    * 如果不设置expires或者max-age这个cookie默认是Session的，也就是关闭浏览器该cookie就消失了。
    * 这里要说明一下：Session的cookie在ie6下，如果用户实在网页上跳转打开页面或新开窗口（包括target="_blank"，鼠标右键新开窗口），都是在同一个Session内。如果用户新开浏览器程序或者说是进程再打开当前的页面就不是同一个Session。其他浏览器只要你Session存在，还是同一个Session，cookie还能共享。在前段时间的项目中ie6下吃了很大一个亏。
* domain属性
    * domain属性可以使多个web服务器共享cookie。domain属性的默认值是创建cookie的网页所在服务器的主机名。不能将一个cookie的域设置成服务器所在的域之外的域。
    * 例如让位于a.sodao.com的服务器能够读取b.sodao.com设置的cookie值。如果b.sodao.com的页面创建的cookie把它的path属性设置为"/"，把domain属性设置成".sodao.com"，那么所有位于b.sodao.com的网页和所有位于a.sodao.com的网页，以及位于sodao.com域的其他服务器上的网页都可以访问这个cookie。
* path属性
    * 它指定与cookie关联在一起的网页。在默认的情况下cookie会与创建它的网页，该网页处于同一目录下的网页以及与这个网页所在目录下的子目录下的网页关联
* secure属性
    * 它是一个布尔值，指定在网络上如何传输cookie，默认是不安全的，通过一个普通的http连接传输；
* HttpOnly属性
    * HttpOnly 属性限制了 cookie 对 HTTP 请求的作用范围。特别的，该属性指示用户代理忽略那些通过"非 HTTP" 方式对 cookie 的访问（比如浏览器暴露给js的接口）。注意 HttpOnly 属性和 Secure 属性相互独立：一个 cookie 既可以是 HttpOnly 的也可以有 Secure 属性。

**其他信息**

* cookie的传输
    * 浏览器将cookie信息以name-value对的形式存储于本地，每当请求新文档时，浏览器将发送Cookie，目的是让Server可以通过HTTP请求追踪客户。所以从WEB性能的角度来说我们要尽量的减小cookie，以达到传输性能的最大化。
* cookie的编码和解码
    * 由于cookie的名/值中的值不允许包含分号，逗号和空格符，为了最大化用户代理和服务器的兼容性，任何被存储为 cookie 值的数据都应该被编码，例如用我们前端熟知的js全局函数encodeURIComponent编码和decodeURIComponent解码。
* cookie作为客户端存储
    * 前面说了每当请求新文档时，浏览器将发送Cookie到服务器，导致WEB性能下降。所以不建议将cookie作为客户端存储一种实现方案，替代方案参见：JavaScript本地存储实践（html5的localStorage和ie的userData）等。
* 同名的 cookie
    * 同名的 cookie，不同的 domain 或不同的 path，属不同的 cookie；同名的 cookie，相同的 domain 且相同的 path，不同的 expires，属同一个 cookie。

**提高cookie安全性的几种方式**

cookie存储在浏览器端（用户本地），一些别有用心的人能够通过浏览器截获cookie（脚本、利用工具抓取等）。

* cookie不安全的表现形式
    * cookie欺骗    
        * 但这时就会去考虑了，既然如此，为何不加密呢？加密后就算拿到cookie不是也没有用么？关键问题就在这里了，一些别有用心的人不需要知道这个cookie的具体含义，只需要将这个cookie向服务器提交（模拟身份验证），身份验证通过之后，就可以冒充被窃取cookie对应用户来访问网站，甚至获取到用户的隐私信息，对于用户的隐私造成非常严重的危害，这种方式就叫做cookie欺骗。
    * cookie截获
        * cookie以纯文本的形式在浏览器和服务器之间传递，在web通信时极容易被非法用户截获和利用。非法用户截获cookie后，在cookie的有效时间内重新发放给服务器，那么这个非法用户就拥有了这个合法用户的所有权限。
    * Flash的内部代码隐患
        * Flash中有一个getURL()函数，Flash利用它自动打开指定的页面。那么这个就意味着，你在观看Flash动画时，在Flash的内部可以悄无声息的打开一个极小的不易发现的包含特殊操作的页面，可以是木马，可以向远端输入当前cookie或者用户信息，这是非常危险的，由于这个是Flash内部的操作，所以网站无法禁止，要想避免，尽量打开本地防火墙以及访问正规网站。

* 提高cookie安全性的几种方式
    * 对保存到cookie里面的敏感信息必须加密
    * 设置HttpOnly为true
        * 该属性值的作用就是防止Cookie值被页面脚本读取。
        * 但是设置HttpOnly属性，HttpOnly属性只是增加了攻击者的难度，Cookie盗窃的威胁并没有彻底消除，因为cookie还是有可能传递的过程中被监听捕获后信息泄漏。
    * 设置Secure为true
        * 给Cookie设置该属性时，只有在https协议下访问的时候，浏览器才会发送该Cookie。
        * 把cookie设置为secure，只保证cookie与WEB服务器之间的数据传输过程加密，而保存在本地的cookie文件并不加密。如果想让本地cookie也加密，得自己加密数据。
    * 给Cookie设置有效期
        * 如果不设置有效期，万一用户获取到用户的Cookie后，就可以一直使用用户身份登录。
        * 在设置Cookie认证的时候，需要加入两个时间，一个是“即使一直在活动，也要失效”的时间，一个是“长时间不活动的失效时间”，并在Web应用中，首先判断两个时间是否已超时，再执行其他操作。

#### 1.4.4.2. 基本认证机制
<a href="#menu" style="float:right">目录</a>

#### 1.4.4.3. 摘要认证
<a href="#menu" style="float:right">目录</a>


### 1.4.5. 实体和编码
<a href="#menu" style="float:right">目录</a>

实体是实际传输的实体数据,首部是描述性信息,首部之后以空行结尾.

#### 1.4.5.1. 实体首部
<a href="#menu" style="float:right">目录</a>


|首部|说明|
|---|---|
|Content-Type   |实体所承载对象的类型
|Content-Length |实体长度大小
|Content-Language    |与所传送对象最相配的人类语言
|Content-Encoding    |对象数据所做的任意变换
|Content-Location    |一个备用位置,请求时可以通过它获得对象
|Content-Range    |如果这是部分实体,这个首部说明它是整体的哪个部分
|Content-MD5    |实体主题内容的校验和
|Last-Modified    |所传输内容在服务器上创建和最后修改的时间
|Expires    |实体数据将要失效的时间
|Allow    |该资源所允许的请求方法
|Etag    |这份文档的特定实例唯一验证码,没有正式定义为实体首部
|Cache-Control    |指出应该如何缓存该文档,没有正式定义为实体首部
  
accept相关首部

|首部|说明|
|---|---|
|Accept|指定客户端能够接收的内容类型|
|Accept-Charset|浏览器可以接受的字符编码集|
|Accept-Encoding|内容压缩编码类型|
|Accept-Language|浏览器可以接受的语言|
|Accept-Ranges|可以请求网页实体的一个或者多个子范围字段|

#### 1.4.5.2. HTTP的媒体类型

当浏览器发起http请求时，有一个关于媒体格式的请求头字段，浏览器会根据请求链接的内容帮我们自动加上，那就是Accept字段，它的作用告诉WEB服务器自己接受的MIME类型，属于请求头，而服务器接收到该信息后，使用Content-Type 应答头通知客户端它选择的MIME类型，属于实体头，服务端不返回Content-Type字段时浏览器会按Accept字段里的属性顺序对返回的数据进行解析。Content-Type也可以用在请求头信息中，用来指定报文主体的类型。

* MIME类型的数据格式标签（MultIpurpose Internet Mail Extension） 
* 最初用于电子邮件系统之间搬移，多用途互联网邮件扩展
* MIME类型是一种文本标记，表示一种主要的对象类型和一种子类型，通过相应报头content-type传递

### 1.4.6. 国际化
<a href="#menu" style="float:right">目录</a>

### 1.4.7. WEB主机托管
<a href="#menu" style="float:right">目录</a>

### 1.4.8. 重定向和负载均衡
<a href="#menu" style="float:right">目录</a>

## 1.5. WEB Socket
<a href="#menu" style="float:right">目录</a>


我们在上网过程中经常用到的是HTTP和HTTPS协议，HTTP协议和HTTPS协议通信过程通常是客户端通过浏览器发出一个请求，服务器接受请求后进行处理并返回结果给客户端，客户端处理结果。
这种机制对于信息变化不是特别频繁的应用可以良好支撑，但对于实时要求高、海量并发的应用来说显得捉襟见肘，尤其在移动互联网蓬勃发展的趋势下，高并发与用户实时响应是Web应用经常面临的问题，比如金融证券的实时信息、社交网络的实时消息推送等。
WebSocket出现前我们实现推送技术，用的都是轮询，在特定的时间间隔，浏览器自动发出请求，将服务器的消息主动的拉回来，这种情况下，我们需要不断的向服务器发送请求，并且HTTP 请求 的header非常长，里面包含的数据可能只是一个很小的值，这样会占用很多的带宽和服务器资源，并且服务器不能主动向客户端推送数据。在这种情况下需要一种高效节能的双向通信机制来保证数据的实时传输，于是基于HTML5规范的WebSocket应运而生。

### 1.5.1. websocket与http

WebSocket与http协议一样都是基于TCP的，所以他们都是可靠的协议，调用的WebSocket的send函数在实现中最终都是通过TCP的系统接口进行传输的。WebSocket和Http协议一样都属于应用层的协议，WebSocket在建立握手连接时，数据是通过**http协议**传输的，但是在建立连接之后，真正的数据传输阶段是不需要http协议参与的。

WebSocket是HTML5下一种新的协议。它实现了浏览器与服务器全双工通信，能更好的节省服务器资源和带宽并达到实时通讯的目的。它与HTTP一样通过已建立的TCP连接来传输数据，但是它和HTTP最大不同是：

WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样；
WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信。


HTTP实现实时推送用到的轮询，轮询分两种：长轮询和短轮询（传统轮询）
* 短轮询：浏览器定时向服务器发送请求，服务器收到请求不管是否有数据到达都直接响应 请求，隔特定时间，浏览器又会发送相同的请求到服务器， 获取数据响应
    * 缺点：数据交互的实时性较低，服务端到浏览器端的数据反馈效率低
* 长轮询：浏览器发起请求到服务器，服务器一直保持连接打开，直到有数据可发送。发送完数据之后，浏览器关闭连接，随即又发起一个到服务器的新请求。这一过程在页面打开期间一直持续不断
    * 缺点：服务器没有数据到达时，http连接会停留一段时间，造成服务器资源浪费，数据交互的实时性也很低
无论是长轮询还是短轮询，浏览器都要先发起对服务器的连接，才能接收数据，并且实时交互性很低。

然而，WebSocket的出现解决了轮询实时交互性和全双工的问题。
在JavaScript中创建了WebSocket后，会有一个HTTP请求发送到服务器以发起连接。取得服务器响应后，建立的连接使用HTTP升级，从HTTP协议交换为WebSocket协议。即，使用标准的HTTP服务器无法实现WebSocket，只有支持这种协议的专门服务器才能正常工作。
WebSocket使用了自定义的协议，未加密的连接不再是http://，而是ws://，默认端口为80，加密的连接也不是https://，而是wss://，默认端口为443。

**相比HTTP长连接，WebSocket有以下特点：**
* 是真正的全双工方式，建立连接后客户端与服务器端是完全平等的，可以互相主动请求。而HTTP长连接基于HTTP，是传统的客户端对服务器发起请求的模式。
* HTTP长连接中，每次数据交换除了真正的数据部分外，服务器和客户端还要大量交换HTTP header，信息交换效率很低。Websocket协议通过第一个request建立了TCP连接之后，之后交换的数据都不需要发送 HTTP header就能交换数据，这显然和原有的HTTP协议有区别所以它需要对服务器和客户端都进行升级才能实现（主流浏览器都已支持HTML5）。此外还有 multiplexing、不同的URL可以复用同一个WebSocket连接等功能。这些都是HTTP长连接不能做到的。


### 1.5.2. 数据帧格式

客户端、服务端数据的交换，离不开数据帧格式的定义。因此，在实际讲解数据交换之前，我们先来看下WebSocket的数据帧格式。

WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。
* 发送端：将��息切割成多个帧，并发送给服务端；
* 接收端：接收消息帧，并将关联的帧重新组装成完整的消息；

本节的重点，就是讲解数据帧的格式。详细定义可参考 RFC6455-5.2节 。

**数据帧格式概览**
下面给出了WebSocket数据帧的统一格式。熟悉TCP/IP协议的同学对这样的图应该不陌生。

从左到右，单位是比特。比如FIN、RSV1各占据1比特，opcode占据4比特。
内容包括了标识、操作代码、掩码、数据、数据长度等。

```
 0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-------+-+-------------+-------------------------------+
 |F|R|R|R| opcode|M| Payload len |    Extended payload length    |
 |I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |
 |N|V|V|V|       |S|             |   (if payload len==126/127)   |
 | |1|2|3|       |K|             |                               |
 +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +
 |     Extended payload length continued, if payload len == 127  |
 + - - - - - - - - - - - - - - - +-------------------------------+
 |                               |Masking-key, if MASK set to 1  |
 +-------------------------------+-------------------------------+
 | Masking-key (continued)       |          Payload Data         |
 +-------------------------------- - - - - - - - - - - - - - - - +
 :                     Payload Data continued ...                :
 + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
 |                     Payload Data continued ...                |
 +---------------------------------------------------------------+
```
**数据帧格式详解**
针对前面的格式概览图，这里逐个字段进行讲解，如有不清楚之处，可参考协议规范，或留言交流。
* **FIN**：1个比特。
如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。

* **RSV1, RSV2, RSV3**：各占1个比特。
一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。

* **Opcode**: 4个比特。
操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下：
%x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。
%x1：表示这是一个文本帧（frame）
%x2：表示这是一个二进制帧（frame）
%x3-7：保留的操作代码，用于后续定义的非控制帧。
%x8：表示连接断开。
%x9：表示这是一个ping操作。
%xA：表示这是一个pong操作。
%xB-F：保留的操作代码，用于后续定义的控制帧。
Mask: 1个比特。

表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。

如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。

如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。

掩码的算法、用途在下一小节讲解。

* **Payload length**：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。

假设数Payload length === x，如果

x为0~126：数据的长度为x字节。
x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。
x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。
此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。

* **Masking-key**：0或4字节（32位）

所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。

备注：载荷数据的长度，不包括mask key的长度。

* **Payload data**：(x+y) 字节

载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。

扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。

应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。

**掩码算法**
掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法：

首先，假设：
original-octet-i：为原始数据的第i字节。
transformed-octet-i：为转换后的数据的第i字节。
j：为i mod 4的结果。
masking-key-octet-j：为mask key第j字节。
算法描述为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。
```
j = i MOD 4
transformed-octet-i = original-octet-i XOR masking-key-octet-j
```
### 1.5.3. 数据传递
<a href="#menu" style="float:right">目录</a>

一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。

WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。

**数据分片**
WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。
FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。
此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。

**数据分片例子**
直接看例子更形象些。下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。

第一条消息
FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。
第二条消息
FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。
FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。
FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。
Client: FIN=1, opcode=0x1, msg="hello"
Server: (process complete message immediately) Hi.
Client: FIN=0, opcode=0x1, msg="and a"
Server: (listening, new message containing text started)
Client: FIN=0, opcode=0x0, msg="happy new"
Server: (listening, payload concatenated to previous message)
Client: FIN=1, opcode=0x0, msg="year!"
Server: (process complete message) Happy new year to you too!

### 1.5.4. 连接保持+心跳
<a href="#menu" style="float:right">目录</a>


WebSocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。

但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。

发送方->接收方：ping
接收方->发送方：pong
ping、pong的操作，对应的是WebSocket的两个控制帧，opcode分别是0x9、0xA。

举例，WebSocket服务端向客户端发送ping，只需要如下代码（采用ws模块）

ws.ping('', false, true);

### 1.5.5. Sec-WebSocket-Key/Accept的作用
<a href="#menu" style="float:right">目录</a>

前面提到了，Sec-WebSocket-Key/Sec-WebSocket-Accept在主要作用在于提供基础的防护，减少恶意连接、意外连接。

作用大致归纳如下：

避免服务端收到非法的websocket连接（比如http客户端不小心请求连接websocket服务，此时服务端可以直接拒绝连接）
确保服务端理解websocket连接。因为ws握手阶段采用的是http协议，因此可能ws连接是被一个http服务器处理并返回的，此时客户端可以通过Sec-WebSocket-Key来确保服务端认识ws协议。（并非百分百保险，比如总是存在那么些无聊的http服务器，光处理Sec-WebSocket-Key，但并没有实现ws协议。。。）
用浏览器里发起ajax请求，设置header时，Sec-WebSocket-Key以及其他相关的header是被禁止的。这样可以避免客户端发送ajax请求时，意外请求协议升级（websocket upgrade）
可以防止反向代理（不理解ws协议）返回错误的数据。比如反向代理前后收到两次ws连接的升级请求，反向代理把第一次请求的返回给cache住，然后第二次请求到来时直接把cache住的请求给返回（无意义的返回）。
Sec-WebSocket-Key主要目的并不是确保数据的安全性，因为Sec-WebSocket-Key、Sec-WebSocket-Accept的转换计算公式是公开的，而且非常简单，最主要的作用是预防一些常见的意外情况（非故意的）。
强调：Sec-WebSocket-Key/Sec-WebSocket-Accept 的换算，只能带来基本的保障，但连接是否安全、数据是否安全、客户端/服务端是否合法的 ws客户端、ws服务端，其实并没有实际性的保证。

### 1.5.6. 数据掩码的作用
<a href="#menu" style="float:right">目录</a>

WebSocket协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。

那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。

答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。

**代理缓存污染攻击**
下面摘自2010年关于安全的一段讲话。其中提到了代理服务器在协议实现上的缺陷可能导致的安全问题。猛击出处。
```
“We show, empirically, that the current version of the WebSocket consent mechanism is vulnerable to proxy cache poisoning attacks. Even though the WebSocket handshake is based on HTTP, which should be understood by most network intermediaries, the handshake uses the esoteric “Upgrade” mechanism of HTTP [5]. In our experiment, we find that many proxies do not implement the Upgrade mechanism properly, which causes the handshake to succeed even though subsequent traffic over the socket will be misinterpreted by the proxy.”

[TALKING] Huang, L-S., Chen, E., Barth, A., Rescorla, E., and C.
Jackson, "Talking to Yourself for Fun and Profit", 2010,
```
在正式描述攻击步骤之前，我们假设有如下参与者：
* 攻击者、攻击者自己控制的服务器（简称“邪恶服务器”）、攻击者伪造的资源（简称“邪恶资源”）
* 受害者、受害者想要访问的资源（简称“正义资源”）
* 受害者实际想要访问的服务器（简称“正义服务器”）
* 中间代理服务器

攻击步骤一：
* 攻击者浏览器 向 邪恶服务器 发起WebSocket连接。根据前文，首先是一个协议升级请求。
* 协议升级请求 实际到达 代理服务器。
* 代理服务器 将协议升级请求转发到 邪恶服务器。
* 邪恶服务器 同意连接，代理服务器 将响应转发给 攻击者。

由于 upgrade 的实现上有缺陷，代理服务器 以为之前转发的是普通的HTTP消息。因此，当协议服务器 同意连接，代理服务器 以为本次会话已经结束。

攻击步骤二：
* 攻击者 在之前建立的连接上，通过WebSocket的接口向 邪恶服务器 发送数据，且数据是精心构造的HTTP格式的文本。其中包含了 正义资源 的地址，以及一个伪造的host（指向正义服务器）。（见后面报文）
* 请求到达 代理服务器 。虽然复用了之前的TCP连接，但 代理服务器 以为是新的HTTP请求。
* 代理服务器 向 邪恶服务器 请求 邪恶资源。
* 邪恶服务器 返回 邪恶资源。代理服务器 缓存住 邪恶资源（url是对的，但host是 正义服务器 的地址）。

到这里，受害者可以登场了：
* 受害者 通过 代理服务器 访问 正义服务器 的 正义资源。
* 代理服务器 检查该资源的url、host，发现本地有一份缓存（伪造的）。
*  代理服务器 将 邪恶资源 返回给 受害者。
* 受害者 卒。

附：前面提到的精心构造的“HTTP请求报文”。
```
Client → Server:
POST /path/of/attackers/choice HTTP/1.1 Host: host-of-attackers-choice.com Sec-WebSocket-Key: <connection-key>
Server → Client:
HTTP/1.1 200 OK
Sec-WebSocket-Accept: <connection-key>
```
**当前解决方案**
最初的提案是对数据进行加密处理。基于安全、效率的考虑，最终采用了折中的方案：对数据载荷进行掩码处理。

需要注意的是，这里只是限制了浏览器对数据载荷进行掩码处理，但是坏人完全可以实现自己的WebSocket客户端、服务端，不按规则来，攻击可以照常进行。

但是对浏览器加上这个限制后，可以大大增加攻击的难度，以及攻击的影响范围。如果没有这个限制，只需要在网上放个钓鱼网站骗人去访问，一下子就可以在短时间内展开大范围的攻击。

### 1.5.7. WebSocket运行流程
<a href="#menu" style="float:right">目录</a>

在客户端，new WebSocket实例化一个新的WebSocket客户端对象，请求类似 ws://yourdomain:port/path 的服务端WebSocket URL，客户端WebSocket对象会自动解析并识别为WebSocket请求，并连接服务端端口，执行双方握手过程，客户端发送数据格式类似：

```js
GET /webfin/websocket/ HTTP/1.1GET /webfin/websocket/ HTTP/1.1
Host: localhost
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: xqBt3ImNzJbYqRINxEFlkg==
Origin: http://localhost:8080
Sec-WebSocket-Version: 13
```
可以看到，客户端发起的WebSocket连接报文类似传统HTTP报文，Upgrade：websocket参数值表明这是WebSocket类型请求，Sec-WebSocket-Key是WebSocket客户端发送的一个 base64编码的密文，要求服务端必须返回一个对应加密的Sec-WebSocket-Accept应答，否则客户端会抛出Error during WebSocket handshake错误，并关闭连接。

服务端收到报文后返回的数据格式类似：
```js
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: K7DJLdLooIwIG/MOpvWFB3y3FE8=
```
Sec-WebSocket-Accept的值是服务端采用与客户端一致的密钥计算出来后返回客户端的，HTTP/1.1 101 Switching Protocols表示服务端接受WebSocket协议的客户端连接，经过这样的请求-响应处理后，两端的WebSocket连接握手成功, 后续就可以进行TCP通讯了。用户可以查阅WebSocket协议栈了解WebSocket客户端和服务端更详细的交互数据格式。



### 1.5.8. SpringBoot + WebSocket实现案例
<a href="#menu" style="float:right">目录</a>

* 服务端实现方式
* 第一种是用“@ServerEndPoint”注解来实现，实现简单；
* 第二种稍显麻烦，但是可以添加拦截器在WebSocket连接建立和断开前进行一些额外操作。

不管用哪种实现方式，都需要先导入jar包（如下），其中version根据实际springboot版本选择，避免冲突
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-websocket</artifactId>
    <!-- <version>1.3.5.RELEASE</version> -->
</dependency>
```


#### 1.5.8.1. 第一种实现方法
<a href="#menu" style="float:right">目录</a>

（1）WebSocket 业务逻辑实现。参数传递采用路径参数的方法，通过以下方式获取参数：


* @ServerEndpoint("/testWebSocket/{id}/{name}")
* public void onOpen(Session session, @PathParam("id") long id, @PathParam("name") String name)

```java
import java.util.concurrent.CopyOnWriteArraySet;

import javax.websocket.OnClose;
import javax.websocket.OnError;
import javax.websocket.OnMessage;
import javax.websocket.OnOpen;
import javax.websocket.Session;
import javax.websocket.server.ServerEndpoint;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.RestController;

@ServerEndpoint("/testWebSocket/{id}/{name}")
@RestController
public class TestWebSocket {

    // 用来记录当前连接数的变量
    private static volatile int onlineCount = 0;

    // concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象
    private static CopyOnWriteArraySet<TestWebSocket> webSocketSet = new CopyOnWriteArraySet<TestWebSocket>();

    // 与某个客户端的连接会话，需要通过它来与客户端进行数据收发
    private Session session;
    
    private static final Logger LOGGER = LoggerFactory.getLogger(TestWebSocket.class);
    
　　@OnOpen
    public void onOpen(Session session, @PathParam("id") long id, @PathParam("name") String name) throws Exception {
        this.session = session;
        System.out.println(this.session.getId());
        webSocketSet.add(this);
        LOGGER.info("Open a websocket. id={}, name={}", id, name);
    }
    
    @OnClose
    public void onClose() {
        webSocketSet.remove(this);
        LOGGER.info("Close a websocket. ");
    }
    
    @OnMessage
    public void onMessage(String message, Session session) {
        LOGGER.info("Receive a message from client: " + message);
    }
    
    @OnError
    public void onError(Session session, Throwable error) {
        LOGGER.error("Error while websocket. ", error);
    }
    
    public void sendMessage(String message) throws Exception {
        if (this.session.isOpen()) {
            this.session.getBasicRemote().sendText("Send a message from server. ");
        }
    }
    
    public static synchronized int getOnlineCount() {
        return onlineCount;
    }

    public static synchronized void addOnlineCount() {
        TestWebSocket.onlineCount++;
    }

    public static synchronized void subOnlineCount() {
        TestWebSocket.onlineCount--;
    }
}
```
（2）配置ServerEndpointExporter，配置后会自动注册所有“@ServerEndpoint”注解声明的Websocket Endpoint

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.socket.server.standard.ServerEndpointExporter;

@Configuration
public class WebSocketConfig {

    @Bean
    public ServerEndpointExporter serverEndpointExporter() {
        return new ServerEndpointExporter();
    }
    
}
```
 

#### 1.5.8.2. 第二种实现方法
<a href="#menu" style="float:right">目录</a>

（1）WebSocket 业务逻辑实现。参数传递采用类似GET请求的方式传递，服务端的参数在拦截器中获取之后通过attributes传递给WebSocketHandler。
```java
import java.util.ArrayList;
import java.util.concurrent.atomic.AtomicInteger;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.socket.CloseStatus;
import org.springframework.web.socket.WebSocketHandler;
import org.springframework.web.socket.WebSocketMessage;
import org.springframework.web.socket.WebSocketSession;

@RestController
public class TestWebSocketController implements WebSocketHandler {
    
    private static AtomicInteger onlineCount = new AtomicInteger(0);
    
    private static final ArrayList<WebSocketSession> sessions = new ArrayList<>();
    
    private final Logger LOGGER = LoggerFactory.getLogger(TestWebSocketController.class);
    
    @Override
    public void afterConnectionEstablished(WebSocketSession session) throws Exception {
        sessions.add(session);
        int onlineNum = addOnlineCount();
        LOGGER.info("Oprn a WebSocket. Current connection number: " + onlineNum);
    }

    @Override
    public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception {
        sessions.remove(session);
        int onlineNum = subOnlineCount();
        LOGGER.info("Close a webSocket. Current connection number: " + onlineNum);
    }

    @Override
    public void handleMessage(WebSocketSession wsSession, WebSocketMessage<?> message) throws Exception {
        LOGGER.info("Receive a message from client: " + message.toString());
    }

    @Override
    public void handleTransportError(WebSocketSession session, Throwable exception) throws Exception {
        LOGGER.error("Exception occurs on webSocket connection. disconnecting....");
        if (session.isOpen()) {
            session.close();
        }
        sessions.remove(session);
        subOnlineCount();
    }

    /*
     * 是否支持消息拆分发送：如果接收的数据量比较大，最好打开(true), 否则可能会导致接收失败。
     * 如果出现WebSocket连接接收一次数据后就自动断开，应检查是否是这里的问题。
     */
    @Override
    public boolean supportsPartialMessages() {
        return true;
    }

    
    public static int getOnlineCount() {
        return onlineCount.get();
    }
    
    public static int addOnlineCount() {
        return onlineCount.incrementAndGet();
    }
    
    public static int subOnlineCount() {
        return onlineCount.decrementAndGet();
    }

}
```

（2）HandShake 拦截器实现

```java
import java.util.Map;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import org.springframework.http.server.ServerHttpRequest;
import org.springframework.http.server.ServerHttpResponse;
import org.springframework.http.server.ServletServerHttpRequest;
import org.springframework.web.socket.WebSocketHandler;
import org.springframework.web.socket.server.support.HttpSessionHandshakeInterceptor;

public class TestHandShakeInterceptor extends HttpSessionHandshakeInterceptor {
    
    private final Logger LOGGER = LoggerFactory.getLogger(TestHandShakeInterceptor.class);
    
    /*
     * 在WebSocket连接建立之前的操作，以鉴权为例
     */
    @Override
    public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, 
            WebSocketHandler wsHandler, Map<String, Object> attributes) throws Exception {
        
        LOGGER.info("Handle before webSocket connected. ");
        
        // 获取url传递的参数，通过attributes在Interceptor处理结束后传递给WebSocketHandler
        // WebSocketHandler可以通过WebSocketSession的getAttributes()方法获取参数
        ServletServerHttpRequest serverRequest = (ServletServerHttpRequest) request;
        String id = serverRequest.getServletRequest().getParameter("id");
        String name = serverRequest.getServletRequest().getParameter("name");

        if (tokenValidation.validateSign()) {
            LOGGER.info("Validation passed. WebSocket connecting.... ");
            attributes.put("id", id);
            attributes.put("name", name);
            return super.beforeHandshake(request, response, wsHandler, attributes);
        } else {
            LOGGER.error("Validation failed. WebSocket will not connect. ");
            return false;
        }
    }
    
    @Override
    public void afterHandshake(ServerHttpRequest request, ServerHttpResponse response,
            WebSocketHandler wsHandler, Exception ex) {
        // 省略
    }

}
```
（3）WebSocket 配置类实现（注册WebSocket实现类，绑定接口，同时将实现类和拦截器绑定）

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.EnableWebMvc;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;
import org.springframework.web.socket.config.annotation.EnableWebSocket;
import org.springframework.web.socket.config.annotation.WebSocketConfigurer;
import org.springframework.web.socket.config.annotation.WebSocketHandlerRegistry;

import TestWebSocketController;
import TestHandShakeInterceptor;

@Configuration
@EnableWebMvc
@EnableWebSocket
public class WebSocketConfig extends WebMvcConfigurerAdapter implements WebSocketConfigurer {

    @Autowired
    private TestWebSocketController testWebSocketController;

    @Override
    public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) {
        registry.addHandler(TestWebSocketController, "/testWebSocket")
                .addInterceptors(new TestHandShakeInterceptor()).setAllowedOrigins("*");
    }

}
```
 

#### 1.5.8.3. 补充说明
<a href="#menu" style="float:right">目录</a>

（1）在WebSocket实现过程中，尤其是通过“@ServerEndpoint”实现的时候，可能会出现注入失败的问题，即注入的Bean为null的问题。可以通过手动注入的方式来解决，需要改造实现类和SpringBoot启动类，如下：

```java
@ServerEndpoint("testWebsocket")
@RestController
public class WebSocketController {

    private TestService testService;
    
    private static ApplicationContext applicationContext;
    
    @OnOpen
    public void onOpen(Session session) {
        testService = applicationContext.getBean(TestService.class);
    }

    @OnClose
    public void onClose() {}

    @OnMessage
    public void onMessage(String message, Session session) {}

    @OnError
    public void onError(Session session, Throwable error) {}

    public static void setApplicationContext(ApplicationContext applicationContext) {
        WebSocketController.applicationContext = applicationContext;
    }
    
}
```
启动类
```java
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.ConfigurableApplicationContext;

import WebSocketController;

@SpringBootApplication
public class Application {

    public static void main(String[] args) {
//        SpringApplication.run(Application.class, args);
        SpringApplication springApplication = new SpringApplication(Application.class);
        ConfigurableApplicationContext configurableApplicationContext = springApplication.run(args);
        WebSocketController.setApplicationContext(configurableApplicationContext);  // 解决WebSocket不能注入的问题
    }

}
```
 

#### 1.5.8.4. 客户端的实现，js方式和java WebSocketClient两种方式
<a href="#menu" style="float:right">目录</a>

**js方式实现**
```html
<!DOCTYPE html>
<html>
<head>
    <title>WebSocket示例</title>
    <meta content='width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no' name='viewport' />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>
<body>
    <input id="text" type="text"/>
    <button onclick="send()">发送消息</button>
    <hr/>
    <button onclick="closeWebSocket()">关闭WebSocket连接</button>
    <hr/>
    <div id="message"></div>
</body>

<script type="text/javascript">
    var websocket = null;
    //判断当前浏览器是否支持WebSocket
    if ('WebSocket' in window) {
        // 不带参数的写法
        websocket = new WebSocket("ws://127.0.0.1:18080/testWebsocket");
        // 通过路径传递参数的方法（服务端采用第一种方法"@ServerEndpoint"实现）
        websocket = new WebSocket("ws://127.0.0.1:18080/testWebsocket/23/Lebron");
        // 通过类似GET请求方式传递参数的方法（服务端采用第二种方法"WebSocketHandler"实现）
        websocket = new WebSocket("ws://127.0.0.1:18080/testWebsocket?id=23&name=Lebron");
    }
    else {
        alert('当前浏览器 Not support websocket')
    }

    //连接发生错误的回调方法
    websocket.onerror = function () {
        setMessageInnerHTML("WebSocket连接发生错误");
    };

    //连接成功建立的回调方法
    websocket.onopen = function () {
        setMessageInnerHTML("WebSocket连接成功");
    }

    //接收到消息的回调方法
    websocket.onmessage = function (event) {
        setMessageInnerHTML(event.data);
    }

    //连接关闭的回调方法
    websocket.onclose = function () {
        setMessageInnerHTML("WebSocket连接关闭");
    }

    //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，防止连接还没断开就关闭窗口，server端会抛异常。
    window.onbeforeunload = function () {
        closeWebSocket();
    }

    //将消息显示在网页上
    function setMessageInnerHTML(innerHTML) {
        document.getElementById('message').innerHTML += innerHTML + '<br/>';
    }

    //关闭WebSocket连接
    function closeWebSocket() {
        websocket.close();
    }

    //发送消息
    function send() {
        var message = document.getElementById('text').value;
        websocket.send(message);
    }
</script>
</html>
```
 

**Java WebSocketClient实现**

（1）WebSocketClient 实现类
```java
import java.net.URI;

import org.java_websocket.client.WebSocketClient;
import org.java_websocket.drafts.Draft;
import org.java_websocket.handshake.ServerHandshake;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class TestWebSocketClient extends WebSocketClient {
    
    private final Logger LOGGER = LoggerFactory.getLogger(TestWebSocketClient.class);
    
    public TestWebSocketClient(URI serverUri) {
        super(serverUri);
    }
    
    public TestWebSocketClient(URI serverUri, Draft protocolDraft) {
        super(serverUri, protocolDraft);
    }

    @Override
    public void onOpen(ServerHandshake serverHandshake) {
        LOGGER.info("Open a WebSocket connection on client. ");
    }
    
    @Override
    public void onClose(int arg0, String arg1, boolean arg2) {
        LOGGER.info("Close a WebSocket connection on client. ");
    }

    @Override
    public void onMessage(String msg) {
        LOGGER.info("WebSocketClient receives a message: " + msg);
    }

    @Override
    public void onError(Exception exception) {
        LOGGER.error("WebSocketClient exception. ", exception);
    }

}
```
（2）WebSocketClient 发送数据
```java
String serverUrl = "ws://127.0.0.1:18080/testWebsocket"
URI recognizeUri = new URI(serverUrl);
client = new TestWebSocketClient(recognizeUri, new Draft_6455());
client.connect();
client.send("This is a message from client. ");
```

## 1.6. Unix环境编程
<a href="#menu" style="float:right">目录</a>

### 1.6.1. 基本概念
<a href="#menu" style="float:right">目录</a>

* **内核**
管理和分配计算机资源(CPU,内存等)的核心层软件

* **内核任务**
    * 进程调度，Linux是抢占式多任务操作系统，内核需要协调好多个任务的执行。`
    * 内存管理
    * 提供文件系统
    * 创建和终止进程
    * 对设备的访问
    * 联网
    * 提供系统应用调用API接口

* **内核态和用户态**
    * 可将虚拟内存区域划分为用户空间和内核空间两部分
    * 在用户态下只能访问用户空间，试图访问内核空间将会报硬件错误
    * 在内核态下两者都可以访问到

* **文件描述符**
    * Linux下一切皆是文件，每打开一个文件或者Socket,都会获得一个文件描述符(整型)来唯一标识。

* **进程**
    * 进程是正在执行的程序实例，执行程序时，内核会将程序代码载入虚拟内存，为程序变量分配空间，建立内核记账数据结构，以记录与进程有关的各种信息（比如，进程ID，用户ID，组ID以及终止状态）
    * 进程内存布局
        * 文本: 程序的指令
        * 数据: 程序使用的静态变量
        * 堆:程序可从该区域动态分配额外的内存
        * 栈:随函数调用，返回而增减的一片内存，用于为局部变量和函数调用链接信息分配存储空间
    * 创建进程和执行程序
        * fork进行创建
        * 内核通过对父进程的复制来创建子进程
        * 子进程从父进程处继承数据段、栈段、以及堆段的副本，即使修改也不会互相影响，两者之间的内存空间是独立的
    * 进程IP
        * 每一个进程都有一个唯一标识符PID，如果有父进程，还有一个父进程PPID

### 1.6.2. IO模型
<a href="#menu" style="float:right">目录</a>

**概念理解**
 在进行网络编程时，我们常常见到同步(Sync)/异步(Async)，阻塞(Block)/非阻塞(Unblock)四种调用方式：
 * 同步
    * 所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。
    * 例如普通B/S模式（同步）：提交请求->等待服务器处理->处理完毕返回 这个期间客户端浏览器不能干任何事
* 异步：
    * 异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
    * 例如 ajax请求（异步）: 请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕
* 阻塞
    * 阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。
    * 有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。

* 非阻塞
    * 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。

**对象的阻塞模式和阻塞函数调用**
对象是否处于阻塞模式和函数是不是阻塞调用有很强的相关性，但是并不是一一对应的。阻塞对象上可以有非阻塞的调用方式，我们可以通过一定的API去轮询状 态，在适当的时候调用阻塞函数，就可以避免阻塞。而对于非阻塞对象，调用特殊的函数也可以进入阻塞调用。函数select就是这样的一个例子。

* 同步，就是我调用一个功能，该功能没有结束前，我死等结果。
* 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知）
* 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。
* 非阻塞，就是调用我（函数），我（函数）立即返回，通过select通知调用者

 

同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！
阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！


对于举个简单c/s 模式：

 

同步：提交请求->等待服务器处理->处理完毕返回这个期间客户端浏览器不能干任何事
异步：请求通过事件触发->服务器处理（这是浏览器仍然可以作其他事情）->处理完毕
同步和异步都只针对于本机SOCKET而言的。
同步和异步,阻塞和非阻塞,有些混用,其实它们完全不是一回事,而且它们修饰的对象也不相同。
阻塞和非阻塞是指当进程访问的数据如果尚未就绪,进程是否需要等待,简单说这相当于函数内部的实现区别,也就是未就绪时是直接返回还是等待就绪;

而同步和异步是指访问数据的机制,同步一般指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞(区别就绪与读写二个阶段,同步的读写必须阻塞),异步则指主动请求数据后便可以继续处理其它任务,随后等待I/O,操作完毕的通知,这可以使进程在数据读写时也不阻塞。(等待"通知")

**Linux下的五种I/O模型**
* 阻塞I/O（blocking I/O）
* 非阻塞I/O （nonblocking I/O）
* I/O复用(select 和poll) （I/O multiplexing）
* 信号驱动I/O （signal driven I/O (SIGIO)）
* 异步I/O （asynchronous I/O (the POSIX aio_functions)）
前四种都是同步，只有最后一种才是异步IO。


**阻塞I/O模型：**
![](https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=3808372216,1260325684&fm=26&gp=0.jpg)
* 简介：进程会一直阻塞，直到数据拷贝完成

应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。

阻塞I/O模型图：在调用recv()/recvfrom（）函数时，发生在内核中等待数据和复制数据的过�����。

当调用recv()函数时，系统首先查是否有准备好的数据。如果数据没有准备好，那么系统就处于等待状态。当数据准备好后，将数据从系统缓冲区复制到用户空间，然后该函数返回。在套接应用程序中，当调用recv()函数时，未必用户空间就已经存在数据，那么此时recv()函数就会处于等待状态。

当使用socket()函数和WSASocket()函数创建套接字时，默认的套接字都是阻塞的。这意味着当调用Windows Sockets API不能立即完成时，线程处于等待状态，直到操作完成。

并不是所有Windows Sockets API以阻塞套接字为参数调用都会发生阻塞。例如，以阻塞模式的套接字为参数调用bind()、listen()函数时，函数会立即返回。将可能阻塞套接字的Windows Sockets API调用分为以下四种:

1．输入操作： recv()、recvfrom()、WSARecv()和WSARecvfrom()函数。以阻塞套接字为参数调用该函数接收数据。如果此时套接字缓冲区内没有数据可读，则调用线程在数据到来前一直睡眠。

2．输出操作： send()、sendto()、WSASend()和WSASendto()函数。以阻塞套接字为参数调用该函数发送数据。如果套接字缓冲区没有可用空间，线程会一直睡眠，直到有空间。

3．接受连接：accept()和WSAAcept()函数。以阻塞套接字为参数调用该函数，等待接受对方的连接请求。如果此时没有连接请求，线程就会进入睡眠状态。

4．外出连接：connect()和WSAConnect()函数。对于TCP连接，客户端以阻塞套接字为参数，调用该函数向服务器发起连接。该函数在收到服务器的应答前，不会返回。这意味着TCP连接总会等待至少到服务器的一次往返时间。

　　使用阻塞模式的套接字，开发网络程序比较简单，容易实现。当希望能够立即发送和接收数据，且处理的套接字数量比较少的情况下，使用阻塞模式来开发网络程序比较合适。

阻塞模式套接字的不足表现为，在大量建立好的套接字线程之间进行通信时比较困难。当使用“生产者-消费者”模型开发网络程序时，为每个套接字都分别分配一个读线程、一个处理数据线程和一个用于同步的事件，那么这样无疑加大系统的开销。其最大的缺点是当希望同时处理大量套接字时，将无从下手，其扩展性很差

**非阻塞IO模型** 
 ![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857412314&di=0d854bfa102034baf1b415032bb0cff8&imgtype=0&src=http%3A%2F%2Fpic.victorchu.info%2F%25E9%259D%259E%25E9%2598%25BB%25E5%25A1%259EIO.jpeg%3FimageView2%2F2%2Fw%2F800%2Fh%2F600%2Fq%2F75%257Cimageslim)

简介：非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的；
 
我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。

把SOCKET设置为非阻塞模式，即通知系统内核：在调用Windows Sockets API时，不要让线程睡眠，而应该让函数立即返回。在返回时，该函数返回一个错误代码。图所示，一个非阻塞模式套接字多次调用recv()函数的过程。前三次调用recv()函数时，内核数据还没有准备好。因此，该函数立即返回WSAEWOULDBLOCK错误代码。第四次调用recv()函数时，数据已经准备好，被复制到应用程序的缓冲区中，recv()函数返回成功指示，应用程序开始处理数据。

当使用socket()函数和WSASocket()函数创建套接字时，默认都是阻���的。在创建套接字之后，通过调用ioctlsocket()函数，将该套接字设置为非阻塞模式。Linux下的函数是:fcntl().

套接字设置为非阻塞模式后，在调用Windows Sockets API函数时，调用函数会立即返回。大多数情况下，这些函数调用都会调用“失败”，并返回WSAEWOULDBLOCK错误代码。说明请求的操作在调用期间内没有时间完成。通常，应用程序需要重复调用该函数，直到获得成功返回代码。

需要说明的是并非所有的Windows Sockets API在非阻塞模式下调用，都会返回WSAEWOULDBLOCK错误。例如，以非阻塞模式的套接字为参数调用bind()函数时，就不会返回该错误代码。当然，在调用WSAStartup()函数时更不会返回该错误代码，因为该函数是应用程序第一调用的函数，当然不会返回这样的错误代码。

要将套接字设置为非阻塞模式，除了使用ioctlsocket()函数之外，还可以使用WSAAsyncselect()和WSAEventselect()函数。当调用该函数时，套接字会自动地设置为非阻塞方式。

由于使用非阻塞套接字在调用函数时，会经常返��WSAEWOULDBLOCK错误。所以在任何时候，都应仔细检查返回代码并作好对“失败”的准备。应用程序连续不断地调用这个函数，直到它返回成功指示为止。上面的程序清单中，在While循环体内不断地调用recv()函数，以读入1024个字节的数据。这种做法很浪费系统资源。

要完成这样的操作，有人使用MSG_PEEK标志调用recv()函数查看缓冲区中是否有数据可读。同样，这种方法也不好。因为该做法对系统造成的开销是很大的，并且应用程序至少要调用recv()函数两次，才能实际地读入数据。较好的做法是，使用套接字的“I/O模型”来判断非阻塞套接字是否可读可写。

非阻塞模式套接字与阻塞模式套接字相比，不容易使用。使用非阻塞模式套接字，需要编写更多的代码，以便在每个Windows Sockets API函数调用中，对收到的WSAEWOULDBLOCK错误进行处理。因此，非阻塞套接字便显得有些难于使用。

但是，非阻塞套接字在控制建立的多个连接，在数据的收发量不均，时间不定时，明显具有优势。这种套接字在使用上存在一定难度，但只要排除了这些困难，它在功能上还是非常强大的。通常情况下，可考虑使用套接字的“I/O模型”，它有助于应用程序通过异步方式，同时对一个或多个套接字的通信加以管理。


**IO复用模型：**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857181158&di=13d24a895a5417ce847d6768a8f6f0f3&imgtype=jpg&src=http%3A%2F%2Fimg0.imgtn.bdimg.com%2Fit%2Fu%3D770609745%2C3299491672%26fm%3D214%26gp%3D0.jpg)

简介：主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听；

I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。



**信号驱动IO**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857276750&di=a736eec5e67ae951a456a8882f3b968d&imgtype=0&src=http%3A%2F%2Fimage.mamicode.com%2Finfo%2F201904%2F20190420195009891716.png) 

简介：两次调用，两次返回；

首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。



**异步IO模型**
![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564857069930&di=25759da9819bd9b52f14476aea277376&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20190624%2Ff5b1176ce6e241f48403c7e999d91b69.jpeg)

简介：数据拷贝的时候进程无需阻塞。

当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作


同步IO引起进程阻塞，直至IO操作完成。
异步IO不会引起进程阻塞。
IO复用是先通过select调用阻塞。

![](https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=176532706,1323700702&fm=26&gp=0.jpg)

### 1.6.3. select&poll&epoll比较
<a href="#menu" style="float:right">目录</a>


#### 1.6.3.1. 整体概览

**水平触发和边缘触发** 
* 水平触发通知
    * 如果文件描述符上可以非阻塞地执行I/O系统调用，此时认为它已经就绪
    * 也就是说主动去(轮询)检查文件描述符状态
    * select,poll,epoll
    * 可以任意时刻去检查文件描述符状态，因此不需要每次尽可能多的读取数据。
* 边缘触发通知
    * 如果文件描述符自上次状态检查以来有了新的I/O活动，此时需要触发通知。
    * select,信号驱动IO模型
    * I/O事件发生时才会收到通知型
    * 当收到通知时，应当尽可能多的读取字节，因为只有下一次I/O来时才能收到通知。


#### 1.6.3.2. 对比总结
epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

**select：**
select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：
* 单个进程可监视的fd数量被限制，即能监听端口的大小有限。
一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

* 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：
当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

* 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

* select函数
```c
int select(int nfds,fd_set *readfds,fd_set *writefds,fd_set *exceptfds, struct timeval *timeout)
```

* 参数
    * readfds 用来检测输入是否就绪的文件描述符集合
    * writefds 输出
    * exceptfds 异常情况是否发生
    * timeout  超时时间结构体
* 返回值
    * 0 ：超时
    * -1 ：发生错误
    * 大于1：就绪状态的描述符的总数，包括读写异常三个参数 
    

**poll：**

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：

* 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
* poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

* poll 函数
```c
int poll(struct pollfd fds[],nfds_t nfds,int timeout)

struct pollfd{
    //文件描述符
    int fd;
    //请求事件位掩码
    short events; 
    //返回事件位源码
    short revents;
}
```


* 参数
    * nfds 指定fds的元素个数，nfds_t实际为无符号整形
    * fds-fd 文件描述符
    * fds-events 需要做检查的事件位掩码，调用者初始化
    * fds-revents 发生了事件的位掩码，内核设置并返回
    * timeout   
        * -1 : 一直阻塞直到有一个文件描述符发生事件
        * 0: 不阻塞，全部检查完即使没有事件也返回
        * 大于0:最多阻塞时间
* 返回:同select

**select poll区别**
* select 检查的文件描述符有数量上限(FD_SETZIZE),LINUX默认为1024，修改需要重新编译内核。poll没有限制

* select的fd_set同时也是保存调用结果的地方，如果多次调用select需要每次都要进行初始化。poll是两个参数存放检查和就绪的文件描述符，从而避免每次都要进行初始化。

* select提供的超时精度比poll高 



**select poll 问题**
* 每次调用select和epoll都要向内核传入需要检查的文件描述符，检测是否处于就绪状态。当检查的文件描述符较多时，将会很耗时
* select 和 poll调用完成以后，程序必须检查返回的数据结构中的每一个元素，以此查明哪个文件描述符处于就绪态。
* 每次调用select和epoll都要向内核传入需要检查的文件描述符，检查完成，又从内核返回应用，如果文件描述符过多，复制也很耗时。



**epoll:**
epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知

* 适用场景:
    * 同时处理许多客户端的服务器;
    * 需要监视大量的文件描述符，但大部分属于空闲状态，只有少数文件描述符处于就绪状态。

* epoll水平触发和边缘触发的区别
    * 例子
        * 套接字上有输入到来
        * 调用一次epoll_wait(),无论采用的是水平触发还是边缘触发，该调用都会告诉我们套接字已经给处于就绪态
        * 再次调用epoll_wait()
    * 说明
        * 如果是水平触发通知，第二个epoll_wait()会告诉我们套接字已经给处于就绪态
        * 如果是边缘触发通知，将会被阻塞，因为没有新的输入进来

* epoll边缘触发通知机制的程序基本框架
    * 让所有监视的文件描述符都成为非阻塞
    * 通过epoll_wait()取得就绪状态的描述符列表
    * 针对每一个处于就绪状态文件描述符，不断进行IO处理直到相关的系统调用(例如read,write,recv,send,accept)返回EAGAIN或EWOULDBLOCK错误 

epoll的接口非常简单，一共就三个函数：
1. int epoll_create(int size);
创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值。需要注意的是，当创建好epoll句柄后，它就是会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。


2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
epoll的事件注册函数，它不同与select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。第一个参数是epoll_create()的返回值，第二个参数表示动作，用三个宏来表示：
EPOLL_CTL_ADD：注册新的fd到epfd中；
EPOLL_CTL_MOD：修改已经注册的fd的监听事件；
EPOLL_CTL_DEL：从epfd中删除一个fd；
第三个参数是需要监听的fd，第四个参数是告诉内核需要监听什么事，struct epoll_event结构如下：

```c
typedef union epoll_data {
    void *ptr;
    int fd;
    __uint32_t u32;
    __uint64_t u64;
} epoll_data_t;

struct epoll_event {
    __uint32_t events; /* Epoll events */
    epoll_data_t data; /* User data variable */
};

```
 


events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里


3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
等待事件的产生，类似于select()调用。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个 maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。


4、关于ET、LT两种工作模式：
可以得出这样的结论:
ET模式仅当状态发生变化的时候才获得通知,这里所谓的状态的变化并不包括缓冲区中还有未处理的数据,也就是说,如果要采用ET模式,需要一直read/write直到出错为止,很多人反映为什么采用ET模式只接收了一部分数据就再也得不到通知了,大多因为这样;而LT模式是只要有数据没有处理就会一直通知下去的.


那么究竟如何来使用epoll呢？其实非常简单。
通过在包含一个头文件#include <sys/epoll.h> 以及几个简单的API将可以大大的提高你的网络服务器的支持人数。

首先通过create_epoll(int maxfds)来创建一个epoll的句柄，其中maxfds为你epoll所支持的最大句柄数。这个函数会返回一个新的epoll句柄，之后的所有操作将通过这个句柄来进行操作。在用完之后，记得用close()来关闭这个创建出来的epoll句柄。

之后在你的网络主循环里面，每一帧的调用epoll_wait(int epfd, epoll_event events, int max events, int timeout)来查询所有的网络接口，看哪一个可以读，哪一个可以写了。基本的语法为：
nfds = epoll_wait(kdpfd, events, maxevents, -1);
其中kdpfd为用epoll_create创建之后的句柄，events是一个epoll_event*的指针，当epoll_wait这个函数操作成功之后，epoll_events里面将储存所有的读写事件。max_events是当前需要监听的所有socket句柄数。最后一个timeout是 epoll_wait的超时，为0的时候表示马上返回，为-1的时候表示一直等下去，直到有事件范围，为任意正整数的时候表示等这么长的时间，如果一直没有事件，则范围。一般如果网络主循环是单独的线程的话，可以用-1来等，这样可以保证一些效率，如果是和主逻辑在同一个线程的话，则可以用0来保证主循环的效率。

epoll_wait范围之后应该是一个循环，遍利所有的事件。

几乎所有的epoll程序都使用下面的框架：
```c
for( ; ; )
    {
        nfds = epoll_wait(epfd,events,20,500);
        for(i=0;i<nfds;++i)
        {
            if(events[i].data.fd==listenfd) //有新的连接
            {
                connfd = accept(listenfd,(sockaddr *)&clientaddr, &clilen); //accept这个连接
                ev.data.fd=connfd;
                ev.events=EPOLLIN|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&ev); //将新的fd添加到epoll的监听队列中
            }
            else if( events[i].events&EPOLLIN ) //接收到数据，读socket
            {
                n = read(sockfd, line, MAXLINE)) < 0    //读
                ev.data.ptr = md;     //md为自定义类型，添加数据
                ev.events=EPOLLOUT|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);//修改标识符，等待下一个循环时发送数据，异步处理的精髓
            }
            else if(events[i].events&EPOLLOUT) //有数据待发送，写socket
            {
                struct myepoll_data* md = (myepoll_data*)events[i].data.ptr;    //取数据
                sockfd = md->fd;
                send( sockfd, md->ptr, strlen((char*)md->ptr), 0 );        //发送数据
                ev.data.fd=sockfd;
                ev.events=EPOLLIN|EPOLLET;
                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev); //修改标识符，等待下一个循环时接收数据
            }
            else
            {
                //其他的处理
            }
        }
    }

```
完整的服务端例子

```cpp
#include <iostream>
#include <sys/socket.h>
#include <sys/epoll.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>
#include <errno.h>

using namespace std;

#define MAXLINE 5
#define OPEN_MAX 100
#define LISTENQ 20
#define SERV_PORT 5000
#define INFTIM 1000

void setnonblocking(int sock)
{
    int opts;
    opts=fcntl(sock,F_GETFL);
    if(opts<0)
    {
        perror("fcntl(sock,GETFL)");
        exit(1);
    }
    opts = opts|O_NONBLOCK;
    if(fcntl(sock,F_SETFL,opts)<0)
    {
        perror("fcntl(sock,SETFL,opts)");
        exit(1);
    }
}

int main(int argc, char* argv[])
{
    int i, maxi, listenfd, connfd, sockfd,epfd,nfds, portnumber;
    ssize_t n;
    char line[MAXLINE];
    socklen_t clilen;


    if ( 2 == argc )
    {
        if( (portnumber = atoi(argv[1])) < 0 )
        {
            fprintf(stderr,"Usage:%s portnumber/a/n",argv[0]);
            return 1;
        }
    }
    else
    {
        fprintf(stderr,"Usage:%s portnumber/a/n",argv[0]);
        return 1;
    }



    //声明epoll_event结构体的变量,ev用于注册事件,数组用于回传要处理的事件

    struct epoll_event ev,events[20];
    //生成用于处理accept的epoll专用的文件描述符

    epfd=epoll_create(256);
    struct sockaddr_in clientaddr;
    struct sockaddr_in serveraddr;
    listenfd = socket(AF_INET, SOCK_STREAM, 0);
    //把socket设置为非阻塞方式

    //setnonblocking(listenfd);

    //设置与要处理的事件相关的文件描述符

    ev.data.fd=listenfd;
    //设置要处理的事件类型

    ev.events=EPOLLIN|EPOLLET;
    //ev.events=EPOLLIN;

    //注册epoll事件

    epoll_ctl(epfd,EPOLL_CTL_ADD,listenfd,&ev);
    bzero(&serveraddr, sizeof(serveraddr));
    serveraddr.sin_family = AF_INET;
    char *local_addr="127.0.0.1";
    inet_aton(local_addr,&(serveraddr.sin_addr));//htons(portnumber);

    serveraddr.sin_port=htons(portnumber);
    bind(listenfd,(sockaddr *)&serveraddr, sizeof(serveraddr));
    listen(listenfd, LISTENQ);
    maxi = 0;
    for ( ; ; ) {
        //等待epoll事件的发生

        nfds=epoll_wait(epfd,events,20,500);
        //处理所发生的所有事件

        for(i=0;i<nfds;++i)
        {
            if(events[i].data.fd==listenfd)//如果新监测到一个SOCKET用户连接到了绑定的SOCKET端口，建立新的连接。

            {
                connfd = accept(listenfd,(sockaddr *)&clientaddr, &clilen);
                if(connfd<0){
                    perror("connfd<0");
                    exit(1);
                }
                //setnonblocking(connfd);

                char *str = inet_ntoa(clientaddr.sin_addr);
                cout << "accapt a connection from " << str << endl;
                //设置用于读操作的文件描述符

                ev.data.fd=connfd;
                //设置用于注测的读操作事件

                ev.events=EPOLLIN|EPOLLET;
                //ev.events=EPOLLIN;

                //注册ev

                epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&ev);
            }
            else if(events[i].events&EPOLLIN)//如果是已经连接的用户，并且收到数据，那么进行读入。

            {
                cout << "EPOLLIN" << endl;
                if ( (sockfd = events[i].data.fd) < 0)
                    continue;
                if ( (n = read(sockfd, line, MAXLINE)) < 0) {
                    if (errno == ECONNRESET) {
                        close(sockfd);
                        events[i].data.fd = -1;
                    } else
                        std::cout<<"readline error"<<std::endl;
                } else if (n == 0) {
                    close(sockfd);
                    events[i].data.fd = -1;
                }
                line[n] = '/0';
                cout << "read " << line << endl;
                //设置用于写操作的文件描述符

                ev.data.fd=sockfd;
                //设置用于注测的写操作事件

                ev.events=EPOLLOUT|EPOLLET;
                //修改sockfd上要处理的事件为EPOLLOUT

                //epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);

            }
            else if(events[i].events&EPOLLOUT) // 如果有数据发送

            {
                sockfd = events[i].data.fd;
                write(sockfd, line, n);
                //设置用于读操作的文件描述符

                ev.data.fd=sockfd;
                //设置用于注测的读操作事件

                ev.events=EPOLLIN|EPOLLET;
                //修改sockfd上要处理的事件为EPOLIN

                epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);
            }
        }
    }
    return 0;
}
```

**select、poll、epoll 区别总结：** 

* 支持一个进程所能打开的最大连接数

|||
|---|---|
|select|单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。
|poll|poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
|epoll|虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接

* FD剧增后带来的IO效率问题

|||
|---|---|
|select|因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。
|poll|同上
|epoll|因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

* 消息传递方式

|||
|---|---|
|select|内核需要将消息传递到用户空间，都需要内核拷贝动作
|poll|同上
|epoll|epoll通过内核和用户空间共享一块内存来实现的。

**总结：**
综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。
* 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。
* select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善



## 1.7. Shell
<a href="#menu" style="float:right">目录</a>

### 1.7.1. 文件安装

#### 1.7.1.1. deb文件操作

dpkg 是Debian Package的简写，是为Debian 专门开发的套件管理系统，方便软件的安装、更新及移除。所有源自Debian的Linux发行版都使用dpkg，例如Ubuntu、Knoppix 等。
以下是一些 Dpkg 的普通用法：
```
1、dpkg -i <package.deb>
安装一个 Debian 软件包，如你手动下载的文件。
2、dpkg -c <package.deb>
列出 <package.deb> 的内容。
3、dpkg -I <package.deb>
从 <package.deb> 中提取包裹信息。
4、dpkg -r <package>
移除一个已安装的包裹。
5、dpkg -P <package>
完全清除一个已安装的包裹。和 remove 不同的是，remove 只是删掉数据和可执行文件，purge 另外还删除所有的配制文件。
6、dpkg -L <package>
列出 <package> 安装的所有文件清单。同时请看 dpkg -c 来检查一个 .deb 文件的内容。
7、dpkg -s <package>
显示已安装包裹的信息。同时请看 apt-cache 显示 Debian 存档中的包裹信息，以及 dpkg -I 来显示从一个 .deb 文件中提取的包裹信息。
8、dpkg-reconfigure <package>
重新配制一个已经安装的包裹，如果它使用的是 debconf (debconf 为包裹安装提供了一个统一的配制界面)。
```
### 1.7.2. 常用命令

#### 1.7.2.1. 系统信息

* man command 查看命令的信息
* date 显示当前日期和时间
* cal 显示当月的日历
* uptime 系统从开机到现在的时间
* w 显示当前登录的用户
* whoami 查看当前的用户名
* finger user 显示user相关信息
* uname -a 显示内核信息
* cat /proc/cpuinfo 查看cpu信息
* cat /proc/meminfo 查看内存信息
* df 显示磁盘占用信息
* du 显示目录空间占用情况
* free 显示内存以及交换区占用情况

#### 1.7.2.2. SSH

* ssh user@host 以用户user连接到host
* ssh -p password user@host 以用户user连接到host

#### 1.7.2.3. 网络

* ping host 查看网络状况
* wget file-address 下载文件
* wget -c file-address 断点续传

#### 1.7.2.4. 进程管理
* ps 显示当前的活动进程
    * -A 显示所有进程
    * a 显示所有进程
    * -a 显示同一终端下所有进程
    * c 显示进程真实名称
    * e 显示环境变量
    * f 显示进程间的关系
    * r 显示当前终端运行的进程
    * -aux 显示所有包含其它使用的进程
    * ps -aux|grep nginx
    
* top 显示正在运行的进程的信息
* kill pid
* killall *.xx 杀掉.xx结尾的文件
* bg 列出已经停止或后台的作业
* fg 将最近的作业带到前台
* fg n 将作业n带到前台

#### 1.7.2.5. 快捷键

* Ctrl+C 停止当前命令
* Ctrl+Z 停止当前命令,使用fg恢复
* Ctrl+D 注销当前会话
* Ctrl+W 删除当前行中的字
* Ctrl+U 删除整行
* !! 重复上次的命令
* exit 注销当前的会话

#### 查看端口占用

* lsof -i:端口号
* netstat -tunlp|grep 端口号
    * 用于显示tcp，udp的端口和进程等相关情况，如下图
    * -t  仅显示和tcp相关的
    * -u 仅显示和udp相关的
    * -n 不限时别名，能显示数字的全部转换为数字
    * -l   仅显示出于Listen(监听)状态的
    * -p  显示建立这些连接的程序名

#### 1.7.2.6. 文件相关
* 路径
  * /   根路径
  * .   当前目录
  * .. 上一级目录
  * ~/  当前用户目录
  * cd  path  进入路径
  * cd -  返回上一级目录
  * pwd 显示当前绝对路径
  
* 文件列表
  * ls 只列出当前目录文件名称
  * ls -l 包含文件权限等信息
  * ls -a 包含"."开头的隐藏文件
  * ls -F 区分文件和目录
  * ls -R 递归显示目录
  * ls -l  aa 只显示带aa的列表，“?”单个字符，"*"多个字符

* 文件压缩
    * tar cf file.tar file... 压缩文件
    * tar xf file.tar 解压缩
    * tar czf file.tar.gz file... 使用gzip压缩
    * tar xzf file.tar.gz 解压缩tar.gz文件
    * tar cjf file.tar.bz2 
    * tar xjf file.tar.bz2 
    * gzip filename 压缩 filename为filename.gz
    * gzip -d file.gz

* wc [option] file..
    * -c 统计字节数
    * -l 统计行数
    * -m 统计字符数
    * -w 统计词数，一个字被定义为由空白、跳格或换行字符分隔的字符串

* 查找文件位置
    * which command    查看可执行文件的位置。
    * whereis file 查看文件的位置。
    * locate  配合数据库查看文件位置。
    * find pathname -options [-print -exec -ok ...]   实际搜寻硬盘查询文件名称。

* 处理文件
  * touch 创建文件
  * mkdir 创建目录
  * cp source  dest 复制文件，加  -r 用于复制目录
  * rm 删除，-r 删除目录 -f 强制删除文件
  * mv source dest 重命名/复制文件
* 查看文件
  * file xxx 查看文件类型
  * cat 打印文件数据，-n 加上行号， -b 只给有文本的加上行号
* 文件权限
  * 文件权限包括用户(U)-组(G)-其他用户(O),包括读(4-r)写(2-w)执行(1-x)权限。
  * chmod u+x file 用户添加执行权限
  * chmod u-x file 用户去除执行权限
  * chmod 111 file 所有的都为执行权限
  * chmod 721 file 用户有读写执行，组用户有写，其他用户有执行权限
```bash
-rw-rw-r-- 1 lgj lgj  1215779 Jun 28 18:08  1.mp4
```
* 文件链接：给文件创建虚拟副本
   * 符号链接:仅保存引用，文件内容和原文件不一样，和源文件同步更新,仅可读，不可修改，即使修改文件权限。
   * 硬链接: 保存引用和文件信息，和源文件同步更新，可以修改。
   * 使用cp 复制链接文件时，复制的文件仍然保留和源文件之间的链接关系，一般不这么做。
   * ln source dest ,加-s 时创建的是软连接。
*查看文件
   * more 只显示一页，按页翻页。空格键翻页。
   * less 按行翻行，方向键，可向前和向后翻。 
   * tail -n 2 file 实时查看文件后2行数据，动态更新。
   * head -5 file 查看看文件前5行数据

#### 1.7.2.7. 监测程序
<a href="#menu" style="float:right">目录</a>

##### 1.7.2.7.1. 探查进程

* ps 命令
    * -A 显示所有进程
    * -N 显示与指定参数不符的所有进程
    * -a 显示除控制进程（ session leader① ）和无终端进程外的所有进程
    * -d 显示除控制进程外的所有进程
    * -e 显示所有进程
    * -C cmdlist 显示包含在cmdlist列表中的进程
    * -G grplist 显示组ID在grplist列表中的进程
    * -U userlist 显示属主的用户ID在userlist列表中的进程
    * -g grplist 显示会话或组ID在grplist列表中的进程②
    * -p pidlist 显示PID在pidlist列表中的进程
    * -s sesslist 显示会话ID在sesslist列表中的进程
    * -t ttylist 显示终端ID在ttylist列表中的进程
    * -u userlist 显示有效用户ID在userlist列表中的进程
    * -F 显示更多额外输出（相对-f参数而言）
    * -O format 显示默认的输出列以及format列表指定的特定列
    * -M 显示进程的安全信息
    * -c 显示进程的额外调度器信息
    * -f 显示完整格式的输出
    * -j 显示任务信息
    * -l 显示长列表
    * -o format 仅显示由format指定的列
    * -y 不要显示进程标记（ process flag，表明进程状态的标记）
    * -Z 显示安全标签（ security context） ① 信息
    * -H 用层级格式来显示进程（树状，用来显示父进程）
    * -n namelist 定义了WCHAN列显示的值
    * -w 采用宽输出模式，不限宽度显示
    * -L 显示进程中的线程
    * -V 显示ps命令的版本号


常用的参数是-ef,显示的信息为:
* UID：启动这些进程的用户。
* PID：进程的进程ID。
* PPID：父进程的进程号（如果该进程是由另一个进程启动的）。
* C：进程生命周期中的CPU利用率。
* STIME：进程启动时的系统时间。
* TTY：进程启动时的终端设备。
* TIME：运行进程需要的累计CPU时间。
* CMD：启动的程序名称。
```
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 Dec04 ?        00:00:24 /sbin/init splash
root         2     0  0 Dec04 ?        00:00:00 [kthreadd]

```
ps -l参数
* F：内核分配给进程的系统标记。
* S：进程的状态（ O代表正在运行； S代表在休眠； R代表可运行，正等待运行； Z代表僵化，进程已结束但父进程已不存在； T代表停止）。
* PRI：进程的优先级（越大的数字代表越低的优先级）。
* NI：谦让度值用来参与决定优先级。,越大优先级越低,默认为0
* ADDR：进程的内存地址。
* SZ：假如进程被换出，所需交换空间的大致大小。
* WCHAN：进程休眠的内核函数的地址。
```
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
0 S  1000 10646  5959  0  80   0 -  5429 wait   pts/2    00:00:00 bash
4 R  1000 20277 10646  0  80   0 -  6487 -      pts/2    00:00:00 ps

```


##### 1.7.2.7.2. 实时监测进程

ps命令虽然在收集运行在系统上的进程信息时非常有用，但也有不足之处：它只能显示某个特定时间点的信息。如果想观察那些频繁换进换出的内存的进程趋势，用ps命令就不方便了。top命令跟ps命令相似，能够显示进程信息，但它是实时显示的。

```
top - 17:31:35 up 19:11,  1 user,  load average: 1.70, 1.04, 0.77
Tasks: 267 total,   1 running, 217 sleeping,   0 stopped,   0 zombie
%Cpu(s):  4.9 us,  1.1 sy,  0.0 ni, 94.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 10174524 total,   527256 free,  5486668 used,  4160600 buff/cache
KiB Swap:  2097148 total,  2097148 free,        0 used.  3808940 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     
 1842 lgj       20   0  642764 159804 113284 S   5.3  1.6  12:20.79 Xorg 
```
* top信息
    * PID：进程的ID。
    * USER：进程属主的名字。
    * PR：进程的优先级。
    * NI：进程的谦让度值。
    * VIRT：进程占用的虚拟内存总量。
    * RES：进程占用的物理内存总量。
    * SHR：进程和其他进程共享的内存总量。
    * S：进程的状态（ D代表可中断的休眠状态， R代表在运行状态， S代表休眠状态， T代表跟踪状态或停止状态， Z代表僵化状态）。
    * %CPU：进程使用的CPU时间比例。
    * %MEM：进程使用的内存占可用内存的比例。
    * TIME+：自进程启动到目前为止的CPU时间总量。
    * COMMAND：进程所对应的命令行名称，也就是启动的程序名。

##### 1.7.2.7.3. 结束进程

在Linux中，进程之间通过信号来通信。进程的信号就是预定义好的一个消息，进程能识别它并决定忽略还是作出反应。进程如何处理信号是由开发人员通过编程来决定的。大多数编写完善的程序都能接收和处理标准Unix进程信号。

|信 号| 名 称| 描 述|
|---|---|---|
|1 |HUP |挂起
|2 |INT |中断
|3 |QUIT |结束运行
|9 |KILL |无条件终止
|11 |SEGV |段错误
|15 |TERM |尽可能终止
|17 |STOP |无条件停止运行，但不终止
|18 |TSTP |停止或暂停，但继续在后台运行
|19 |CONT |在STOP或TSTP之后恢复执行

在Linux上有两个命令可以向运行中的进程发出进程信号。


**kill命令**

kill命令可通过进程ID（ PID）给进程发信号。默认情况下， kill命令会向命令行中列出的全部PID发送一个TERM信号。遗憾的是，你只能用进程的PID而不能用命令名，所以kill命令有
时并不好用。要发送进程信号，你必须是进程的属主或登录为root用户。
```
$ kill 3940
$ kill -3 3940
```
**killall命令**

killall命令非常强大，它支持通过进程名而不是PID来结束进程。 killall命令也支持通配符，这在系统因负载过大而变得很慢时很有用
```
# killall http*
#
```
上例中的命令结束了所有以http开头的进程.以root用户身份登录系统时，使用killall命令要特别小心，因为很容易就会误用通配符而结束了重要的系统进程。这可能会破坏文件系统。

#### 1.7.2.8. 监测磁盘空间

##### 1.7.2.8.1. df 命令

df命令可以让你很方便地查看所有已挂载磁盘的使用情况。
```bash
~$ df --help
Usage: df [OPTION]... [FILE]...
```


```
$ df
Filesystem     1K-blocks     Used Available Use% Mounted on
udev             5065648        0   5065648   0% /dev
tmpfs            1017456     1836   1015620   1% /run
/dev/sdb2       72417352 60574108   8121568  89% /

```
* 设备的设备文件位置；
* 能容纳多少个1024字节大小的块；
* 已用了多少个1024字节大小的块；
* 还有多少个1024字节大小的块可用；
* 已用空间所占的比例；
* 设备挂载到了哪个挂载点上。

df一个常用的参数是-h。它会把输出中的磁盘空间按照用户易读的形式显示，通常用M来替代兆字节，用G替代吉字节。

##### 1.7.2.8.2. du 命令

另一个有用的命令是du命令。 du命令可以显示某个特定目录（默认情况下是当前目录）的磁盘使用情况。这一方法可用来快速判断系统上某个目录下是不是有超大文件。
默认情况下， du命令会显示当前目录下所有的文件、目录和子目录的磁盘使用情况，它会以磁盘块为单位来表明每个文件或目录占用了多大存储空间。对标准大小的目录来说，这个输出会是一个比较长的列表。
```
du [OPTION]... [FILE]...
or:  du [OPTION]... --files0-from=F

```
每行输出左边的数值是每个文件或目录占用的磁盘块数。注意，这个列表是从目录层级的最底部开始，然后按文件、子目录、目录逐级向上

常用参数
* -c：显示所有已列出文件总的大小。
* -h：按用户易读的格式输出大小，即用K替代千字节，用M替代兆字节，用G替代吉字节。
* -s：显示每个输出参数的总计。


#### 1.7.2.9. 处理数据文件
<a href="#menu" style="float:right">目录</a>

##### 1.7.2.9.1. 排序数据

sort命令按照会话指定的默认语言的排序规则对文本文件中的**数据行**排序。

```
sort [OPTION]... [FILE]...
or:  sort [OPTION]... --files0-from=F

```
```
$ cat txt
rr
bb
AA
aaI rf
BB
$ sort txt
AA
BB
aaI rf
bb
rr

```

如果数据行为数字,需要添加-n参数.

如果用-M参数， sort命令就能识别三字符的月份名
```
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
```
* -b --ignore-leading-blanks 排序时忽略起始的空白
* -C --check=quiet 不排序，如果数据无序也不要报告
* -c --check 不排序，但检查输入数据是不是已排序；未排序的话，报告
* -d --dictionary-order 仅考虑空白和字母，不考虑特殊字符
* -f --ignore-case 默认情况下，会将大写字母排在前面；这个参数会忽略大小写
* -g --general-number-sort 按通用数值来排序（跟-n不同，把值当浮点数来排序，支持科学计数法表示的值）
* -i --ignore-nonprinting 在排序时忽略不可打印字符
* -k --key=POS1[,POS2] 排序从POS1位置开始；如果指定了POS2的话，到POS2位置结束
* -M --month-sort 用三字符月份名按月份排序
* -m --merge 将两个已排序数据文件合并
* -n --numeric-sort 按字符串数值来排序（并不转换为浮点数）
* -o --output=file 将排序结果写出到指定的文件中
* -R --random-sort 按随机生成的散列表的键值排序
* --random-source=FILE 指定-R参数用到的随机字节的源文件
* -r --reverse 反序排序（升序变成降序）
* -S --buffer-size=SIZE 指定使用的内存大小
* -s --stable 禁用最后重排序比较
* -T --temporary-directory=DIR 指定一个位置来存储临时工作文件
* -t --field-separator=SEP 指定一个用来区分键位置的字符
* -u --unique 和-c参数一起使用时，检查严格排序；不和-c参数一起用时，仅输出第一例相似的两行
* -z --zero-terminated 用NULL字符作为行尾，而不是用换行符


##### 1.7.2.9.2. 搜索数据

需要在大文件中找一行数据，而这行数据又埋藏在文件的中间。这时并不需要手动翻看整个文件，用grep命令来帮助查找就行了
```
grep [OPTION]... PATTERN [FILE]...

```
grep命令会在输入或指定的文件中查找包含匹配指定模式的字符的行。 grep的输出就是包含了匹配模式的行

如果要进行反向搜索（输出不匹配该模式的行），可加-v参数。
```
$ grep -v t file1
one
four
five
$
```
如果要显示匹配模式的行所在的行号，可加-n参数。
```
$ grep -n t file1
2:two
3:three
$
```
如果只要知道有多少行含有匹配的模式，可用-c参数。
```
$ grep -c t file1
2
$
```
如果要指定多个匹配模式，可用-e参数来指定每个模式。
```
$ grep -e t -e f file1
two
three
four
five
$
```

##### 1.7.2.9.3. 归档数据

Unix和Linux上最广泛使用的归档工具是tar命令。tar命令最开始是用来将文件写到磁带设备上归档的，然而它也能把输出写到文件里，这种用法在Linux上已经普遍用来归档数据了。

```
tar [OPTION...] [FILE]...
```

|参数	|参数说明|
|---|---|
|-c	|新建打包文件，同 -v 一起使用 查看过程中打包文件名
|-x	|解决文件， -C 解压到对应的文件目录。
|-f	|后面接要处理的文件
|-j	|通过bzip2方式压缩或解压，最后以.tar.br2 为后缀。压缩后大小小于.tar.gz
|-z	|通过gzip方式压缩或解压，最后以.tar.gz 为后缀
|-v	|压缩或解压过程中，显示出来过程
|-t	|查看打包文件中内容，重点文件名
|-u	|更新压缩文件中的内容。
|-p	|保留绝对路径，即允许备份数据中含有根目录
|-P	|保留数据原来权限及属性。
|--exclude =FILE	|压缩过程中，不要讲FILE打包
|man tar	|查看更多参数

说明： -c/-x/-t/u 不可同时出现

* tar -jcv -f 压缩文件名称.tar.br2	压缩方式一
* tar -jxv -f 压缩文件名称.tar.br2 -C 指定文件目录	解压文件方式一
* tar -zcv -f 压缩文件名称.tar.gz	压缩方式二
* tar -zxv -f 压缩文件名称.tar.gz	解压文件方式二
* tar -tf 压缩文件名	查看文件名
* tar -tvf 压缩文件	查看文件：所属权限、用户名用户组、日期等


### 1.7.3. 环境变量

<a href="#menu" style="float:right">目录</a>

#### 1.7.3.1. 什么是环境变量

bash shell用一个叫作环境变量（ environment variable）的特性来存储有关shell会话和工作环境的信息（这也是它们被称作环境变量的原因）。这项特性允许你在内存中存储数据，以便程序
或shell中运行的脚本能够轻松访问到它们。这也是存储持久数据的一种简便方法。

##### 1.7.3.1.1. 全局环境变量

全局环境变量对于shell会话和所有生成的子shell都是可见的。局部变量则只对创建它们的shell可见。这让全局环境变量对那些所创建的子shell需要获取父shell信息的程序来说非常有用。

Linux系统在你开始bash会话时就设置了一些全局环境变量.系统环境变量基本上都是使用全大写字母，以区别于普通用户的环境变量。要查看全局变量，可以使用env或printenv命令
要显示个别环境变量的值，可以使用printenv命令，但是不要用env命令。
```bash
printenv HOME
env HOME
#或者
echo $HOME
```

##### 1.7.3.1.2. 局部环境变量

局部环境变量只能在定义它们的进程中可见.Linux系统也默认定义了标准的局部环境变量。查看局部环境变量的列表有点复杂。遗憾的是，在Linux系统并没有一个只显示局部环境变量的命令。 set命令会显示为某个特定进程设置的所有环境变量，包括局部变量、全局变量以及用户定义变量。所有通过printenv命令能看到的全局环境变量都出现在了set命令的输出中。但在set命令的输出中还有其他一些环境变量，即局部环境变量和用户定义变量。

命令env、 printenv和set之间的差异很细微。 set命令会显示出全局变量、局部变量以及用户定义变量。它还会按照字母顺序对结果进行排序。 env和printenv命令同set命令的区别在于前两个命令不会对变量排序，也不会输出局部变量和用户定义变量。在这种情况下， env和printenv的输出是重复的。不过env命令有一个printenv没有的功能，这使得它要更有用一些。



#### 1.7.3.2. 设置用户定义变量

##### 1.7.3.2.1. 设置局部用户变量

可以在shell脚本文件中或者命令行页面使用name=val来定义局部变量.变量名、等号和值之间没有空格，这一点非常重要。如果在赋值表达式中加上了空格，bash shell就会把值当成一个单独的命令.如果值为多个单词,请用引号圈起来
```
$ name=liang
$ echo $name
liang
```

##### 1.7.3.2.2. 设置全局变量

在设定全局环境变量的进程所创建的子进程中，该变量都是可见的。创建全局环境变量的方法是先创建一个局部环境变量，然后再把它导出到全局环境中。这个过程通过export命令来完成，变量名前面不需要加$。

```bash
export name
```


#### 1.7.3.3. 删除环境变量

可以用unset命令完成这个操作。在unset命令中引用环境变量时，记住不要使用$.如果你是在子进程中删除了一个全局环境变量，这只对子进程有效。该全局环境变量在父进程中依然可用。


在涉及环境变量名时，什么时候该使用$，什么时候不该使用$，实在让人摸不着头脑。记住一点就行了：如果要用到变量，使用$；如果要操作变量，不使用$。这条规则的一个例外就是使用printenv显示某个变量的值。


#### 1.7.3.4. 默认的shell环境变量

默认情况下， bash shell会用一些特定的环境变量来定义系统环境。这些变量在你的Linux系统上都已经设置好了，只管放心使用。

变 量 描 述
* CDPATH 冒号分隔的目录列表，作为cd命令的搜索路径
* HOME 当前用户的主目录
* IFS shell用来将文本字符串分割成字段的一系列字符
* MAIL 当前用户收件箱的文件名（ bash shell会检查这个文件，看看有没有新邮件）
* MAILPATH 冒号分隔的当前用户收件箱的文件名列表（ bash shell会检查列表中的每个文件，看看有没有新邮件）
* OPTARG getopts命令处理的最后一个选项参数值
* OPTIND getopts命令处理的最后一个选项参数的索引号
* PATH shell查找命令的目录列表，由冒号分隔
* PS1 shell命令行界面的主提示符
* PS2 shell命令行界面的次提示符
* FUNCNEST 当设置成非零值时，表示所允许的最大函数嵌套级数（一旦超出，当前命令即被终止）
* GLOBIGNORE 冒号分隔的模式列表，定义了在进行文件名扩展时可以忽略的一组文件名
* GROUPS 含有当前用户属组列表的数组变量
* histchars 控制历史记录扩展，最多可有3个字符
* HISTCMD 当前命令在历史记录中的编号
* HISTCONTROL 控制哪些命令留在历史记录列表中
* HISTFILE 保存shell历史记录列表的文件名（默认是.bash_history）
* HISTFILESIZE 最多在历史文件中存多少行
* HISTTIMEFORMAT 如果设置了且非空，就用作格式化字符串，以显示bash历史中每条命令的时间戳
* HISTIGNORE 由冒号分隔的模式列表，用来决定历史文件中哪些命令会被忽略
* HISTSIZE 最多在历史文件中存多少条命令
* HOSTFILE shell在补全主机名时读取的文件名称
* HOSTNAME 当前主机的名称
* HOSTTYPE 当前运行bash shell的机器
* IGNOREEOF shell在退出前必须收到连续的EOF字符的数量（如果这个值不存在，默认是1）
* INPUTRC Readline初始化文件名（默认是.inputrc）
* LANG shell的语言环境类别
* LC_ALL 定义了一个语言环境类别，能够覆盖LANG变量
* LC_COLLATE 设置对字符串排序时用的排序规则
* LC_CTYPE 决定如何解释出现在文件名扩展和模式匹配中的字符
* LC_MESSAGES 在解释前面带有$的双引号字符串时，该环境变量决定了所采用的语言环境设置
* LC_NUMERIC 决定着格式化数字时采用的语言环境设置
* LINENO 当前执行的脚本的行号
* LINES 定义了终端上可见的行数
* MACHTYPE 用“ CPU公司系统”（ CPU-company-system）格式定义的系统类型
* MAPFILE 一个数组变量，当mapfile命令未指定数组变量作为参数时，它存储了mapfile所读入的文本
* MAILCHECK shell查看新邮件的频率（以秒为单位，默认值是60）
* OLDPWD shell之前的工作目录
* OPTERR 设置为1时， bash shell会显示getopts命令产生的错误
* OSTYPE 定义了shell所在的操作系统
* PIPESTATUS 含有前台进程的退出状态列表的数组变量
* POSIXLY_CORRECT 设置了的话， bash会以POSIX模式启动
* PPID bash shell父进程的PID
* PROMPT_COMMAND 设置了的话，在命令行主提示符显示之前会执行这条命令
* PROMPT_DIRTRIM 用来定义当启用了\w或\W提示符字符串转义时显示的尾部目录名的数量。被删除的目录名会用一组英文句点替换
* PS3 select命令的提示符
* PS4 如果使用了bash的-x选项，在命令行之前显示的提示信息
* PWD 当前工作目录
* RANDOM 返回一个0～ 32767的随机数（对其的赋值可作为随机数生成器的种子）
* READLINE_LINE 当使用bind –x命令时，存储Readline缓冲区的内容
* READLINE_POINT 当使用bind –x命令时，表示Readline缓冲区内容插入点的当前位置
* REPLY read命令的默认变量
* SECONDS 自从shell启动到现在的秒数（对其赋值将会重置计数器）
* SHELL bash shell的全路径名
* SHELLOPTS 已启用bash shell选项列表，列表项之间以冒号分隔
* SHLVL shell的层级；每次启动一个新bash shell，该值增加1
* TIMEFORMAT 指定了shell的时间显示格式
* TMOUT select和read命令在没输入的情况下等待多久（以秒为单位）。默认值为0，表示无限长
* TMPDIR 目录名，保存bash shell创建的临时文件
* UID 当前用户的真实用户ID（数字形式）



#### 1.7.3.5. 设置PATH环境变量

当你在shell命令行界面中输入一个外部命令时， shell必须搜索系统来找到对应的程序。 PATH环境变量定义了用于进行命令和程序查找的目录。应用程序放置可执行文件的目录常常不在PATH环境变量所包含的目录中。解决的办法是保证PATH环境变量包含了所有存放应用程序的目录。PATH中各个目录之间是用冒号分隔的。你只需引用原来的PATH值，然后再给这个字符串添加新目录就行了.

```BASH
PATH=$PATH:/XX/XX/XX
```
以上对PATH变量的修改只能持续到退出或重启系统。

#### 1.7.3.6. 定位系统环境变量

在你登入Linux系统启动一个bash shell时，默认情况下bash会在几个文件中查找命令。这些文件叫作启动文件或环境文件。 bash检查的启动文件取决于你启动bash shell的方式。启动bash
shell有3种方式：
* 登录时作为默认登录shell
* 作为非登录shell的交互式shell
* 作为运行脚本的非交互shell

##### 1.7.3.6.1. 环境变量持久化

对全局环境变量来说（ Linux系统中所有用户都需要使用的变量），可能更倾向于将新的或修改过的变量设置放在/etc/profile文件中，但这可不是什么好主意。如果你升级了所用的发行版，
这个文件也会跟着更新，那你所有定制过的变量设置可就都没有了。
最好是在/etc/profile.d目录中创建一个以.sh结尾的文件。把所有新的或修改过的全局环境变量设置放在这个文件中。


#### 1.7.3.7. 数组变量

环境变量有一个很酷的特性就是，它们可作为数组使用。数组是能够存储多个值的变量。这些值可以单独引用，也可以作为整个数组来引用。要给某个环境变量设置多个值，可以把值放在括号里，值与值之间用空格分隔。

```bash
#定义
mytest=(one two three four five)
#打印第一个值
echo $mytest

#按索引
echo ${mytest[2]}
# *所有数据
echo ${mytest[*]}

#修改某个索引
mytest[2]=seven
# unset命令删除数组中的某个值,该位置为空
unset mytest[2]

# 删除整个数组的值
unset mytest
```

### 1.7.4. 理解Linux文件权限
<a href="#menu" style="float:right">目录</a>

系统中必须有一套能够保护文件免遭非授权用户浏览或修改的机制。 Linux沿用了Unix文件权限的办法，即允许用户和组根据每个文件和目录的安全性设置来访问文件。

#### 1.7.4.1. Linux 安全性

Linux安全系统的核心是用户账户。每个能进入Linux系统的用户都会被分配唯一的用户账户。用户对系统中各种对象的访问权限取决于他们登录系统时用的账户。用户权限是通过创建用户时分配的用户ID（ User ID，通常缩写为UID）来跟踪的。 UID是数值，每个用户都有唯一的UID，但在登录系统时用的不是UID，而是登录名。登录名是用户用来登录系统的最长八字符的字符串（字符可以是数字或字母），同时会关联一个对应的密码。

##### 1.7.4.1.1. /etc/passwd 文件

Linux系统使用一个专门的文件来将用户的登录名匹配到对应的UID值。这个文件就是/etc/passwd文件，它包含了一些与用户有关的信息

```
cat /etc/passwd  
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
lgj:x:1000:1000:lgj,,,:/home/lgj:/bin/bash

```

root用户账户是Linux系统的管理员，固定分配给它的UID是0。就像上例中显示的， Linux系统会为各种各样的功能创建不同的用户账户，而这些账户并不是真的用户。这些账户叫作系统账户，是系统上运行的各种服务进程访问资源用的特殊账户。所有运行在后台的服务都需要用一个系统用户账户登录到Linux系统上。

Linux为系统账户预留了500以下的UID值。有些服务甚至要用特定的UID才能正常工作。为普通用户创建账户时，大多数Linux系统会从500开始，将第一个可用UID分配给这个账户.

/etc/passwd文件的字段包含了如下信息：

* 登录用户名
* 用户密码,/etc/passwd文件中的密码字段都被设置成了x
* 用户账户的UID（数字形式）
* 用户账户的组ID（ GID）（数字形式）
* 用户账户的文本描述（称为备注字段）
* 用户HOME目录的位置
* 用户的默认shell

绝大多数Linux系统都将用户密码保存在另一个单独的文件中（叫作shadow文件，位置在/etc/shadow）。只有特定的程序（比如登录程序）才能访问这个文件。

##### 1.7.4.1.2. /etc/shadow 文件

/etc/shadow文件对Linux系统密码管理提供了更多的控制。只有root用户才能访问/etc/shadow文件，这让它比起/etc/passwd安全许多。

```
sudo cat /etc/shadow
root:!:17896:0:99999:7:::
daemon:*:17737:0:99999:7:::
bin:*:17737:0:99999:7:::
sys:*:17737:0:99999:7:::
lgj:$6$y3NHikSM$Av9t3R45Hji8COM1cWegzv0yyn7QeVCReWmh8mhvdhmWhxZsw2AqU9Ua2e7N523SkooLQPAkmqXx8Rhk8qdbL0:17896:0:99999:7:::

```

在/etc/shadow文件的每条记录中都有9个字段：
* 与/etc/passwd文件中的登录名字段对应的登录名
* 加密后的密码
* 自上次修改密码后过去的天数密码（自1970年1月1日开始计算）
* 多少天后才能更改密码
* 多少天后必须更改密码
* 密码过期前提前多少天提醒用户更改密码
* 密码过期后多少天禁用用户账户
* 用户账户被禁用的日期（用自1970年1月1日到当天的天数表示）
* 预留字段给将来使用
使用shadow密码系统后， Linux系统可以更好地控制用户密码。它可以控制用户多久更改一次密码，以及什么时候禁用该用户账户，如果密码未更新的话。

##### 1.7.4.1.3. 添加新用户

用来向Linux系统添加新用户的主要工具是useradd。这个命令简单快捷，可以一次性创建新用户账户及设置用户HOME目录结构。 useradd命令使用系统的默认值以及命令行参数来设置用户账户。系统默认值被设置在/etc/default/useradd文件中。可以使用加入了-D选项的useradd命令查看所用Linux系统中的这些默认值。在创建新用户时，如果你不在命令行中指定具体的值， useradd命令就会使用-D选项所显示的那些默认值。

```
$ useradd -D
GROUP=100
HOME=/home
INACTIVE=-1
EXPIRE=
SHELL=/bin/sh
SKEL=/etc/skel
CREATE_MAIL_SPOOL=YES
```
* 新用户会被添加到GID为100的公共组；
* 新用户的HOME目录将会位于/home/loginname；
* 新用户账户密码在过期后不会被禁用；
* 新用户账户未被设置过期日期；
* 新用户账户将bash shell作为默认shell；
* 系统会将/etc/skel目录下的内容复制到用户的HOME目录下；
* 系统为该用户账户在mail目录下创建一个用于接收邮件的文件。

倒数第二个值很有意思。 useradd命令允许管理员创建一份默认的HOME目录配置，然后把它作为创建新用户HOME目录的模板。这样就能自动在每个新用户的HOME目录里放置默认的系统文件。在Ubuntu Linux系统上， /etc/skel目录有下列文件：

```
 ls -al /etc/skel
total 40
drwxr-xr-x   2 root root  4096 Jul 25  2018 .
drwxr-xr-x 143 root root 12288 Dec  5 04:15 ..
-rw-r--r--   1 root root   220 Apr  5  2018 .bash_logout
-rw-r--r--   1 root root  3771 Apr  5  2018 .bashrc
-rw-r--r--   1 root root   807 Apr  5  2018 .profile
-rw-r--r--   1 root root  8980 Apr 16  2018 examples.desktop

```
它们是bash shell环境的标准启动文件。系统会自动将这些默认文件复制到你创建的每个用户的HOME目录。

参 数 描 述
* -b default_home 更改默认的创建用户HOME目录的位置
* -e expiration_date 更改默认的新账户的过期日期
* -f inactive 更改默认的新用户从密码过期到账户被禁用的天数
* -g group 更改默认的组名称或GID
* -s shell 更改默认的登录shell
* -c comment 给新用户添加备注
* -d home_dir 为主目录指定一个名字（如果不想用登录名作为主目录名的话）
* -e expire_date 用YYYY-MM-DD格式指定一个账户过期的日期
* -f inactive_days 指定这个账户密码过期后多少天这个账户被禁用； 0表示密码一过期就立即禁用， 1表示禁用这个功能
* -g initial_group 指定用户登录组的GID或组名
* -G group ... 指定用户除登录组之外所属的一个或多个附加组
* -k 必须和-m一起使用，将/etc/skel目录的内容复制到用户的HOME目录
* -m 创建用户的HOME目录
* -M 不创建用户的HOME目录（当默认设置里要求创建时才使用这个选项）
* -n 创建一个与用户登录名同名的新组
* -r 创建系统账户
* -p passwd 为用户账户指定默认密码
* -s shell 指定默认的登录shell
* -u uid 为账户指定唯一的UID

##### 1.7.4.1.4. 删除用户

默认情况下， userdel命令会只删除/etc/passwd文件中的用户信息，而不会删除系统中属于该账户的任何文件。如果加上-r参数， userdel会删除用户的HOME目录以及邮件目录(需要小心,防止误删除文件)。然而，系统上仍可能存有已删除用户的其他文件。这在有些环境中会造成问题。
```bash
userdel -r test
```

##### 1.7.4.1.5. 修改用户

用户账户修改工具

|命 令 |描 述|
|---|---|
|usermod |修改用户账户的字段，还可以指定主要组以及附加组的所属关系
|passwd |修改已有用户的密码
|chpasswd |从文件中读取登录名密码对，并更新密码
|chage |修改密码的过期日期
|chfn |修改用户账户的备注信息
|chsh |修改用户账户的默认登录shell

**usermod**

usermod命令是用户账户修改工具中最强大的一个。它能用来修改/etc/passwd文件中的大部分字段，只需用与想修改的字段对应的命令行参数就可以了。参数大部分跟useradd命令的参数一样（比如， -c修改备注字段， -e修改过期日期， -g修改默认的登录组）。除此之外，还有另外一些可能派上用场的选项。
* -l修改用户账户的登录名。
* -L锁定账户，使用户无法登录。
* -p修改账户的密码。
* -U解除锁定，使用户能够登录。

**passwd和chpasswd**

改变用户密码的一个简便方法就是用passwd命令。如果只用passwd命令，它会改你自己的密码。系统上的任何用户都能改自己的密码，但只有root用户才有权限改别人的密码。

如果需要为系统中的大量用户修改密码， chpasswd命令可以事半功倍。 chpasswd命令能从标准输入自动读取登录名和密码对（由冒号分割）列表，给密码加密，然后为用户账户设置。你也可以用重定向命令来将含有userid:passwd对的文件重定向给该命令。
```
# chpasswd < users.txt
```

#### 1.7.4.2. 使用Linux组

用户账户在控制单个用户安全性方面很好用，但涉及在共享资源的一组用户时就捉襟见肘了。为了解决这个问题， Linux系统采用了另外一个安全概念——组（ group）。组权限允许多个用户对系统中的对象（比如文件、目录或设备等）共享一组共用的权限。每个组都有唯一的GID——跟UID类似，在系统上这是个唯一的数值。除了GID，每个组还有唯一的组名。 

##### 1.7.4.2.1. /etc/group 文件

与用户账户类似，组信息也保存在系统的一个文件中。 /etc/group文件包含系统上用到的每个组的信息。
```
$ cat /etc/group
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:

```
* 组名
* 组密码
* GID
* 属于该组的用户列表

##### 1.7.4.2.2. 创建新组

组密码允许非组内成员通过它临时成为该组成员。这个功能并不很普遍，但确实存在。千万不能通过直接修改/etc/group文件来添加用户到一个组，要用usermod命令.在添加用户到不同的组之前，首先得创建组。

groupadd命令可在系统上创建新组。

```
groupadd  group_name
```
在创建新组时，默认没有用户被分配到该组。 groupadd命令没有提供将用户添加到组中的选项，但可以用usermod命令来弥补这一点。

```
sermod -G group_name  user_name
```
-G选项会把这个新组添加到该用户账户的组列表里。

为用户账户分配组时要格外小心。如果加了-g选项，指定的组名会替换掉该账户的默认组。 -G选项则将该组添加到用户的属组的列表里，不会影响默认组。


##### 1.7.4.2.3. 修改组

在/etc/group文件中可以看到，需要修改的组信息并不多。 groupmod命令可以修改已有组的GID（加-g选项）或组名（加-n选项）。

```
groupmod -n new_name old_name
```
修改组名时， GID和组成员不会变，只有组名改变。由于所有的安全权限都是基于GID的，你可以随意改变组名而不会影响文件的安全性。

#### 1.7.4.3. 理解文件权限

##### 1.7.4.3.1. 使用文件权限符

```
$ ls -l
total 322056
-rw-rw-r--  1 lgj  lgj        19003 Aug 17 21:59  9be419dbly1g617zg1l6bj208q0dwq37.jpg
drwxrwxr-x  2 lgj lgj         4096 2019-09-03 15:12 test2
```
* -代表文件
* d代表目录
* l代表链接
* c代表字符型设备
* b代表块设备
* n代表网络设备

之后有3组三字符的编码。每一组定义了3种访问权限：
* r代表对象是可读的
* w代表对象是可写的
* x代表对象是可执行的

若没有某种权限，在该权限位会出现单破折线。这3组权限分别对应对象的3个安全级别：
* 对象的属主
* 对象的属组
* 系统其他用户

**Linux文件权限码**
|权 限 |二进制值 |八进制值 |描 述|
|---|---|---|---|
|--- |000 |0 |没有任何权限
|--x |001 |1 |只有执行权限
|-w- | 010 |2 |只有写入权限
|-wx | 011 |3 |有写入和执行权限
|r-- | 100 |4 |只有读取权限
|r-x | 101 |5 |有读取和执行权限
|rw- | 110 |6 |有读取和写入权限
|rwx | 111 |7 |有全部权限



#### 1.7.4.4. 改变安全性设置

**修改文件权限**
```bash
chmod 723 filename
chmod u+x filename 
chmod g+r filename 
chmod o+r filename 
chmod g-r filename 
chmod o-r filename 
```


**改变所属关系**

Linux提供了两个命令来实现这个功能： chown命令用来改变文件的属主，chgrp命令用来改变文件的默认属组。

chown命令的格式如下。
```bash
chown options owner[.group] file

chown dan.shared newfile
#如果你不嫌麻烦，可以只改变一个目录的默认属组。
chown .rich newfile
```
chown命令采用一些不同的选项参数。 -R选项配合通配符可以递归地改变子目录和文件的所属关系。 -h选项可以改变该文件的所有符号链接文件的所属关系
只有root用户能够改变文件的属主。任何属主都可以改变文件的属组，但前提是属主必须是原属组和目标属组的成员。

chgrp命令可以更改文件或目录的默认属组
```bash
chgrp shared newfile
```
用户账户必须是这个文件的属主，除了能够更换属组之外，还得是新组的成员。现在shared组的任意一个成员都可以写这个文件了

#### 1.7.4.5. 共享文件

创建新文件时， Linux会用你默认的UID和GID给文件分配权限。想让其他人也能访问文件，要么改变其他用户所在安全组的访问权限，要么就给文件分配一个包含其他用户的新默认属组

如果你想在大范围环境中创建文档并将文档与人共享，这会很烦琐。幸好有一种简单的方法可以解决这个问题。

Linux还为每个文件和目录存储了3个额外的信息位。
* 设置用户ID（ SUID） ：当文件被用户使用时，程序会以文件属主的权限运行。
* 设置组ID（ SGID） ：对文件来说，程序会以文件属组的权限运行；对目录来说，目录中创建的新文件会以目录的默认属组作为默认属组。
* 粘着位：进程结束后文件还驻留（粘着）在内存中。

SGID位对文件共享非常重要。启用SGID位后，你可以强制在一个共享目录下创建的新文件都属于该目录的属组，这个组也就成为了每个用户的属组。

GID可通过chmod命令设置。它会加到标准3位八进制值之前（组成4位八进制值），或者在符号模式下用符号s。如果你用的是八进制模式，你需要知道这些位的位置

**chmod SUID、 SGID和粘着位的八进制值**

|二进制值 |八进制值 |描 述|
|---|---|---|
|000 |0 |所有位都清零
|001 |1 |粘着位置位
|010 |2 |SGID位置位
|011 |3 |SGID位和粘着位都置位
|100 |4 |SUID位置位
|101 |5 |SUID位和粘着位都置位
|110 |6 |SUID位和SGID位都置位
|111 |7 |所有位都置位

要创建一个共享目录，使目录里的新文件都能沿用目录的属组，只需将该目录的SGID位置位。

```bash
$ mkdir testdir
$ ls -l
drwxrwxr-x 2 rich rich 4096 Sep 20 23:12 testdir/
$ chgrp shared testdir
$ chmod g+s testdir
$ ls -l
drwxrwsr-x 2 rich shared 4096 Sep 20 23:12 testdir/
$ umask 002
$ cd testdir
$ touch testfile
$ ls -l
total 0
-rw-rw-r-- 1 rich shared 0 Sep 20 23:13 testfile
$
```
首先，用mkdir命令来创建希望共享的目录。然后通过chgrp命令将目录的默认属组改为包含所有需要共享文件的用户的组（你必须是该组的成员）。最后，将目录的SGID位置位，以保证目录中新建文件都用shared作为默认属组。
为了让这个环境能正常工作，所有组成员都需把他们的umask值设置成文件对属组成员可写。在前面的例子中， umask改成了002，所以文件对属组是可写的。
做完了这些，组成员就能到共享目录下创建新文件了。跟期望的一样，新文件会沿用目录的属组，而不是用户的默认属组。现在shared组的所有用户都能访问这个文件了。

### 1.7.5. 管理文件系统
<a href="#menu" style="float:right">目录</a>

#### 1.7.5.1. Linux 文件系统

**ext文件系统**

Linux操作系统中引入的最早的文件系统叫作扩展文件系统（ extended filesystem，简记为ext）。它为Linux提供了一个基本的类Unix文件系统：使用虚拟目录来操作硬件设备，在物理设备上按定长的块来存储数据。

ext文件系统采用名为索引节点的系统来存放虚拟目录中所存储文件的信息。索引节点系统在每个物理设备中创建一个单独的表（称为索引节点表）来存储这些文件的信息。存储在虚拟目录中的每一个文件在索引节点表中都有一个条目。 ext文件系统名称中的extended部分来自其跟踪的每个文件的额外数据，包括：


#### 1.7.5.2. 操作文件系统
#### 1.7.5.3. 逻辑文件系统



### 1.7.6. Shell脚本编程

#### 1.7.6.1. 基本脚本命令

<a href="#menu" style="float:right">目录</a>

##### 1.7.6.1.1. 创建 shell 脚本文件

在创建shell脚本文件时，必须在文件的第一行指定要使用的shell:
```bash
#!/bin/bash
```
在通常的shell脚本中，井号（ #）用作注释行。 shell并不会处理shell脚本中的注释行。然而，shell脚本文件的第一行是个例外， #后面的惊叹号会告诉shell用哪个shell来运行脚本.

编写完成后,保存为test.sh,并修改文件权限为可执行文件.
```bash
#用户权限增加执行
chmod u+x test.sh
```
两种方式运行:
第一种:直接使用"./"命令
```bash
./test.sh
```
第二种:直接让shell自动搜索该文件并执行.需要在环境变量中添加该执行脚本的目录

```bash

PATH=$PATH:/xxx/xxx
#直接执行
test.sh

```

##### 1.7.6.1.2. 脚本中打印

使用echo命令.

```bash
echo this is a test!
```
echo命令可用单引号或双引号来划定文本字符串。如果在字符串中用到了它们，你需要在文本中使用其中一种引号，而用另外一种来将字符串划定起来

echo 后面会自动换行,如果取消换行,可以使用-n参数.

##### 1.7.6.1.3. 使用变量

用户也可以自定义变量
* 用户变量可以是任何由字母、数字或下划线组成的文本字符串，长度不超过20个。用户变量区分大小写，所以变量Var1和变量var1是不同的
* 使用等号将值赋给用户变量。在变量、等号和值之间不能出现空格
* hell脚本会自动决定变量值的数据类型。在脚本的整个生命周期里， shell脚本中定义的变量会一直保持着它们的值，但在shell脚本结束时会被删除掉
* 使用变量,在变量前加"$",而引用变量来对其进行赋值时则不要使用美元符号
```bash
name="libai"

echo $name
```

##### 1.7.6.1.4. 命令替换

shell脚本中最有用的特性之一就是可以从命令输出中提取信息，并将其赋给变量.
有两种方法可以将命令输出赋给变量：
* 反引号字符（`）
* $()格式

```
testing='date'
testing=$(date)
echo "The date and time are: " $testing

today=$(date +%y%m%d)

```
+%y%m%d格式告诉date命令将日期显示为两位数的年月日的组合

##### 1.7.6.1.5. 重定向输入和输出

* 输出重定向

最基本的重定向将命令的输出发送到一个文件中,bash shell用大于号（>）来完成这项功能,追加内容使用(>>)
```
command > test.txt
```
定向操作符创建了一个文件test.txt（通过默认的umask设置），并将命令的输出重定向到该文件中。如果输出文件已经存在了，重定向操作符会用新的文件数据覆盖已有文件。

* 输入重定向

输入重定向和输出重定向正好相反。输入重定向将文件的内容重定向到命令，而非将命令的输出重定向到文件


##### 1.7.6.1.6. 管道
有时需要将一个命令的输出作为另一个命令的输入,使用"|".
```bash
command1 | command2
```
不要以为由管道串起的两个命令会依次执行。 Linux系统实际上会同时运行这两个命令，在系统内部将它们连接起来。在第一个命令产生输出的同时，输出会被立即送给第二个命令。数据传输不会用到任何中间文件或缓冲区。

##### 1.7.6.1.7. 执行数学运算

**基本数学运算**
```bahs
var1=$[1 + 5]
var2=$[$var1 * 2]
var4=$[$var1 * ($var2 - $var3)]
```
上面的数学运算不支持浮点运算

**浮点操作**


##### 1.7.6.1.8. 退出脚本

shell中运行的每个命令都使用退出状态码（ exit status）告诉shell它已经运行完毕。退出状态码是一个0～ 255的整数值，在命令结束运行时由命令传给shell。可以捕获这个值并在脚本中使用

默认情况下， shell脚本会以脚本中的最后一个命令的退出状态码退出。也可以主动调用exit命令退出.

Linux提供了一个专门的变量$?来保存上个已执行命令的退出状态码。对于需要进行检查的命令，必须在其运行完毕后立刻查看或使用$?变量。它的值会变成由shell所执行的最后一条命令的退出状态码.

|状 态 码 |描 述|
|---|---|
|0 |命令成功结束
|1 |一般性未知错误
|2 |不适合的shell命令
|126 |命令不可执行
|127 |没找到命令
|128 |无效的退出参数
|128+x |与Linux信号x相关的严重错误
|130 |通过Ctrl+C终止的命令
|255 |正常范围之外的退出状态码



#### 1.7.6.2. 结构化命令
<a href="#menu" style="float:right">目录</a>

##### 1.7.6.2.1. 使用 if-then 语句

```bash
if command
then
   commands
fi
```
bash shell的if语句会运行if后面的那个命令。如果该命令的退出状态码是0（该命令成功运行），位于then部分的命令就会被执行。如果该命令的退出状态码是其他值， then部分的命令就不会被执行， bash shell会继续执行脚本中的下一个命令。 fi语句用来表示if-then语句到此结束

##### 1.7.6.2.2. if-then-else 语句

```bash
if command
then
    commands
else
    commands
fi
```
当if语句中的命令返回退出状态码0时， then部分中的命令会被执行，这跟普通的if-then语句一样。当if语句中的命令返回非零退出状态码时， bash shell会执行else部分中的命令。


##### 1.7.6.2.3. 嵌套 if

```bash
if command1
then
    commands
elif command2
    then
    more commands
fi
```

##### 1.7.6.2.4. test 命令

if-then语句只能判断命令的退出状态码,不能判断其他,比如比较两个数值的大小.test命令提供了在if-then语句中测试不同条件的途径。如果test命令中列出的条件成立，test命令就会退出并返回退出状态码0.如果条件不成立， test命令就会退出并返回非零的退出状态码，这使得if-then语句不会再被执行。

```bash
test condition
```

test命令可以判断三类条件：
* 数值比较
* 字符串比较
* 文件比较


bash shell提供了另一种条件测试方法，无需在if-then语句中声明test命令。方括号定义了测试条件。注意，第一个方括号之后和第二个方括号之前必须加上一个空格，否则就会报错。
```bash
if [ condition ]
then
commands
fi
```

**test命令的数值比较功能**

|比 较 |描 述|
|---|---|
|n1 -eq n2 |检查n1是否与n2相等
|n1 -ge n2 |检查n1是否大于或等于n2
|n1 -gt n2 |检查n1是否大于n2
|n1 -le n2 |检查n1是否小于或等于n2
|n1 -lt n2 |检查n1是否小于n2
|n1 -ne n2 |检查n1是否不等于n2

以上仅支持整数,不支持浮点数

```bash
if [ $value1 -gt 5 ]
```

**字符串比较**

|比 较 |描 述|
|---|---|
|str1 = str2 |检查str1是否和str2相同
|str1 != str2 |检查str1是否和str2不同
|str1 < str2 |检查str1是否比str2小
|str1 > str2| 检查str1是否比str2大
|-n str1 |检查str1的长度是否非0
|-z str1 |检查str1的长度是否为0

上面的使用大于号和小于号必须转义，否则shell会把它们当作重定向符号，把字符串值当作文件名
```bash
if [ $val1 \> $val2 ]
```

大于和小于顺序和sort命令所采用的不同。比较测试中使用的是标准的ASCII顺序，根据每个字符的ASCII数值来决定排序结果。 sort命令使用的是系统的本地化语言设置中定义的排序顺序。对于英语，本地化设置指定了在排序顺序中小写字母出现在大写字母前。

test命令和测试表达式使用标准的数学比较符号来表示字符串比较，而用文本代码来表示数值比较。这个细微的特性被很多程序员理解反了。如果你对数值使用了数学运算符号， shell会将它们当成字符串值，可能无法得到正确的结果。

**字符串大小**
-n和-z可以检查一个变量是否含有数据。

if [ -n $val1 ]
判断val1变量是否长度非0
if [ -z $var2 ]
判断val2变量是否长度为0


**文件比较**

|比 较| 描 述|
|---|---|
|-d file |检查file是否存在并是一个目录
|-e file |检查file是否存在
|-f file |检查file是否存在并是一个文件
|-r file |检查file是否存在并可读
|-s file |检查file是否存在并非空
|-w file |检查file是否存在并可写
|-x file |检查file是否存在并可执行
|-O file |检查file是否存在并属当前用户所有
|-G file |检查file是否存在并且默认组与当前用户相同
|file1 -nt file2 |检查file1是否比file2新
|file1 -ot file2 |检查file1是否比file2旧

##### 1.7.6.2.5. 复合条件测试

if-then语句允许你使用布尔逻辑来组合测试。有两种布尔运算符可用：
* [ condition1 ] && [ condition2 ]
* [ condition1 ] || [ condition2 ]

##### 1.7.6.2.6. if-then 的高级特性

bash shell提供了两项可在if-then语句中使用的高级特性：
* 用于数学表达式的双括号
* 用于高级字符串处理功能的双方括号

双括号命令的格式如下：
```bash
(( expression ))
```

expression可以是任意的数学赋值或比较表达式。除了test命令使用的标准数学运算符，双括号命令中会用到的其他运算符。

|符 号| 描 述|
|---|---|
|val++ |后增
|val-- |后减
|++val |先增
|--val |先减
|! |逻辑求反
|~ |位求反
|**| 幂运算
|<< |左位移
|>> |右位移
|& |位布尔和
|\| |位布尔或
|&& |逻辑和
| \|\| |逻辑或

可以在if语句中用双括号命令，也可以在脚本中的普通命令里使用来赋值。

```bash
if (( $val1 ** 2 > 90 ))
then
(( val2 = $val1 ** 2 ))
echo "The square of $val1 is $val2"
fi
```

双方括号命令提供了针对字符串比较的高级特性。双方括号命令的格式如下：
```bash
[[ expression ]]
```

双方括号里的expression使用了test命令中采用的标准字符串比较。但它提供了test命令未提供的另一个特性——模式匹配（ pattern matching）。
双方括号在bash shell中工作良好。不过要小心，不是所有的shell都支持双方括号。

在模式匹配中，可以定义一个正则表达式来匹配字符串值。

```bash
if [[ $USER == r* ]]
then
echo "Hello $USER"
else
echo "Sorry, I do not know you"
fi
```

##### 1.7.6.2.7. case 命令


有了case命令，就不需要再写出所有的elif语句来不停地检查同一个变量的值了。 case命令会采用列表格式来检查单个变量的多个值。

```bash
case variable in
pattern1 | pattern2) commands1;;
pattern3) commands2;;
*) default commands;;
esac
```

```bash
case $USER in
rich | barbara)
echo "Welcome, $USER"
echo "Please enjoy your visit";;
testing)
echo "Special testing account";;
jessica)
echo "Do not forget to log off when you're done";;
*)
echo "Sorry, you are not allowed here";;
esac
```
#### 1.7.6.3. 更多结构化命令
<a href="#menu" style="float:right">目录</a>

##### 1.7.6.3.1. for命令

bash shell提供了for命令，允许你创建一个遍历一系列值的循环。每次迭代都使用其中一个值来执行已定义好的一组命令

```bash
for var in list
do
commands
done
```

```bash
for test in Alabama Alaska Arizona Arkansas California Colorado
do
echo The next state is $test
done
```

如果字符串列表中包含单引号,就会出现问题,单引号之间的多个字符就被当作一个字符.
有两种办法可解决这个问题：
* 使用转义字符（反斜线）来将单引号转义；
* 使用双引号来定义用到单引号的值。

for循环假定每个值都是用空格分割的,但有的词语是多个单词组成的,比如人名.此时应该使用双引号圈起来.另外要注意的是，在某个值两边使用双引号时， shell并不会将双引号当成值的一部分。

**从变量读取列表**

```bash
list="Alabama Alaska Arizona Arkansas Colorado"
for state in $list
do
echo "Have you ever visited $state?"
done
```
**从命令读取值**

```bash
for state in $(cat $file)
do
echo "Visit beautiful $state"
done
```

**更改字段分隔符**
IFS环境变量定义了bash shell用作字段分隔符的一系列字符.默认情况下， bash shell会将下列字符当作字段分隔符：
* 空格
* 制表符
* 换行符

```bash
#将这个语句加入到脚本中，告诉bash shell在数据值中忽略空格和制表符
IFS=$'\n'
for state in $(cat $file)
do
echo "Visit beautiful $state"
done
```

在处理代码量较大的脚本时，可能在一个地方需要修改IFS的值，然后忽略这次修改，在脚本的其他地方继续沿用IFS的默认值。一个可参考的安全实践是在改变IFS之前保存原来的IFS值，之后再恢复它。这种技术可以这样实现：
```bash
IFS.OLD=$IFS
IFS=$'\n'
```
<在代码中使用新的IFS值>
```bash
IFS=$IFS.OLD
```

这就保证了在脚本的后续操作中使用的是IFS的默认值。

自定义任意字符为分隔符
```bash
IFS=a

for val in bac

do 
   echo $val
done
#输出
b c
```

IFS=$'\n':;"
这个赋值会将换行符、冒号、分号和双引号作为字段分隔符。如何使用IFS字符解析数据没有任何限制。

**用通配符读取目录**

可以用for命令来自动遍历目录中的文件。进行此操作时，必须在文件名或路径名中使用通配符。它会强制shell使用文件扩展匹配。文件扩展匹配是生成匹配指定通配符的文件名或路径名的过程。

```bash
for file in /home/rich/test/* /home/rich/test1/*
do
if [ -d "$file" ]
then
echo "$file is a directory"
elif [ -f "$file" ]
then
echo "$file is a file"
fi
done
```
在Linux中，目录名和文件名中包含空格当然是合法的。要适应这种情况，应该将$file变量用双引号圈起来。如果不这么做，遇到含有空格的目录名或文件名时就会有错误产生。

##### 1.7.6.3.2. C 语言的 for 命令

```bash
for (( i=1; i <= 10; i++ ))
do
echo "The next number is $i"
done

for (( a=1, b=10; a <= 10; a++, b-- ))
do
echo "$a - $b"
done
```
##### 1.7.6.3.3. while 命令

```bash
while命令的格式是：
while test command
do
other commands
done

```
while命令中定义的test command和if-then语句中的格式一模一样。可以使用任何普通的bash shell命令，或者用test命令进行条件测试，比如测试变量值。
while命令的关键在于所指定的test command的退出状态码必须随着循环中运行的命令而改变。如果退出状态码不发生变化， while循环就将一直不停地进行下去。
```bash
while [ $var1 -gt 0 ]
do
echo $var1
var1=$[ $var1 - 1 ]
done

```
while命令允许你在while语句行定义多个测试命令。只有最后一个测试命令的退出状态码会被用来决定什么时候结束循环。
```bash
while echo $var1
[ $var1 -ge 0 ]
do
echo "This is inside the loop"
var1=$[ $var1 - 1 ]
done
```
##### 1.7.6.3.4. until 命令

until命令和while命令工作的方式完全相反。 until命令要求你指定一个通常返回非零退出状态码的测试命令。只有测试命令的退出状态码不为0， bash shell才会执行循环中列出的命令。一旦测试命令返回了退出状态码0，循环就结束了

和while命令类似，你可以在until命令语句中放入多个测试命令。只有最后一个命令的退出状态码决定了bash shell是否执行已定义的other commands。

```bash
until test commands
do
    other commands
done
```

##### 1.7.6.3.5. 控制循环

有两个命令能帮我们控制循环内部的情况：
* break命令
* continue命令

##### 1.7.6.3.6. 处理循环的输出

```bash
在shell脚本中，你可以对循环的输出使用管道或进行重定向。这可以通过在done命令
之后添加一个处理命令来实现。
for file in /home/rich/*
do
if [ -d "$file" ]
then
echo "$file is a directory"
elif
echo "$file is a file"
fi
done > output.txt

```
shell会将for命令的结果重定向到文件output.txt中，而不是显示在屏幕上。

#### 1.7.6.4. 处理用户输入
<a href="#menu" style="float:right">目录</a>

##### 1.7.6.4.1. 命令行参数

**命令行参数**
向shell脚本传递数据的最基本方法是使用命令行参数。命令行参数允许在运行脚本时向命令行添加数据。
```bash
$ ./addem 10 30
```

**读取参数**
bash shell会将一些称为位置参数（ positional parameter）的特殊变量分配给输入到命令行中的所有参数。这也包括shell所执行的脚本名称。位置参数变量是标准的数字： $0是程序名， $1是第一个参数， $2是第二个参数，依次类推，直到第九个参数$9.如果脚本需要的命令行参数不止9个，你仍然可以处理，但是需要稍微修改一下变量名。在第9个变量之后，你必须在变量数字周围加上花括号，比如${10}

如果需要输入更多的命令行参数，则每个参数都必须用空格分开。

但是这里存在一个潜在的问题。如果使用另一个命令来运行shell脚本，命令会和脚本名混在一起，出现在$0参数中。当传给$0变量的实际字符串不仅仅是脚本名，而是完整的脚本路径时，变量$0就会使用整个路径。

basename命令会返回不包含路径的脚本名。

```bash
$(basename $0)
```

当脚本认为参数变量中会有数据而实际上并没有时，脚本很有可能会产生错误消息。这种写脚本的方法并不可取。在使用参数前一定要检查其中是否存在数据。
```bash
if [ -n "$1" ]
then
echo Hello $1, glad to meet you.
else
echo "Sorry, you did not identify yourself. "
fi
```



##### 1.7.6.4.2. 特殊参数变量

* 特殊变量$#含有脚本运行时携带的命令行参数的个数。可以在脚本中任何地方使用这个特殊变量，就跟普通变量一样.
* 变量${$#}或者${!#}就代表了最后一个命令行参数变量,当命令行上没有任何参数时， $#的值为0，params变量的值也一样，但${!#}变量会返回命令行用到的脚本名。
* $*和$@变量可以用来轻松访问所有的参数。这两个变量都能够在单个变量中存储所有的命令行参数。
* $*变量会将命令行上提供的所有参数当作一个单词保存。这个单词包含了命令行中出现的每一个参数值。基本上$*变量会将这些参数视为一个整体，而不是多个个体。
* 另一方面， $@变量会将命令行上提供的所有参数当作同一字符串中的多个独立的单词。这样你就能够遍历所有的参数值，得到每个参数。这通常通过for命令完成

##### 1.7.6.4.3. 移动变量

bash shell工具箱中另一件工具是shift命令。 bash shell的shift命令能够用来操作命令行参数。跟字面上的意思一样， shift命令会根据它们的相对位置来移动命令行参数。
在使用shift命令时，默认情况下它会将每个参数变量向左移动一个位置。所以，变量$3的值会移到$2中，变量$2的值会移到$1中，而变量$1的值则会被删除（注意，变量$0的值，也就是程序名，不会改变）。
这是遍历命令行参数的另一个好方法，尤其是在你不知道到底有多少参数时。你可以只操作第一个参数，移动参数，然后继续操作第一个参数。

使用shift命令的时候要小心。如果某个参数被移出，它的值就被丢弃了，无法再恢复.

```bash
count=1
while [ -n "$1" ]
do
echo "Parameter #$count = $1"
count=$[ $count + 1 ]
shift
done

```
也可以一次性移动多个位置，只需要给shift命令提供一个参数，指明要移动的位置数就行了。

```bash
shift 2
```
##### 1.7.6.4.4. 处理选项

选项是跟在单破折线后面的单个字母，它能改变命令的行为。

**处理简单选项**

```bash
while [ -n "$1" ]
do
    case "$1" in
        -a) echo "Found the -a option" ;;
        -b) echo "Found the -b option" ;;
        -c) echo "Found the -c option" ;;
        *) echo "$1 is not an option" ;;
    esac
shift
done
```
**分离参数和选项**

想在shell脚本中同时使用选项和参数的情况。 Linux中处理这个问题的标准方式是用特殊字符来将二者分开，该字符会告诉脚本何时选项结束以及普通参数何时开始。

```bash
while [ -n "$1" ]
do
case "$1" in
-a) echo "Found the -a option" ;;
-b) echo "Found the -b option";;
-c) echo "Found the -c option" ;;
--) shift
break ;;
*) echo "$1 is not an option";;
esac
shift
done
```

**处理带值的选项**
有些选项会带上一个额外的参数值。在这种情况下，命令行看起来像下面这样。
```bash
$ ./testing.sh -a test1 -b -c -d test2
```
```bash
while [ -n "$1" ]
do
    case "$1" in
        -a) echo "Found the -a option";;
        -b) param="$2"
        echo "Found the -b option, with parameter value $param"
        shift ;;
        -c) echo "Found the -c option";;
        --) shift
        break ;;
        *) echo "$1 is not an option";;
    esac
shift
done
#
```

**使用 getopt 命令**

getopt命令是一个在处理命令行选项和参数时非常方便的工具。它能够识别命令行参数，从而在脚本中解析它们时更方便

命令的格式
getopt命令可以接受一系列任意形式的命令行选项和参数，并自动将它们转换成适当的格式。它的命令格式如下：getopt optstring parameters
optstring是这个过程的关键所在。它定义了命令行有效的选项字母，还定义了哪些选项字母需要参数值。

首先，在optstring中列出你要在脚本中用到的每个命令行选项字母。然后，在每个需要参数值的选项字母后加一个冒号。 getopt命令会基于你定义的optstring解析提供的参数。

```bash
$ getopt ab:cd -a -b test1 -cd test2 test3
#输出
 -a -b test1 -c -d -- test2 test3

```
optstring定义了四个有效选项字母： a、 b、 c和d。冒号（ :）被放在了字母b后面，因为b选项需要一个参数值。当getopt命令运行时，它会检查提供的参数列表（ -a -b test1 -cd
test2 test3），并基于提供的optstring进行解析。注意，它会自动将-cd选项分成两个单独的选项，并插入双破折线来分隔行中的额外参数。

如果指定了一个不在optstring中的选项，默认情况下， getopt命令会产生一条错误消息。

```bash
$ getopt ab:cd -a -b test1 -cde test2 test3
getopt: invalid option -- e
-a -b test1 -c -d -- test2 test3
$
```
如果想忽略这条错误消息，可以在命令后加-q选项。
```bash
$ getopt -q ab:cd -a -b test1 -cde test2 test3
-a -b 'test1' -c -d -- 'test2' 'test3'
$
```
注意， getopt命令选项必须出现在optstring之前。现在应该可以在脚本中使用此命令处
理命令行选项了。

**在脚本中使用getopt**

可以在脚本中使用getopt来格式化脚本所携带的任何命令行选项或参数，但用起来略微复杂。方法是用getopt命令生成的格式化后的版本来替换已有的命令行选项和参数。用set命令能够做到。

set命令的选项之一是双破折线（ --），它会将命令行参数替换成set命令的命令行值。然后，该方法会将原始脚本的命令行参数传给getopt命令，之后再将getopt命令的输出传给set命令，用getopt格式化后的命令行参数来替换原始的命令行参数，看起来如下所示。
set -- $(getopt -q ab:cd "$@")
现在原始的命令行参数变量的值会被getopt命令的输出替换，而getopt已经为我们格式化好了命令行参数。

```bash
set -- $(getopt -q ab:cd "$@")
while [ -n "$1" ]
do
    case "$1" in
        -a) echo "Found the -a option" ;;
        -b) param="$2"
        echo "Found the -b option, with parameter value $param"
        shift ;;
        -c) echo "Found the -c option" ;;
        --) shift
        break ;;
        *) echo "$1 is not an option";;
    esac
    shift
done

count=1
for param in "$@"
do
echo "Parameter #$count: $param"
count=$[ $count + 1 ]
done


```

```bash
./test18.sh -a -b test1 -cd "test2 test3" test4
Found the -a option
Found the -b option, with parameter value 'test1'
Found the -c option
Parameter #1: 'test2
Parameter #2: test3'
Parameter #3: 'test4
```
getopt命令并不擅长处理带空格和引号的参数值。它会将空格当作参数分隔符，而不是根据双引号将二者当作一个参数。幸而还有另外一个办法能解决这个问题。


**使用更高级的 getopts**

getopts命令（注意是复数）内建于bash shell。它跟近亲getopt看起来很像，但多了一些扩展功能。

与getopt不同，前者将命令行上选项和参数处理后只生成一个输出，而getopts命令能够和已有的shell参数变量配合默契。
每次调用它时，它一次只处理命令行上检测到的一个参数。处理完所有的参数后，它会退出并返回一个大于0的退出状态码。这让它非常适合用解析命令行所有参数的循环中。
getopts命令的格式如下：
```bash
getopts optstring variable
```
optstring值类似于getopt命令中的那个。有效的选项字母都会列在optstring中，如果选项字母要求有个参数值，就加一个冒号。要去掉错误消息的话，可以在optstring之前加一个冒号。 getopts命令将当前参数保存在命令行中定义的variable中。
getopts命令会用到两个环境变量。如果选项需要跟一个参数值， OPTARG环境变量就会保存这个值。 OPTIND环境变量保存了参数列表中getopts正在处理的参数位置。这样你就能在处理完选项之后继续处理其他命令行参数了。

```bash
echo
while getopts :ab:c opt
do
    case "$opt" in
        a) echo "Found the -a option" ;;
        b) echo "Found the -b option, with value $OPTARG";;
        c) echo "Found the -c option" ;;
        *) echo "Unknown option: $opt";;
    esac
done

```
```bash
$ ./test19.sh -ab test1 -c
Found the -a option
Found the -b option, with value test1
Found the -c option
```

getopts命令有几个好用的功能,可以在参数值中包含空格.

```bash
$ ./test19.sh -b "test1 test2" -a
Found the -b option, with value test1 test2
Found the -a option
```

另一个好用的功能是将选项字母和参数值放在一起使用，而不用加空格。
```
$ ./test19.sh -abtest1
Found the -a option
Found the -b option, with value test1
```

getopts命令能够从-b选项中正确解析出test1值。除此之外， getopts还能够将命令行上
找到的所有未定义的选项统一输出成问号。
```
$ ./test19.sh -d
Unknown option: ?
$
$ ./test19.sh -acde
Found the -a option
Found the -c option
Unknown option: ?
Unknown option: ?
```

##### 1.7.6.4.5. 获得用户输入

**基本的读取**
```bash
echo -n "Enter your name: "
read name
```
生成提示的echo命令使用了-n选项。该选项不会在字符串末尾输出换行符，允许脚本用户紧跟其后输入数据，而不是下一行

实际上， read命令包含了-p选项，允许你直接在read命令行指定提示符。
```bash
read -p "Please enter your age: " age
```

read命令会将提示符后输入的所有数据分配给单个变量，要么你就指定多个变量。输入的每个数据值都会分配给变量列表中的下一个变量。如果变量数量不够，剩下的数据就全部分配给最后一个变量。



**超时**

可以用-t选项来指定一个计时器。 -t选项指定了read命令等待输入的秒数。当计时器过期后， read命令会返回一个非零退出状态码。

```bash
read -t 5 name

```
也可以不对输入过程计时，而是让read命令来统计输入的字符数。当输入的字符达到预设的字符数时，就自动退出，将输入的数据赋给变量。
```bash
read -n1 -p "Do you want to continue [Y/N]? " answer
case $answer in
    Y | y) echo
    echo "fine, continue on…";;
    N | n) echo
    echo OK, goodbye
    exit;;
esac
```
本例中将-n选项和值1一起使用，告诉read命令在接受单个字符后退出。只要按下单个字符回答后， read命令就会接受输入并将它传给变量，无需按回车键。

**隐藏方式读取**

-s选项可以避免在read命令中输入的数据出现在显示器上（实际上，数据会被显示，只是read命令会将文本颜色设成跟背景色一样）。

**从文件中读取**

也可以用read命令来读取Linux系统上文件里保存的数据。每次调用read命令，它都会从文件中读取一行文本。当文件中再没有内容时， read命令会退出并返回非零退出状态码。
其中最难的部分是将文件中的数据传给read命令。最常见的方法是对文件使用cat命令，将结果通过管道直接传给含有read命令的while命令。

```bash
cat test | while read line
do
echo "Line $count: $line"
count=$[ $count + 1]
done
```

#### 1.7.6.5. 呈现数据
<a href="#menu" style="float:right">目录</a>

##### 1.7.6.5.1. 理解输入和输出

**标准文件描述符**
Linux系统将每个对象当作文件处理。这包括输入和输出进程。 Linux用文件描述符（ filedescriptor） 来标识每个文件对象。文件描述符是一个非负整数，可以唯一标识会话中打开的文件。每个进程一次最多可以有九个文件描述符。出于特殊目的， bash shell保留了前三个文件描述符（ 0、 1和2）

|文件描述符|缩 写| 描 述|
|---|---|---|
|0 |STDIN  |标准输入
|1 |STDOUT |标准输出
|2 |STDERR |标准错误

STDIN
STDIN文件描述符代表shell的标准输入。对终端界面来说，标准输入是键盘。 shell从STDIN文件描述符对应的键盘获得输入，在用户输入时处理每个字符。在使用输入重定向符号（ <）时， Linux会用重定向指定的文件来替换标准输入文件描述符。它会读取文件并提取数据，就如同它是键盘上键入的。

STDOUT文件描述符代表shell的标准输出。在终端界面上，标准输出就是终端显示器。 shell的所有输出（包括shell中运行的程序和脚本）会被定向到标准输出中，也就是显示器。默认情况下，大多数bash命令会将输出导向STDOUT文件描述符。你可以用输出重定向>来改变.通过输出重定向符号，通常会显示到显示器的所有输出会被shell重定向到指定的重定向文件。
你也可以将数据追加到某个文件。这可以用>>符号来完成.


shell通过特殊的STDERR文件描述符来处理错误消息。 STDERR文件描述符代表shell的标准错误输出。 shell或shell中运行的程序和脚本出错时生成的错误消息都会发送到这个位置。默认情况下， STDERR文件描述符会和STDOUT文件描述符指向同样的地方（尽管分配给它们的文件描述符值不同）。也就是说，默认情况下，错误消息也会输出到显示器输出中。但从上面的例子可以看出， STDERR并不会随着STDOUT的重定向而发生改变。使用脚本时，你常常会想改变这种行为，尤其是当你希望将错误消息保存到日志文件中的时候。




**重定向错误**
重定向STDERR数据也没太大差别，只要在使用重定向符号时定义STDERR文件描述符就可以了。有几种办法实现方法。

* 只重定向错误
可以选择只重定向错误消息，将该文件描述符值放在重定向符号前。该值必须紧紧地放在重定向符号前，否则不会工作。

```bash
lgj@lgj-Lenovo-G470:~/aaa$ ls -al badfile 2> test4
lgj@lgj-Lenovo-G470:~/aaa$ cat test4
ls: cannot access 'badfile': No such file or directory

```
现在运行该命令，错误消息不会出现在屏幕上了。该命令生成的任何错误消息都会保存在输出文件中。用这种方法， shell会只重定向错误消息，而非普通数据。

* 重定向错误和数据

如果想重定向错误和正常输出，必须用两个重定向符号。需要在符号前面放上待重定向数据所对应的文件描述符，然后指向用于保存数据的输出文件。

```bash
s -al test test2 test3 badtest 2> test6 1> test7
```
可以用这种方法将脚本的正常输出和脚本生成的错误消息分离开来。这样就可以轻松地识别出错误信息，再不用在成千上万行正常输出数据中翻腾了

另外， 如果愿意， 也可以将STDERR和STDOUT的输出重定向到同一个输出文件。 为此bash shell提供了特殊的重定向符号&>。

```bash
ls -al test test2 test3 badtest &> test7
```

##### 1.7.6.5.2. 脚本中重定向输出

可以在脚本中用STDOUT和STDERR文件描述符以在多个位置生成输出，只要简单地重定向相应的文件描述符就行了。有两种方法来在脚本中重定向输出：
* 临时重定向行输出
* 永久重定向脚本中的所有命令

**临时重定向**

如果有意在脚本中生成错误消息，可以将单独的一行输出重定向到STDERR。你所需要做的是使用输出重定向符来将输出信息重定向到STDERR文件描述符。在重定向到文件描述符时，你必须在文件描述符数字之前加一个&：
```bash
echo "This is an error message" >&2
```
这行会在脚本的STDERR文件描述符所指向的位置显示文本，而不是通常的STDOUT。

默认情况下， Linux会将STDERR导向STDOUT。但是，如果你在运行脚本时重定向了STDERR，脚本中所有导向STDERR的文本都会被重定向。

```bash
$ ./test8 2> test9
This is normal output
$ cat test9
This is an error
```
**永久重定向脚本中的所有命令**

如果脚本中有大量数据需要重定向，那重定向每个echo语句就会很烦琐。取而代之，你可以用exec命令告诉shell在脚本执行期间重定向某个特定文件描述符。

```bash
exec 1>testout
exec 2>testerror
```
##### 1.7.6.5.3. 脚本中重定向输入

你可以使用与脚本中重定向STDOUT和STDERR相同的方法来将STDIN从键盘重定向到其他位置。 exec命令允许你将STDIN重定向到Linux系统上的文件中：
```bash
exec 0< testfile
```
这个命令会告诉shell它应该从文件testfile中获得输入，而不是STDIN。这个重定向只要在脚本需要输入时就会作用

```bash
exec 0< testfile
count=1
while read line
do
    echo "Line #$count: $line"
    count=$[ $count + 1 ]
done
```

##### 1.7.6.5.4. 创建自己的重定向

在脚本中重定向输入和输出时，并不局限于这3个默认的文件描述符。在shell中最多可以有9个打开的文件描述符。其他6个从3~8的文件描述符均可用作输入或输出重定向。你可以将这些文件描述符中的任意一个分配给文件，然后在脚本中使用它们

**创建输出文件描述符**

可以用exec命令来给输出分配文件描述符。和标准的文件描述符一样，一旦将另一个文件描述符分配给一个文件，这个重定向就会一直有效，直到你重新分配

```bash
exec 3>test13out
echo "and this should be stored in the file" >&3
```
也可以不用创建新文件，而是使用exec命令来将输出追加到现有文件中。
```bash
exec 3>>test13out
```

**重定向文件描述符**

你可以分配另外一个文件描述符给标准文件描述符，反之亦然。这意味着你可以将STDOUT的原来位置重定向到另一个文件描述符，然后再利用该文件描述符重定向回STDOUT。

```bash
#将文件描述符3重定向到文件描述符1(标准输出)
exec 3>&1
#将文件描述符1重定向到文件
exec 1>test1
echo "This should store in the output file"
echo "along with this line."
#将文件描述符1恢复到标准输出
exec 1>&3
#输出
$ ./test.sh
This should store in the output file
$ cat test1
along with this line.

```
首先，脚本将文件描述符3重定向到文件描述符1的当前位置，也就是STDOUT。这意味着任何发送给文件描述符3的输出都将出现在显示器上。
第二个exec命令将STDOUT重定向到文件， shell现在会将发送给STDOUT的输出直接重定向到输出文件中。但是，文件描述符3仍然指向STDOUT原来的位置，也就是显示器。如果此时将输出数据发送给文件描述符3，它仍然会出现在显示器上，尽管STDOUT已经被重定向了。
在向STDOUT（现在指向一个文件）发送一些输出之后，脚本将STDOUT重定向到文件描述符3的当前位置（现在仍然是显示器）。这意味着现在STDOUT又指向了它原来的位置：显示器

**创建输入文件描述符**

可以用和重定向输出文件描述符同样的办法重定向输入文件描述符。在重定向到文件之前，先将STDIN文件描述符保存到另外一个文件描述符，然后在读取完文件之后再将STDIN恢复到它原来的位置。

```bash
exec 6<&0
exec 0< testfile
exec 0<&6
```
**创建读写文件描述符**

可以用同一个文件描述符对同一个文件进行读写。
不过用这种方法时，你要特别小心。由于你是对同一个文件进行数据读写， shell会维护一个内部指针，指明在文件中的当前位置。任何读或写都会从文件指针上次的位置开始。

```bash
exec 3<> testfile
read line <&3
echo "Read: $line"
echo "This is a test line" >&3
```
**关闭文件描述符**

如果你创建了新的输入或输出文件描述符， shell会在脚本退出时自动关闭它们。然而在有些情况下，你需要在脚本结束前手动关闭文件描述符。
要关闭文件描述符，将它重定向到特殊符号&-。脚本中看起来如下：
```bash
exec 3>&-
```
一旦关闭了文件描述符，就不能在脚本中向它写入任何数据，否则shell会生成错误消息


##### 1.7.6.5.5. 列出打开的文件描述符

lsof命令会列出整个Linux系统打开的所有文件描述符。这是个有争议的功能，因为它会向非系统管理员用户提供Linux系统的信息。鉴于此，许多Linux系统隐藏了该命令，这样用户就不
会一不小心就发现了。
在很多Linux系统中（如Fedora）， lsof命令位于/usr/sbin目录。要想以普通用户账户来运行它，必须通过全路径名来引用：$ /usr/sbin/lsof
该命令会产生大量的输出。它会显示当前Linux系统上打开的每个文件的有关信息。这包括后台运行的所有进程以及登录到系统的任何用户。
有大量的命令行选项和参数可以用来帮助过滤lsof的输出。最常用的有-p和-d，前者允许指定进程ID（ PID），后者允许指定要显示的文件描述符编号。
要想知道进程的当前PID，可以用特殊环境变量$$（ shell会将它设为当前PID）。 -a选项用来对其他两个选项的结果执行布尔AND运算，这会产生如下输出。

```bash
$ /usr/sbin/lsof -a -p $$ -d 0,1,2
```
输出
```
COMMAND    PID  TID             USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAME
systemd      1                  root  cwd   unknown                                         /proc/1/cwd (readlink: Permission denied)
systemd      1                  root  rtd   unknown                                         /proc/1/root (readlink: Permission denied)
systemd      1                  root  txt   unknown                                         /proc/1/exe (readlink: Permission denied)

```
* COMMAND 正在运行的命令名的前9个字符
* PID 进程的PID
* USER 进程属主的登录名
* FD 文件描述符号以及访问类型（ r代表读， w代表写， u代表读写）
* TYPE 文件的类型（ CHR代表字符型， BLK代表块型， DIR代表目录， REG代表常规文件）
* DEVICE 设备的设备号（主设备号和从设备号）
* SIZE 如果有的话，表示文件的大小
* NODE 本地文件的节点号
* NAME 文件名

```bash
exec 3> test18file1
exec 6> test18file2
exec 7< testfile
/usr/sbin/lsof -a -p $$ -d0,1,2,3,6,7
$ ./test18
COMMAND PID USER FD TYPE DEVICE SIZE NODE NAME
test18 3594 rich 0u CHR 136,0 2 /dev/pts/0
test18 3594 rich 1u CHR 136,0 2 /dev/pts/0
test18 3594 rich 2u CHR 136,0 2 /dev/pts/0
18 3594 rich 3w REG 253,0 0 360712 /home/rich/test18file1
18 3594 rich 6w REG 253,0 0 360715 /home/rich/test18file2
18 3594 rich 7r REG 253,0 73 360717 /home/rich/testfile
```

##### 1.7.6.5.6. 阻止命令输出

不想显示脚本的输出,要解决这个问题，可以将STDERR重定向到一个叫作null文件的特殊文件。 null文件跟它的名字很像，文件里什么都没有。 shell输出到null文件的任何数据都不会保存，全部都被丢掉了。
在Linux系统上null文件的标准位置是/dev/null。你重定向到该位置的任何数据都会被丢掉，不会显示。

```bash
 ls -al > /dev/null
 #刷掉文件中的数据,文件testfile仍然存在系统上，但现在它是空文件。这是清除日志文件的一个常用方法，因为日志文件必须时刻准备等待应用程序操作。
 cat /dev/null > testfile
```

##### 1.7.6.5.7. 创建临时文件

Linux系统有特殊的目录，专供临时文件使用。 Linux使用/tmp目录来存放不需要永久保留的文件。大多数Linux发行版配置了系统在启动时自动删除/tmp目录的所有文件。系统上的任何用户账户都有权限在读写/tmp目录中的文件。这个特性为你提供了一种创建临时文件的简单方法，而且还不用操心清理工作。
有个特殊命令可以用来创建临时文件。 mktemp命令可以在/tmp目录中创建一个唯一的临时文件。 shell会创建这个文件，但不用默认的umask值（参见第7章）。它会将文件的读和写权限分配给文件的属主，并将你设成文件的属主。一旦创建了文件，你就在脚本中有了完整的读写权限，但其他人没法访问它（当然， root用户除外）。


**创建本地临时文件**

默认情况下， mktemp会在本地目录中创建一个文件。要用mktemp命令在本地目录中创建一个临时文件，你只要指定一个文件名模板就行了。模板可以包含任意文本文件名，在文件名末尾加上6个X就行了。
```bash
$ mktemp testing.XXXXXX

#创建的文件
-rw------- 1 lgj lgj   0 Dec  5 01:23 testing.neAOCU

```
mktemp命令会用6个字符码替换这6个X，从而保证文件名在目录中是唯一的。你可以创建多个临时文件，它可以保证每个文件都是唯一的。



**在/temp目录中创建临时文件**

-t选项会强制mktemp命令来在系统的临时目录来创建该文件。在用这个特性时， mktemp命令会返回用来创建临时文件的全路径，而不是只有文件名。
```bash
lgj@lgj-Lenovo-G470:~/aaa$ mktemp -t test.XXXXXX
/tmp/test.hkfHEK

lgj@lgj-Lenovo-G470:~/aaa$ ls -l /tmp/test.*
-rw------- 1 lgj lgj 0 Dec  5 01:39 /tmp/test.hkfHEK

```

**创建临时目录**

-d选项告诉mktemp命令来创建一个临时目录而不是临时文件。


##### 1.7.6.5.8. 记录消息

将输出同时发送到显示器和日志文件，这种做法有时候能够派上用场。你不用将输出重定向两次，只要用特殊的tee命令就行。tee命令相当于管道的一个T型接头。它将从STDIN过来的数据同时发往两处。一处是STDOUT，另一处是tee命令行所指定的文件名：

```bash
tee filename
```


#### 1.7.6.6. 控制脚本
<a href="#menu" style="float:right">目录</a>

##### 1.7.6.6.1. 处理信号

**Linux信号**

Linux系统和应用程序可以生成超过30个信号

常用Linux信号

|信 号 |值 |描 述|
|---|---|---|
|1 |SIGHUP |挂起进程
|2 |SIGINT |终止进程
|3 |SIGQUIT |停止进程
|9 |SIGKILL |无条件终止进程
|15 |SIGTERM |尽可能终止进程
|17 |SIGSTOP |无条件停止进程，但不是终止进程
|18 |SIGTSTP |停止或暂停进程，但不终止进程
|19 |SIGCONT |继续运行停止的进程

默认情况下， bash shell会忽略收到的任何SIGQUIT (3)和SIGTERM (5)信号（正因为这样，交互式shell才不会被意外终止）。但是bash shell会处理收到的SIGHUP (1)和SIGINT (2)信号。

如果bash shell收到了SIGHUP信号，比如当你要离开一个交互式shell，它就会退出。但在退出之前，它会将SIGHUP信号传给所有由该shell所启动的进程（包括正在运行的shell脚本）

通过SIGINT信号，可以中断shell。 Linux内核会停止为shell分配CPU处理时间。这种情况发生时， shell会将SIGINT信号传给所有由它所启动的进程，以此告知出现的状况。



**生成信号**

* 中断进程,Ctrl+C组合键会生成SIGINT信号,并将其发送给当前在shell中运行的所有进程。
* 暂停进程,Ctrl+Z组合键会生成一个SIGTSTP信号，停止shell中运行的任何进程.停止（ stopping）进程跟终止（ terminating）进程不同：停止进程会让程序继续保留在内存中，并能从上次停止的位置
继续运行。

**捕获信号**

也可以不忽略信号，在信号出现时捕获它们并执行其他命令。 trap命令允许你来指定shell脚本要监看并从shell中拦截的Linux信号。如果脚本收到了trap命令中列出的信号，该信号不再
由shell处理，而是交由本地处理。
trap命令的格式是：trap commands signals

```bash
trap "echo ' Sorry! I have trapped Ctrl-C'" SIGINT
```
以上在脚本中加入,运行状态时收到SIGINT会打印该语句,但是不会终止运行.
**捕获脚本退出**

除了在shell脚本中捕获信号，你也可以在shell脚本退出时进行捕获。这是在shell完成任务时执行命令的一种简便方法

要捕获shell脚本的退出，只要在trap命令后加上EXIT信号就行。
```bash
trap "echo Goodbye..." EXIT
```
当脚本运行到正常的退出位置时，捕获就被触发了， shell会执行在trap命令行指定的命令。如果提前退出脚本(正常或者异常)，同样能够捕获到EXIT。


**修改或移除捕获**

要想在脚本中的不同位置进行不同的捕获处理，只需重新使用带有新选项的trap命令

也可以删除已设置好的捕获。只需要在trap命令与希望恢复默认行为的信号列表之间加上两个破折号就行了。

```bash
trap -- SIGINT
```


##### 1.7.6.6.2. 以后台模式运行脚本

**后台运行脚本**

以后台模式运行shell脚本非常简单。只要在命令后加个&符就行了.当&符放到命令后时，它会将命令和bash shell分离开来，将命令作为系统中的一个独立的后台进程运行。显示的第一行是：[1] 3231

##### 1.7.6.6.3. 在非控制台下运行脚本

时你会想在终端会话中启动shell脚本，然后让脚本一直以后台模式运行到结束，即使你退出了终端会话。这可以用nohup命令来实现。
nohup命令运行了另外一个命令来阻断所有发送给该进程的SIGHUP信号。这会在退出终端会话时阻止进程退出。
nohup命令的格式如下：$ nohup ./test1.sh &

和普通后台进程一样， shell会给命令分配一个作业号， Linux系统会为其分配一个PID号。区别在于，当你使用nohup命令时，如果关闭该会话，脚本会忽略终端会话发过来的SIGHUP信号

由于nohup命令会解除终端与进程的关联，进程也就不再同STDOUT和STDERR联系在一起。为了保存该命令产生的输出， nohup命令会自动将STDOUT和STDERR的消息重定向到一个名为nohup.out的文件中。

如果使用nohup运行了另一个命令，该命令的输出会被追加到已有的nohup.out文件中。当运行位于同一个目录中的多个命令时一定要当心，因为所有的输出都会被发送到同一个nohup.out文件中



##### 1.7.6.6.4. 作业控制

**查看作业**

作业控制中的关键命令是jobs命令。 jobs命令允许查看shell当前正在处理的作业。


jobs命令参数

|参 数| 描 述|
|---|---|
|-l |列出进程的PID以及作业号
|-n |只列出上次shell发出的通知后改变了状态的作业
|-p |只列出作业的PID
|-r |只列出运行中的作业
|-s |只列出已停止的作业

```bash
$ jobs -l
[1]+  8290 Running                 ./test.sh &

```
你可能注意到了jobs命令输出中的加号和减号。带加号的作业会被当做默认作业。在使用作业控制命令时，如果未在命令行指定任何作业号，该作业会被当成作业控制命令的操作对象。
当前的默认作业完成处理后，带减号的作业成为下一个默认作业。任何时候都只有一个带加号的作业和一个带减号的作业，不管shell中有多少个正在运行的作业


**重启停止的作业**

要以后台模式重启一个作业，可用bg命令加上作业号
要以前台模式重启作业，可用带有作业号的fg命令
```bash
bg 2
fg 2
```

##### 1.7.6.6.5. 调整谦让度

在多任务操作系统中（ Linux就是），内核负责将CPU时间分配给系统上运行的每个进程。 调度优先级（ scheduling priority）是内核分配给进程的CPU时间（相对于其他进程）。在Linux系统
中，由shell启动的所有进程的调度优先级默认都是相同的。
调度优先级是个整数值，从20（最高优先级）到+19（最低优先级）。默认情况下， bash shell以优先级0来启动所有进程



**nice命令**

nice命令允许你设置命令启动时的调度优先级。要让命令以更低的优先级运行，只要用nice的-n命令行来指定新的优先级级别。
```bash
$ nice -n 10 ./test4.sh > test4.out &

#查看优先级ni
ps -p 4973 -o pid,ppid,ni,cmd
```
nice命令阻止普通系统用户来提高命令的优先级。

**renice命令**

改变系统上已运行命令的优先级。这正是renice命令可以做到的。它允许你指定运行进程的PID来改变它的优先级。
```bash
renice -n 10 -p 5055
```
renice命令会自动更新当前运行进程的调度优先级。和nice命令一样， renice命令也有一些限制：
* 只能对属于你的进程执行renice；
* 只能通过renice降低进程的优先级；
* root用户可以通过renice来任意调整进程的优先级。
如果想完全控制运行进程，必须以root账户身份登录或使用sudo命令。

##### 1.7.6.6.6. 定时运行作业

**用at命令**

at命令允许指定Linux系统何时运行脚本。 at命令会将作业提交到队列中，指定shell何时运行该作业。 at的守护进程atd会以后台模式运行，检查作业队列来运行作业。大多数Linux发行版会在启动时运行此守护进程。
atd守护进程会检查系统上的一个特殊目录（通常位于/var/spool/at）来获取用at命令提交的作业。默认情况下， atd守护进程会每60秒检查一下这个目录。有作业时， atd守护进程会检查
作业设置运行的时间。如果时间跟当前时间匹配， atd守护进程就会运行此作业

at命令的基本格式非常简单：at [-f filename] time

默认情况下， at命令会将STDIN的输入放到队列中。你可以用-f参数来指定用于读取命令（脚本文件）的文件名。
time参数指定了Linux系统何时运行该作业。如果你指定的时间已经错过， at命令会在第二天的那个时间运行指定的作业。
在如何指定时间这个问题上，你可以非常灵活。 at命令能识别多种不同的时间格式。
* 标准的小时和分钟格式，比如10:15。
* AM/PM指示符，比如10:15 PM。
* 特定可命名时间，比如now、 noon、 midnight或者teatime（ 4 PM）。
除了指定运行作业的时间，也可以通过不同的日期格式指定特定的日期。
* 标准日期格式，比如MMDDYY、 MM/DD/YY或DD.MM.YY。
* 文本日期，比如Jul 4或Dec 25，加不加年份均可。
* 你也可以指定时间增量。
* 当前时间+25 min
* 明天10:15 PM
* 10:15+7天

在你使用at命令时，该作业会被提交到作业队列（ job queue）。作业队列会保存通过at命令提交的待处理的作业。针对不同优先级，存在26种不同的作业队列。作业队列通常用小写字母a~z和大写字母A~Z来指代。

```bash
lgj@lgj-Lenovo-G470:~/aaa$ at -f test.sh now
warning: commands will be executed using /bin/sh
job 8 at Thu Dec  5 04:23:00 2019

```

**安排需要定期执行的脚本**

用at命令在预设时间安排脚本执行非常好用，但如果你需要脚本在每天的同一时间运行或是每周一次、每月一次呢？用不着再使用at不断提交作业了，你可以利用Linux系统的另一个功能。Linux系统使用cron程序来安排要定期执行的作业。 cron程序会在后台运行并检查一个特殊的表（被称作cron时间表） ，以获知已安排执行的作业。

cron时间表采用一种特别的格式来指定作业何时运行。其格式如下：
min hour dayofmonth month dayofweek command
cron时间表允许你用特定值、取值范围（比如1~5）或者是通配符（星号）来指定条目。例如，如果想在每天的10:15运行一个命令，可以用cron时间表条目：15 10 * * * command


可以用三字符的文本值（ mon、 tue、 wed、 thu、 fri、 sat、 sun）或数值（ 0为周日， 6为周六）来指定dayofweek表项。

如何设置一个在每个月的最后一天执行的命令，因为你无法设置dayofmonth的值来涵盖所有的月份。这个问题困扰着Linux和Unix程序员，也激发了不少解决办法。常用的方法是加一条使用date命令的if-then语句来检查明天的日期是不是01：00 12 * * * if [`date +%d -d tomorrow` = 01 ] ; then ; command
它会在每天中午12点来检查是不是当月的最后一天，如果是， cron将会运行该命令。

命令列表必须指定要运行的命令或脚本的全路径名。你可以像在普通的命令行中那样，添加任何想要的命令行参数和重定向符号。
15 10 * * * /home/rich/test4.sh > test4out

**使用新的shell启动脚本**


### 1.7.7. 高级 shell 脚本编程


#### 1.7.7.1. 创建函数

##### 1.7.7.1.1. 基本的脚本函数

第一种格式采用关键字function，后跟分配给该代码块的函数名。

```bash
function name {
    commands
}
```
第二种格式更接近于其他编程语言中定义函数的方式。函数名后的空括号表明正在定义的是一个函数
```bash
name() {
    commands
}
```
**使用函数**
使用函数直接调用函数名称即可.函数在调用前必须先声明,否则会抛出错误.



##### 1.7.7.1.2. 返回值

bash shell会把函数当作一个小型脚本，运行结束时会返回一个退出状态码。有3种不同的方法来为函数生成退出状态码。

**默认退出状态码**

默认情况下，函数的退出状态码是函数中最后一条命令返回的退出状态码。在函数执行结束后，可以用标准变量$?来确定函数的退出状态码。

**使用 return 命令**

bash shell使用return命令来退出函数并返回特定的退出状态码。 return命令允许指定一个整数值来定义函数的退出状态码，从而提供了一种简单的途径来编程设定函数退出状态码。

```bash
function db1 {
    read -p "Enter a value: " value
    echo "doubling the value"
    return $[ $value * 2 ]
}
db1
echo "The new value is $?"
$
```
但当用这种方法从函数中返回值时，要小心了。记住下面两条技巧来避免问题：
* 函数一结束就取返回值；
* 退出状态码必须是0~255。超过该范围会导致溢出
如果在用$?变量提取函数返回值之前执行了其他命令，函数的返回值就会丢失。记住， $?变量会返回执行的最后一条命令的退出状态码。
第二个问题界定了返回值的取值范围。由于退出状态码必须小于256，函数的结果必须生成一个小于256的整数值。任何大于256的值都会产生一个错误值。要返回较大的整数值或者字符串值的话，你就不能用这种返回值的方法了

**使用函数输出**

正如可以将命令的输出保存到shell变量中一样，你也可以对函数的输出采用同样的处理办法。可以用这种技术来获得任何类型的函数输出，并将其保存到变量中：
result='dbl'
这个命令会将dbl函数的输出赋给$result变量。
```bash
function dbl {
    read -p "Enter a value: " value
    echo $[ $value * 2 ]
}
result=$(dbl)
echo "The new value is $result"
```
$result的值是函数中所有echo的输出值

dbl函数实际上输出了两条消息。 read命令输出了一条简短的消息来向用户询问输入值。 bash shell脚本非常聪明， 并不将其作为STDOUT输出的一部分，并且忽略掉它。如果你用echo语句生成这条消息来向用户查询，那么它会与输出值一起被读进shell变量中。



##### 1.7.7.1.3. 在函数中使用变量

**向函数传递参数**
函数可以使用标准的参数环境变量来表示命令行上传给函数的参数。例如，函数名会在$0变量中定义，函数命令行上的任何参数都会通过$1、 $2等定义。也可以用特殊变量$#来判断传给函数的参数数目。

调用并传参
```
result=$(db1 par1  par2 )
```

**在函数中使用变量**

函数使用两种类型的变量：全局变量和局部变量

全局变量是在shell脚本中任何地方都有效的变量。如果你在脚本的主体部分定义了一个全局变量，那么可以在函数内读取它的值。类似地，如果你在函数内定义了一个全局变量，可以在脚
本的主体部分读取它的值。
默认情况下，你在脚本中定义的任何变量都是全局变量。在函数外定义的变量可在函数内正常访问。

无需在函数中使用全局变量，函数内部使用的任何变量都可以被声明成局部变量。要实现这一点，只要在变量声明的前面加上local关键字就可以了。
```bash
local temp
local temp=$[ $value + 5 ]
```
local关键字保证了变量只局限在该函数中。如果脚本中在该函数之外有同样名字的变量，那么shell将会保持这两个变量的值是分离的。


##### 1.7.7.1.4. 数组变量和函数

**向函数传数组参数**

```bash
function testit {
    echo "The parameters are: $@"
    thisarray=$1
    echo "The received array is ${thisarray[*]}"
}
myarray=(1 2 3 4 5)
echo "The original array is: ${myarray[*]}"
testit $myarray
$
$ ./badtest3
The original array is: 1 2 3 4 5
The parameters are: 1
The received array is 1
$
```

如果你试图将该数组变量作为函数参数，函数只会取数组变量的第一个值。
要解决这个问题，你必须将该数组变量的值分解成单个的值，然后将这些值作为函数参数使用。在函数内部，可以将所有的参数重新组合成一个新的变量。下面是个具体的例子。

```bash
function testit {
local newarray
    newarray=(;'echo "$@"')
    echo "The new array value is: ${newarray[*]}"
}
myarray=(1 2 3 4 5)
echo "The original array is ${myarray[*]}"
testit ${myarray[*]}
$
$ ./test10
The original array is 1 2 3 4 5
The new array value is: 1 2 3 4 5
$
```


**从函数返回数组**

从函数里向shell脚本传回数组变量也用类似的方法。函数用echo语句来按正确顺序输出单个数组值，然后脚本再将它们重新放进一个新的数组变量中。

```bash
function arraydblr {
    local origarray
    local newarray
    local elements
    local i
    origarray=($(echo "$@"))
    newarray=($(echo "$@"))
    elements=$[ $# - 1 ]
    for (( i = 0; i <= $elements; i++ ))
    {
        newarray[$i]=$[ ${origarray[$i]} * 2 ]
    }
    echo ${newarray[*]}
}
myarray=(1 2 3 4 5)
echo "The original array is: ${myarray[*]}"
arg1=$(echo ${myarray[*]})
result=($(arraydblr $arg1))
echo "The new array is: ${result[*]}"
$
$ ./test12
The original array is: 1 2 3 4 5
The new array is: 2 4 6 8 10
```

该脚本用$arg1变量将数组值传给arraydblr函数。 arraydblr函数将该数组重组到新的数组变量中，生成该输出数组变量的一个副本。然后对数据元素进行遍历，将每个元素值翻倍，并将结果存入函数中该数组变量的副本。
arraydblr函数使用echo语句来输出每个数组元素的值。脚本用arraydblr函数的输出来重新生成一个新的数组变量。


##### 1.7.7.1.5. 函数递归

局部函数变量的一个特性是自成体系。除了从脚本命令行处获得的变量，自成体系的函数不需要使用任何外部资源。
这个特性使得函数可以递归地调用，也就是说，函数可以调用自己来得到结果。

##### 1.7.7.1.6. 创建库

使用函数可以在脚本中省去一些输入工作，这一点是显而易见的。但如果你碰巧要在多个脚本中使用同一段代码呢？显然，为了使用一次而在每个脚本中都定义同样的函数太过麻烦

和环境变量一样， shell函数仅在定义它的shell会话内有效。如果你在shell命令行界面的提示符下运行myfuncs shell脚本， shell会创建一个新的shell并在其中运行这个脚本。它会为那个新shell定义这三个函数，但当你运行另外一个要用到这些函数的脚本时，它们是无法使用的。这同样适用于脚本。如果你尝试像普通脚本文件那样运行库文件，函数并不会出现在脚本中。
myfuncs.sh定义公共函数
test.sh中这样使用会出现问题
```bash
./myfuncs.sh
```
使用函数库的关键在于source命令。 source命令会在当前shell上下文中执行命令，而不是创建一个新shell。可以用source命令来在shell脚本中运行库文件脚本。这样脚本就可以使用库
中的函数了。source命令有个快捷的别名，称作点操作符（ dot operator）。要在shell脚本中运行myfuncs库文件，只需添加下面这行：. ./myfuncs
正确用法
```bash
. ./myfuncs.sh
```

##### 1.7.7.1.7. 在命令行上使用函数






#### 1.7.7.2. 图形化桌面环境中的脚本编程

#### 1.7.7.3. 初识 sed 和 gawk

##### 1.7.7.3.1. 文本处理

##### 1.7.7.3.2. sed编辑器基础

#### 1.7.7.4. 正则表达式

##### 1.7.7.4.1. 什么是正则表达式

##### 1.7.7.4.2. 定义BRE模式

##### 1.7.7.4.3. 扩展正则表达式

##### 1.7.7.4.4. 正则表达式实战

#### 1.7.7.5. sed 进阶

##### 1.7.7.5.1. 多行命令
##### 1.7.7.5.2. 保持空间
##### 1.7.7.5.3. 排除命令
##### 1.7.7.5.4. 改变流
##### 1.7.7.5.5. 模式替代
##### 1.7.7.5.6. 在脚本中使用sed
##### 1.7.7.5.7. 创建sed实用工具

#### 1.7.7.6. gawk 进阶

##### 1.7.7.6.1. 使用变量
##### 1.7.7.6.2. 处理数组
##### 1.7.7.6.3. 使用模式
##### 1.7.7.6.4. 结构化命令 
##### 1.7.7.6.5. 格式化打印
##### 1.7.7.6.6. 内建函数
##### 1.7.7.6.7. 自定义函数
